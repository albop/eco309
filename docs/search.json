[
  {
    "objectID": "tutorials/3_Optimization_correction.html",
    "href": "tutorials/3_Optimization_correction.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "In this tutorial you will learn to code and use common optimization algorithms for static models.\n\n\n\n\nA monopolist produces quantity \\(q\\) of goods X at price \\(p\\). Its cost function is \\(c(q) = 0.5 + q (1-qe^{-q})\\)\nThe consumer’s demand for price \\(p\\) is \\(x(p)=2 e^{-0.5 p}\\) (constant elasticity of demand to price).\nWrite down the profit function of the monopolist and find the optimal production (if any). Don’t use any library except for plotting.\nAssume the monopolist decides on the optimal quantity \\(q\\). Price at this quantity is determined by demand: \\(p(x) = -2 \\log\\left( \\frac{x}{2} \\right)\\)\nProfit function \\(\\pi(q) = \\underbrace{R(q)}_{\\text{revenue}} - c(q) = q * p(q) - c(q)\\)\n\np(q) = -2log(q/2)\nc(q) = 0.5 + q*(1-q*exp(-q))\nR(q) = q*p(q)\nprofits(q) = R(q) - c(q)\n\nprofits (generic function with 1 method)\n\n\n\nusing Plots\n\n\nqvec = range(0.1, 1; length=100)\n\n0.1:0.00909090909090909:1.0\n\n\n\nprofits.(qvec);\n\n\nplot(qvec, profits.(qvec))\n\n\n\n\n\nfunction golden(f, a, b; fa=f(a), fb=f(b), Φ=0.3, ϵ=1e-5)\n    if abs(b-a)<ϵ\n        return (a+b)/2\n    end\n    c = a + Φ*(b-a)\n    d = a + (1-Φ)*(b-a)\n    fc = f(c)\n    fd = f(d)\n    # I need to choose between [a,c,d] or [c,d,b]\n    if (fc>=fa && fc>=fd)\n        return golden(f, a, d; fa=fa, fb=fd, Φ=Φ, ϵ=ϵ)\n    elseif (fd>fc && fd>fb)\n        return golden(f, c, b; fa=fc, fb=fb, Φ=Φ, ϵ=ϵ)\n    else\n        # here I should return a or b\n        throw(\"Incorrect function: does not contain an unconstrained local maximum\")\n    end\nend\n\ngolden (generic function with 1 method)\n\n\n\nqopt = golden(profits, 0.2, 1.0)\n\n0.5618586881082992\n\n\n\npl = plot(qvec, profits.(qvec))\nplot!([qopt], [profits(qopt)], marker=\"o\")\n\n┌ Warning: Skipped marker arg o.\n└ @ Plots /home/pablo/.julia/packages/Plots/SVksJ/src/args.jl:873\n\n\n\n\n\nAlternative approach: define\n\\(\\pi^{\\prime} = r^{\\prime}(q) - c^{\\prime}(q)\\)\nLook for a zero \\(\\pi^{\\prime}(q) = 0\\).\nIf we do that, we need to check that it is indeed a maximum and that profits are positive.\n\n\n\n\nConsider the function \\(f(x,y) = 1-(x-0.5)^2 -(y-0.3)^2\\).\nUse Optim.jl to minimize \\(f\\) without constraint. Check you understand diagnostic information returned by the optimizer.\n\nusing Optim\n\n┌ Info: Precompiling Optim [429524aa-4258-5aef-a3af-852621145aeb]\n└ @ Base loading.jl:1278\n\n\n\nf(x::Vector{Float64}) = 1- (x[1]-0.5)^2 - (x[2]-0.3)^2\n\nf (generic function with 1 method)\n\n\n\nx0 = [0.0, 0.0]\nresult = Optim.optimize(u->-f(u), x0, Newton())\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     -1.000000e+00\n\n * Found with\n    Algorithm:     Newton's Method\n\n * Convergence measures\n    |x - x'|               = 5.00e-01 ≰ 0.0e+00\n    |x - x'|/|x'|          = 1.00e+00 ≰ 0.0e+00\n    |f(x) - f(x')|         = 3.40e-01 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 3.40e-01 ≰ 0.0e+00\n    |g(x)|                 = 1.65e-09 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    1\n    f(x) calls:    4\n    ∇f(x) calls:   4\n    ∇²f(x) calls:  1\n\n\n\nresult.minimizer\n\n2-element Array{Float64,1}:\n 0.5000172833186103\n 0.2999408484491455\n\n\nNow, consider the constraint \\(x<0.3\\) and maximize \\(f\\) under this new constraint.\n\nlower = [-Inf, -Inf]\nupper = [0.3, Inf]\n\n2-element Array{Float64,1}:\n  0.3\n Inf\n\n\n\nx0\n\n2-element Array{Float64,1}:\n 0.0\n 0.0\n\n\n\nresult_bounded = Optim.optimize(u->-f(u), lower, upper, x0)\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     -9.600000e-01\n\n * Found with\n    Algorithm:     Fminbox with L-BFGS\n\n * Convergence measures\n    |x - x'|               = 1.20e-06 ≰ 0.0e+00\n    |x - x'|/|x'|          = 2.83e-06 ≰ 0.0e+00\n    |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 0.0e+00\n    |g(x)|                 = 1.20e-09 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    3\n    f(x) calls:    56\n    ∇f(x) calls:   56\n\n\n\nresult_bounded.minimizer\n\n2-element Array{Float64,1}:\n 0.2999999988\n 0.29999999999995636\n\n\nReformulate the problem as a root finding problem with lagrangians. Write the complementarity conditions.\nSolve using NLSolve.jl\n\n\n\n\nA consumer has preferences \\(U(c_1, c_2)\\) over two consumption goods \\(c_1\\) and \\(c_2\\).\nGiven a budget \\(I\\), consumer wants to maximize utility subject to the budget constraint \\(p_1 c_1 + p_2 c_2 \\leq I\\).\nWe choose a Stone-Geary specification where\n\\(U(c_1, c_2)=\\beta_1 \\log(c_1-\\gamma_1) + \\beta_2 \\log(c_2-\\gamma_2)\\)\nWrite the Karush-Kuhn-Tucker necessary conditions for the problem.\nVerify the KKT conditions are sufficient for optimality.\nDerive analytically the demand functions, and the shadow price.\nInterpret this problem as a complementarity problem and solve it using NLSolve.\nProduce some nice graphs with isoutility curves, the budget constraint and the optimal choice."
  },
  {
    "objectID": "tutorials/3_Optimization.html",
    "href": "tutorials/3_Optimization.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "In this tutorial you will learn to code and use common optimization algorithms for static models.\n\n\n\n\nA monopolist produces quantity \\(q\\) of goods X at price \\(p\\). Its cost function is \\(c(q) = 0.5 + q (1-qe^{-q})\\)\nThe consumer’s demand for price \\(p\\) is \\(x(p)=2 e^{-0.5 p}\\) (constant elasticity of demand to price).\nWrite down the profit function of the monopolist and find the optimal production (if any). Don’t use any library except for plotting.\n\n\n\n\nConsider the function \\(f(x,y) = 1-(x-0.5)^2 -(y-0.3)^2\\).\nUse Optim.jl to minimize \\(f\\) without constraint. Check you understand diagnostic information returned by the optimizer.\nNow, consider the constraint \\(x<0.3\\) and maximize \\(f\\) under this new constraint.\nReformulate the problem as a root finding problem with lagrangians. Write the complementarity conditions.\nSolve using NLSolve.jl\n\n\n\n\nA consumer has preferences \\(U(c_1, c_2)\\) over two consumption goods \\(c_1\\) and \\(c_2\\).\nGiven a budget \\(I\\), consumer wants to maximize utility subject to the budget constraint \\(p_1 c_1 + p_2 c_2 \\leq I\\).\nWe choose a Stone-Geary specification where\n\\(U(c_1, c_2)=\\beta_1 \\log(c_1-\\gamma_1) + \\beta_2 \\log(c_2-\\gamma_2)\\)\nWrite the Karush-Kuhn-Tucker necessary conditions for the problem.\nVerify the KKT conditions are sufficient for optimality.\nDerive analytically the demand functions, and the shadow price.\nInterpret this problem as a complementarity problem and solve it using NLSolve.\nProduce some nice graphs with isoutility curves, the budget constraint and the optimal choice."
  },
  {
    "objectID": "tutorials/1_2_Epidemiology.html",
    "href": "tutorials/1_2_Epidemiology.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "H.W. Heathcote: epidemiologic models are deterministic models for infectious diseases which are spread by direct person-to-person contact in a population.\nThis kind of models has been used since by a few decades by economist, for matters that have nothing to do with health.\n\ndiffusion of information, or opinions on social medias\nasset prices and fads\nexpectation formation for macroeconomic outcomes (ex: The Epidemiology of Macroeconomic Expectations by Chris Carroll)\n\nEpidemiologic models have two features that depart from standard economic models:\n\nAgent’s behaviour does not take the full system into account, an is irrational in the sense that it isn’t forwards looking. Instead, an agent is given a behavioural heuristic.\nThe transitions of the whole system can be determined without solving for complex interactions first.\n\nUnderstanding why these two assumptions are very costly for economists will keep us busy during a big part of the course. Here we just consider two simple models as small programming exercises.\n\n\nThere is a continuum of agents of mass \\(1\\). Each agent can be either “Susceptible” (S), “Infected” (I) or “Recovered” (R). In each period, one agent meets another agent drawn randomly. During a meeting Susceptible agents who meet an infected agent, will always catch the disease (or the fad) but are not contagious. Infected agents, have a probability \\(\\pi\\) of being recovered. Nothing happens to Recovered agents who meet other people. No distinction is made between recovering as a healthy or a dead person.\nWe’re interested in the evolution in the number infected persons, both the speed of infection and the total amount of infected people in every period.\nWrite down the transition equations for \\(n_I\\), the number of infected people, for \\(n_R\\) the number of recovered people and \\(n_S\\) the number of susceptible people.\nCompute the transition function f for the vector state \\(s_t\\) returning \\(s_{t+1}\\).\nCompute the transitions over \\(T\\) periods. Plot the result using Plots.jl. (bonus: check against closed form solution)\nWe now assume a Susceptible person who meets an infected one has a probability \\(\\mu\\) of catching the disease. Update the transition function. Update function \\(f\\) and write a function of \\(\\mu\\), \\(\\pi\\) which returns the simulation. Compare different values of the parameters. How would you interpret “social distancing”? How would you choose parameters \\(\\Pi\\) and \\(\\mu\\)?\n\n\n\nWe now consider another version of the model where agents evolve in the space \\(\\mathcal{S}=[0,1]\\times[0,1]\\). There are \\(N\\in\\mathbb{N}\\) agent. At any date, each agent \\(n \\in [0,1]\\) is located at \\((x_n,y_n)\\in \\mathcal{S}\\).\nEach agent moves follows a random walk bounded by \\(\\mathcal{S}\\): \\[x_t = \\min(\\max( x_{t-1} + \\epsilon_t, 0), 1)\\] \\[y_t = \\min(\\max( y_{t-1} + \\eta_t, 0), 1)\\] where \\(\\epsilon_t\\) and \\(\\eta_t\\) are both normally distributed with standard deviation \\(\\sigma\\).\nAt any date, the individual state of an agent is \\(s_t=(x_t, y_t, h_t)\\) where \\(h_t\\) is either “S”, “I” or “R”. \\(v_t\\) denotes the states of all agents (for instance \\(v_t=(s_{n,t})_n\\). The health status of each agent is updated in the following way:\n\nAgents \\(R\\) stay \\(R\\).\nAgents \\(I\\) have probability \\(\\pi\\) to become \\(R\\). They stay \\(I\\) otherwise.\nAn agent of type \\(S\\) in position \\((x,y)\\) has a probability \\(prob(x,y,S)\\) to be infected that is \\(\\mu\\) if there is another infected agent within a radius \\(r>0\\).\n\nDefine a type Agent, which holds the type of an agent. The state of the whole system will be held in a Vector[Agent] type.\nWrite a function spatial_transition(S::Vector{Agent})::Vector{Agent} to compute the transition of the positions. Write another function random_guess(T=100) which simulates for \\(T\\) periods in order to find a good initial guess.\nWrite a function show_population to plot all agents with different colors for different health status.\nWrite a function evolve(S::Vector[Agent])::Vector[Agent] which takes the population in a given state and returns the same population with updated health status.\nWrite a function simulate(S0::Vector[Agent], k=1) to simulate the economy starting from an initially random position with k infected individuals. The returned object should be of type Vector[Vector[Agent]].\nCompute statistics along a simulated path for \\(n_I\\), \\(n_S\\), \\(n_R\\). Plot and compare with the basic SIR model\n\n\n\nHave fun by trying to answer one of these questions: - change probability of infection so that it depends on the number of infected people in the vincinity (with some suitable functional formulation for) - compute an animation of the transition - compute an interactive visualisation (with Interact.jl if available)"
  },
  {
    "objectID": "tutorials/2_solow_correction.html",
    "href": "tutorials/2_solow_correction.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "Convergence: Solow Model\n\nSolow Model\nA representative agent uses capital \\(k_t\\) to produce \\(y_t\\) using the following production function:\n\\[y_t = k_t^{\\alpha}\\]\nHe chooses to consume an amount \\(c_t \\in ]0, y_t]\\) and invests what remains:\n\\[i_t = y_t - c_t\\]\nHe accumulates capital \\(k_t\\) according to:\n\\[k_{t+1} = \\left( 1-\\delta \\right) k_{t} + i_{t}\\]\nwhere \\(\\delta\\) is the depreciation rate and \\(i_t\\) is the amount invested.\nThe goal of the representative agent is to maximize:\n\\[\\sum_{t\\geq 0} \\beta^t U(c_t)\\]\nwhere \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\beta<1\\) is the discount factor.\nFor now, we ignore the objective and assume that the saving rate \\(s=\\frac{c_t}{y_t}\\) is constant over time.\nCreate a NamedTuple to hold parameter values \\(\\beta=0.96\\), \\(\\delta=0.1\\), \\(\\alpha=0.3\\), \\(\\gamma=4\\).\n\np = (;β=0.96, δ=0.1, α=0.3, γ=4.0)\n\n(β = 0.96, δ = 0.1, α = 0.3, γ = 4.0)\n\n\nWrite down the formula of function \\(f\\) such that \\(k_{t+1}\\): \\(k_{t+1} = f(k_t)\\).\n\\[k_{t+1}= (1-\\delta) k_t + (1-s) k_t^{\\alpha}\\]\nDefine a function f(k::Float64, p::NamedTuple)::Float64 to represent \\(f\\) for a given calibration\n\n# function f(k::Float64, p::NamedTuple)\n\n# we added a keyword argument to specify the saving rate\nfunction f(k, p; s=0.2)\n\n    (;α, δ) = p # keyword unpacking syntax\n\n    val = k*(1-δ) + s*k^α\n\n    return val \nend\n\nf (generic function with 2 methods)\n\n\n\nf(0.1, p)\n\n0.1902374467254545\n\n\nWrite a function simulate(k0::Float64, T::Int, p::NamedTuple)::Vector{Float64} to compute the simulation over T periods starting from initial capital level k0.\n\nfunction simulate(k0, T, p; s=0.5)\n\n    sim = [k0]\n\n    for i ∈ 1:T    # same as for i in ... or for i=...\n        # in Julia, intervals contain the lower and upper bound\n        k1 = f(k0, p; s=s)\n\n        # add new value to simulation vector\n        push!(sim, k1)\n\n        k0 = k1\n    end\n\n    return sim\nend\n\nsimulate (generic function with 1 method)\n\n\n\nsim = simulate(0.5, 100, p;)\n\n101-element Vector{Float64}:\n 0.2\n 0.30340677254400195\n 0.4129080792968781\n 0.525003373019628\n 0.6373491155565568\n 0.7483344417178636\n 0.856841626057419\n 0.9620988898971137\n 1.0635841029776287\n 1.1609587708409257\n ⋮\n 2.6876186883735818\n 2.6879113388853018\n 2.6881835130861362\n 2.6884366430712516\n 2.6886720608576273\n 2.688891005366757\n 2.689094628921639\n 2.6892840032916374\n 2.6894601253165105\n\n\n\n# sometimes, we want to avoid using too much memory\n# in that case we try to do as many inplace operations as possible\n\nfunction simulate_preallocate(k, T, p; s=0.2)\n    v = zeros(T) # allocates memore\n    v[1] = k\n    for t = 1:(T-1)\n        k0 = v[t]\n        v[t+1] = f(k0, p; s=s)\n    end\n    return v\nend\n\nsimulate_preallocate (generic function with 1 method)\n\n\n\n@time simulate(0.2, 1000000, p);\n@time simulate_preallocate(0.2, 1000000, p);\n\n  0.067737 seconds (14 allocations: 9.781 MiB)\n  0.055613 seconds (2 allocations: 7.629 MiB)\n\n\nMake a nice plot to illustrate the convergence. Do we get convergence from any initial level of capital?\n\npl= plot(simulate(0.5, 100, p;); label=\"baseline\", title=\"Convergence of Solow Model\")\nplot!(pl, simulate(6.0, 100, p;); label=\"high initial capital\")\nplot!(pl, simulate(0.5, 100, p;s=0.2); label=\"lower saving rate\")\n\nSuppose you were interested in using f to compute the steady-state. What would you propose to measure convergence speed? To speed-up convergence? Implement these ideas.\n\nfunction steady_state(p; s=0.2)\n    sim = simulate(0.1, 1000, p)\n    return sim[end]\nend\n\nsteady_state (generic function with 1 method)\n\n\n\nsteady_state(p)\n\n2.691800385264708"
  },
  {
    "objectID": "tutorials/1_2_Epidemiology_correction.html",
    "href": "tutorials/1_2_Epidemiology_correction.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "H.W. Heathcote: epidemiologic models are deterministic models for infectious diseases which are spread by direct person-to-person contact in a population.\nThis kind of models has been used since by a few decades by economist, for matters that have nothing to do with health.\n\ndiffusion of information, or opinions on social medias\nasset prices and fads\nexpectation formation for macroeconomic outcomes (ex: The Epidemiology of Macroeconomic Expectations by Chris Carroll)\n\nEpidemiologic models have two features that depart from standard economic models:\n\nAgent’s behaviour does not take the full system into account, an is irrational in the sense that it isn’t forwards looking. Instead, an agent is given a behavioural heuristic.\nThe transitions of the whole system can be determined without solving for complex interactions first.\n\nUnderstanding why these two assumptions are very costly for economists will keep us busy during a big part of the course. Here we just consider two simple models as small programming exercises.\n\n\nThere is a continuum of agents of mass \\(1\\). Each agent can be either “Susceptible” (S), “Infected” (I) or “Recovered” (R). In each period, one agent meets another agent drawn randomly. During a meeting Susceptible agents who meet an infected agent, will always catch the disease (or the fad) but are not contagious. Infected agents, have a probability \\(\\pi\\) of being recovered. Nothing happens to Recovered agents who meet other people. No distinction is made between recovering as a healthy or a dead person.\nWe’re interested in the evolution in the number infected persons, both the speed of infection and the total amount of infected people in every period.\nWrite down the transition equations for \\(n_I\\), the number of infected people, for \\(n_R\\) the number of recovered people and \\(n_S\\) the number of susceptible people.\nCompute the transition function f for the vector state \\(s_t\\) returning \\(s_{t+1}\\).\nCompute the transitions over \\(T\\) periods. Plot the result using Plots.jl. (bonus: check against closed form solution)\nWe now assume a Susceptible person who meets an infected one has a probability \\(\\mu\\) of catching the disease. Update the transition function. Update function \\(f\\) and write a function of \\(\\mu\\), \\(\\pi\\) which returns the simulation. Compare different values of the parameters. How would you interpret “social distancing”? How would you choose parameters \\(\\Pi\\) and \\(\\mu\\)\n\n\n\nWe now consider another version of the model where agents evolve in the space \\(\\mathcal{S}=[0,1]\\times[0,1]\\). There are \\(N\\in\\mathbb{N}\\) agent. At any date, each agent \\(n \\in [0,1]\\) is located at \\((x_n,y_n)\\in \\mathcal{S}\\).\nEach agent moves follows a random walk bounded by \\(\\mathcal{S}\\): \\[x_t = \\min(\\max( x_{t-1} + \\epsilon_t, 0), 1)\\] \\[y_t = \\min(\\max( y_{t-1} + \\eta_t, 0), 1)\\] where \\(\\epsilon_t\\) and \\(\\eta_t\\) are both normally distributed with standard deviation \\(\\sigma\\).\nAt any date, the individual state of an agent is \\(s_t=(x_t, y_t, h_t)\\) where \\(h_t\\) is either “S”, “I” or “R”. \\(v_t\\) denotes the states of all agents (for instance \\(v_t=(s_{n,t})_n\\). The health status of each agent is updated in the following way:\n\nAgents \\(R\\) stay \\(R\\).\nAgents \\(I\\) have probability \\(\\pi\\) to become \\(R\\). They stay \\(I\\) otherwise.\nAn agent of type \\(S\\) in position \\((x,y)\\) has a probability \\(prob(x,y,S)\\) to be infected that is \\(\\mu\\) if there is another infected agent within a radius \\(r>0\\).\n\nDefine a type Agent, which holds the type of an agent. The state of the whole system will be held in a Vector[Agent] type.\n\nstruct Status\n    state::Int8\nend\n\nstruct Agent\n    x::Float64\n    y::Float64\n    status::Status\nend\n\nstruct Parameters\n    π::Float64\n    μ::Float64\n    σ::Float64\n    r::Float64\nend\n\n\np0 = Parameters(0.1, 0.1, 0.001, 0.1)\n\nParameters(0.1, 0.1, 0.001, 0.1)\n\n\n\nrand() # uniform between 0 and 1\n\n0.9645133907543597\n\n\n\nconst SUSCEPTIBLE = Status(0)\nconst INFECTED = Status(1)\nconst RECOVERED = Status(2)\n\nStatus(2)\n\n\n\nAgent(0.4, 0.2, INFECTED)\n\nAgent(0.4, 0.2, Status(1))\n\n\n\nAgent() = Agent(rand(), rand(), SUSCEPTIBLE)\n\nAgent\n\n\n\nimport Base: rand\n\n\nrand(::Type{Agent}) = Agent()\n\nrand (generic function with 82 methods)\n\n\n\nrand(Agent)\n\nAgent(0.12241393063082096, 0.009820745516522678, Status(0))\n\n\n\nAgent()\n\nAgent(0.04704558826258931, 0.5582242718714534, Status(0))\n\n\n\nN = 100\n\n100\n\n\n\npopulation = [Agent() for i=1:N]\n\n100-element Vector{Agent}:\n Agent(0.603474617660857, 0.04984181483460226, Status(0))\n Agent(0.5692517542408487, 0.4968235776556129, Status(0))\n Agent(0.8801593677800986, 0.21082627297869572, Status(0))\n Agent(0.6890219567821928, 0.7889357942851952, Status(0))\n Agent(0.7626365464770398, 0.6843585685767309, Status(0))\n Agent(0.608943597583597, 0.5003788557044796, Status(0))\n Agent(0.790167128396794, 0.35324161731764236, Status(0))\n Agent(0.10574309961267592, 0.13035959478004067, Status(0))\n Agent(0.639248323010488, 0.9310489780139874, Status(0))\n Agent(0.7975770467075609, 0.7176061106024042, Status(0))\n ⋮\n Agent(0.9086189632277857, 0.6411997710867648, Status(0))\n Agent(0.7629250832195819, 0.4149410225883555, Status(0))\n Agent(0.7684816918347468, 0.5317898079648127, Status(0))\n Agent(0.919114830226366, 0.27304980482411334, Status(0))\n Agent(0.8519677622187019, 0.4869021633645947, Status(0))\n Agent(0.11136045666318939, 0.6830924155620919, Status(0))\n Agent(0.8571207724822775, 0.9439303234682542, Status(0))\n Agent(0.5382649903605102, 0.7537829694495641, Status(0))\n Agent(0.9670532448525562, 0.7988378945702634, Status(0))\n\n\nWrite a function spatial_transition(S::Vector{Agent})::Vector{Agent} to compute the transition of the positions. Write another function random_guess(T=100) which simulates for \\(T\\) periods in order to find a good initial guess.\n\nfunction move(agent::Agent, p::Parameters)\n    x = agent.x + randn()*p.σ\n    y = agent.y + randn()*p.σ\n    return Agent(x, y, agent.status)\nend\n\nmove (generic function with 1 method)\n\n\n\ns = Agent()\n\nAgent(0.19109302144457063, 0.9972375327137523, Status(0))\n\n\n\nmove(s, p0)\n\nAgent(0.19140459573580712, 0.9985560158311684, Status(0))\n\n\n\nfunction spatial_transition(S::Vector{Agent}, p::Parameters)\n    out = [move(agent, p) for agent in S]\n    return out\nend\n\nspatial_transition (generic function with 1 method)\n\n\n\nspatial_transition(population, p0);\n\n\nfunction random_guess(p0, T=100, N=100)\n    population = [Agent() for n =1:N]\n    for t in 1:T\n        population = spatial_transition(population, p0)\n    end\n    return population\n    \nend\n\nrandom_guess (generic function with 3 methods)\n\n\n\nrandom_guess(p0)\n\n100-element Vector{Agent}:\n Agent(0.2976064486608136, 0.5784539646390013, Status(0))\n Agent(0.29763083333041257, 0.8425679924681841, Status(0))\n Agent(0.8916400971653442, 0.194460738386959, Status(0))\n Agent(0.4078025879854576, 1.0026092982646875, Status(0))\n Agent(0.8222643728515747, 0.8635643003337271, Status(0))\n Agent(0.557986697251115, 0.05677355700380427, Status(0))\n Agent(0.624994363104445, 0.8058887201857622, Status(0))\n Agent(0.9639917981338069, 0.03198111152540351, Status(0))\n Agent(0.26875685736220184, 0.23757018739610938, Status(0))\n Agent(0.5312074608062188, 0.9901156821302931, Status(0))\n ⋮\n Agent(0.7637196750232844, 0.2324507593082516, Status(0))\n Agent(0.6140989842838054, 0.49153521124236615, Status(0))\n Agent(0.12728164966963984, 0.7609489635537258, Status(0))\n Agent(0.9063144322011756, 0.2738246510859142, Status(0))\n Agent(0.9759053788780547, 0.8184258196689864, Status(0))\n Agent(0.3001853299414538, 0.21435262826928347, Status(0))\n Agent(0.3041065562385744, 0.05225009454092963, Status(0))\n Agent(0.7148178353125043, 0.45742636738594805, Status(0))\n Agent(0.7232529018259629, 0.23903652455520707, Status(0))\n\n\nWrite a function show_population to plot all agents with different colors for different health status.\n\nimport Plots: plot, plot!\n\n\nusing Plots # imports all functions that are \"exported\"\n\n\nplot(\n [a.x for a in population],\n [a.y for a in population];\n marker=\".\", seriestype=:scatter # should make lines invisible\n)\n\n┌ Warning: Skipped marker arg ..\n└ @ Plots /home/pablo/.julia/packages/Plots/FCUr0/src/args.jl:1224\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter(\n[a.x for a in population],\n[a.y for a in population]; marker=\".\", seriestype=:scatter # should make lines invisible\n)\n\n┌ Warning: Skipped marker arg ..\n└ @ Plots /home/pablo/.julia/packages/Plots/8K4be/src/args.jl:1230\n\n\n\n\n\n\nimport Plots: plot\n\n\nfunction plot(population::Vector{Agent})\n    pl = scatter(\n        [a.x for a in population],\n        [a.y for a in population]; marker=\".\", seriestype=:scatter # should make lines invisible\n    )\n    return pl\nend\n\nplot (generic function with 5 methods)\n\n\n\npop0 = random_guess(p0);\n\n\npl1 = plot(population)\npl2 = plot(pop0)\nplot(pl1, pl2)\n\n┌ Warning: Skipped marker arg ..\n└ @ Plots /home/pablo/.julia/packages/Plots/FCUr0/src/args.jl:1224\n┌ Warning: Skipped marker arg ..\n└ @ Plots /home/pablo/.julia/packages/Plots/FCUr0/src/args.jl:1224\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrite a function evolve(S::Vector[Agent])::Vector[Agent] which takes the population in a given state and returns the same population with updated health status.\n\nimport Base: -\n(-)(a1, a2) = Agent( a1.x-a2.x, a1.y - a2.y, a1.status)\n\n- (generic function with 277 methods)\n\n\n\nfunction distance(a1::Agent, a2::Agent) \n    d = a2-a1\n    sqrt( ((d).x)^2 + ((d).y)^2 )\nend\n\ndistance (generic function with 1 method)\n\n\n\ndistance(a1::Agent, a2::Agent) = begin d = a2-a1; sqrt( ((a2-a1).x)^2 + ((a2-a1).y)^2 ) end\n\ndistance (generic function with 1 method)\n\n\n\ndistance(Agent(), Agent())\n\n0.7510463976312519\n\n\n\nfunction evolve(S::Vector{Agent}, p::Parameters)\n    S = spatial_transition(S, p)\n    new_S = []\n    for (agent) in (S)\n        if agent.status == SUSCEPTIBLE\n            \n            risky_encounter = false\n            for (oagent) in (S)\n                    d = distance(agent, oagent)\n                    if (d<p.r) && (oagent.status == INFECTED)\n                        risky_encounter=true\n                        break\n                    end\n                break\n            end\n            \n            if risky_encounter\n                if rand() < p.μ\n                    new_agent = Agent(agent.x, agent.y, INFECTED)\n                else\n                    new_agent = agent\n                end\n            else\n                new_agent = agent\n            end\n            \n            \n        elseif agent.status == INFECTED\n            if rand() < p.π\n                new_agent = Agent(agent.x, agent.y, RECOVERED)\n            else\n                new_agent = agent\n            end\n        elseif agent.status == RECOVERED\n            new_agent = agent\n        end\n        \n        push!(new_S, new_agent)\n        \n    end\n    \n    return new_S\n    \nend\n\nevolve (generic function with 1 method)\n\n\n\ninfect(agent::Agent) = Agent(agent.x, agent.y, INFECTED)\n\ninfect (generic function with 1 method)\n\n\n\npop0[1] = infect(pop0[1])\n\nAgent(0.14398902534673688, 0.05952932502871551, Status(1))\n\n\n\nevolve(pop0, p0)\n\n100-element Vector{Any}:\n Agent(0.14443591008212647, 0.05973319651057636, Status(1))\n Agent(0.21391446312298745, 0.3431716231916697, Status(0))\n Agent(0.1313821247762785, 0.3733738724607018, Status(0))\n Agent(0.829487554150509, 0.7374014404077809, Status(0))\n Agent(0.18258910706447048, 0.12465025380744699, Status(0))\n Agent(0.33550908262118523, 0.8518606650608103, Status(0))\n Agent(0.06379645488594773, 0.508292158862834, Status(0))\n Agent(0.8275029549746096, 0.4894650328908453, Status(0))\n Agent(0.9619221744912682, 0.5823744241196236, Status(0))\n Agent(0.21757943870229296, 0.3058418297798114, Status(0))\n ⋮\n Agent(0.534384102884382, 0.8559941465050988, Status(0))\n Agent(0.3042231405607041, 0.14661669046195813, Status(0))\n Agent(0.76966652918973, 0.17548740727096868, Status(0))\n Agent(0.28041408456733286, 0.9318658472895824, Status(0))\n Agent(0.11113123658314303, 0.1586064285347957, Status(0))\n Agent(0.5643325416237239, 0.7518932089796421, Status(0))\n Agent(0.5406388076341186, 0.6880335168629441, Status(0))\n Agent(0.2482676045283046, 0.6215605641002976, Status(0))\n Agent(0.1686492249134962, 0.787400361611512, Status(0))\n\n\nWrite a function simulate(S0::Vector[Agent], k=1) to simulate the economy starting from an initially random position with k infected individuals. The returned object should be of type Vector[Vector[Agent]].\n\nfunction simulate(S0::Vector{Agent}, p::Parameters; T=1)\n    sim = [S0]\n    for t=1:T\n        pop = sim[end]\n        push!(sim, evolve(pop, p))\n    end\n    return sim\nend\n\nsimulate (generic function with 1 method)\n\n\n\nsim = simulate(pop0, p0; T=100)\n\n101-element Vector{Vector{Agent}}:\n [Agent(0.14398902534673688, 0.05952932502871551, Status(1)), Agent(0.2124018391497947, 0.3437524458344835, Status(0)), Agent(0.13086677181219225, 0.37280223522340816, Status(0)), Agent(0.8295148524188453, 0.7362148104558279, Status(0)), Agent(0.1827213766460102, 0.1248206543010004, Status(0)), Agent(0.3346321547696226, 0.852755785564367, Status(0)), Agent(0.06454574623725366, 0.5082540848095396, Status(0)), Agent(0.8270333722715933, 0.4896086495976404, Status(0)), Agent(0.9645119025258528, 0.5815205247675457, Status(0)), Agent(0.21759580890339664, 0.3069491282927926, Status(0))  …  Agent(0.32145427162414997, 0.28167912709610876, Status(0)), Agent(0.5353041230108323, 0.8554402985083074, Status(0)), Agent(0.3025957760944855, 0.14703134881851318, Status(0)), Agent(0.7685323119924398, 0.17632622180897486, Status(0)), Agent(0.2789629280164711, 0.9323492115020356, Status(0)), Agent(0.11163520540275197, 0.16042197379821738, Status(0)), Agent(0.5640745835346013, 0.7538807482931196, Status(0)), Agent(0.5422350442818089, 0.6885137868115678, Status(0)), Agent(0.2479121299161601, 0.6199914931312133, Status(0)), Agent(0.1683206400544488, 0.7864659293551597, Status(0))]\n [Agent(0.143045060213971, 0.058688404819301786, Status(1)), Agent(0.2123950478769078, 0.34351083143967226, Status(0)), Agent(0.1315540093860285, 0.37178829386910656, Status(0)), Agent(0.8275906406438384, 0.7365713823481104, Status(0)), Agent(0.18269542968326416, 0.1245256743063103, Status(0)), Agent(0.3335663950675765, 0.8514787465351259, Status(0)), Agent(0.06585548563884629, 0.5091882799569852, Status(0)), Agent(0.8269881268404957, 0.4896043448109561, Status(0)), Agent(0.9624051954880644, 0.583443788809633, Status(0)), Agent(0.21727876076206457, 0.3056027135879953, Status(0))  …  Agent(0.32135523073539213, 0.28190539658699476, Status(0)), Agent(0.5370773789205201, 0.853908469491312, Status(0)), Agent(0.30248322025026947, 0.1475329971516781, Status(0)), Agent(0.76827857046271, 0.17704889279976244, Status(0)), Agent(0.2772730442331317, 0.933343971849612, Status(0)), Agent(0.10995892414788352, 0.16026600081585132, Status(0)), Agent(0.5629320195279919, 0.7545332130073539, Status(0)), Agent(0.5414167504307332, 0.6910882160743447, Status(0)), Agent(0.2480317702335498, 0.6198972973639346, Status(0)), Agent(0.16856005948945396, 0.7851776600567484, Status(0))]\n [Agent(0.1448219912070159, 0.05867879862919474, Status(1)), Agent(0.21274818744889545, 0.34539619940446253, Status(0)), Agent(0.12979469803573987, 0.37304016039124327, Status(0)), Agent(0.8266216683848453, 0.7358243609255943, Status(0)), Agent(0.1822203685817205, 0.12215198030314965, Status(0)), Agent(0.3335271594970596, 0.8529362908962428, Status(0)), Agent(0.06846909768337506, 0.5084425824877334, Status(0)), Agent(0.8261586579314717, 0.4904030123276874, Status(0)), Agent(0.9616431773636904, 0.5821060403210396, Status(0)), Agent(0.2176688518392291, 0.3053409054714411, Status(0))  …  Agent(0.31948354627362674, 0.2810850965718394, Status(0)), Agent(0.5368521130411449, 0.8522717915416546, Status(0)), Agent(0.3026196084037437, 0.1473889801765504, Status(0)), Agent(0.7685435565706306, 0.1765641904190221, Status(0)), Agent(0.2792080588345354, 0.9321863445741666, Status(0)), Agent(0.11068936054169616, 0.16139150465287944, Status(0)), Agent(0.5633872494628905, 0.7547053059630611, Status(0)), Agent(0.5426481092970389, 0.6914416386116682, Status(0)), Agent(0.24738841554562346, 0.6208463722597348, Status(0)), Agent(0.16856735502534012, 0.7835335898014246, Status(0))]\n [Agent(0.14602629971016504, 0.05954975471961896, Status(2)), Agent(0.21252048523189965, 0.34627585802822947, Status(0)), Agent(0.13021560007940092, 0.3738286685044819, Status(0)), Agent(0.8262797581649076, 0.7361939847610962, Status(0)), Agent(0.1847937661076219, 0.12274175354484715, Status(0)), Agent(0.33219781167195783, 0.8519026168976197, Status(0)), Agent(0.06928398754334347, 0.5072250793045607, Status(0)), Agent(0.827278557040866, 0.4892617585158768, Status(0)), Agent(0.962235565327812, 0.5826907920008065, Status(0)), Agent(0.21748295061709713, 0.3053792871419847, Status(0))  …  Agent(0.3198418518163843, 0.28043303985273504, Status(0)), Agent(0.5375637889583335, 0.8509806189181333, Status(0)), Agent(0.3006214996147106, 0.14777795377482042, Status(0)), Agent(0.7670965870380725, 0.17563915720534837, Status(0)), Agent(0.2787908258647634, 0.9331182464736565, Status(0)), Agent(0.11094266114562787, 0.161764675192105, Status(0)), Agent(0.5621066659738954, 0.7550526128730787, Status(0)), Agent(0.5424310331341351, 0.6912924009149476, Status(0)), Agent(0.24595498685014575, 0.6194362426203994, Status(0)), Agent(0.16912037245307357, 0.7847975427522074, Status(0))]\n [Agent(0.1467674879343263, 0.05787951376372758, Status(2)), Agent(0.21159767860821543, 0.34608686709341907, Status(0)), Agent(0.12916559628784827, 0.37393987658495254, Status(0)), Agent(0.8277782363891356, 0.7346067591765312, Status(0)), Agent(0.18467652119304231, 0.12383810703720885, Status(0)), Agent(0.33228339624554254, 0.8533220484740406, Status(0)), Agent(0.07074970077549925, 0.5065513447279405, Status(0)), Agent(0.8287283723140452, 0.49082668353141246, Status(0)), Agent(0.9609701434474287, 0.5819045202267109, Status(0)), Agent(0.21608255266785148, 0.3049254570226026, Status(0))  …  Agent(0.3206041359087765, 0.27996315630898866, Status(0)), Agent(0.5373723648587754, 0.8501129279588091, Status(0)), Agent(0.3001144884653357, 0.1479139147014014, Status(0)), Agent(0.7643819400991371, 0.1773135348086444, Status(0)), Agent(0.27993138724124095, 0.9327461501135823, Status(0)), Agent(0.11034598833848988, 0.16137902784534053, Status(0)), Agent(0.563100050441279, 0.7545589329961775, Status(0)), Agent(0.5434190886734763, 0.6927834907285934, Status(0)), Agent(0.24644915839171652, 0.6208513390336553, Status(0)), Agent(0.17025766102936798, 0.7836489057412196, Status(0))]\n [Agent(0.14836792595570011, 0.057895492231217795, Status(2)), Agent(0.2107376108465143, 0.3471425898849841, Status(0)), Agent(0.12751791304883162, 0.3741470086015752, Status(0)), Agent(0.8295004648653994, 0.7344426266760594, Status(0)), Agent(0.18435579270454516, 0.12304053501631679, Status(0)), Agent(0.3321745188068356, 0.8539627825176953, Status(0)), Agent(0.07052365891188438, 0.5049118283358088, Status(0)), Agent(0.8298156260247881, 0.49146476832404623, Status(0)), Agent(0.9627104222106135, 0.5811060899346989, Status(0)), Agent(0.21665818343436002, 0.30443507091884464, Status(0))  …  Agent(0.3212050861874722, 0.28009342081046257, Status(0)), Agent(0.5380943782502404, 0.8485940248388955, Status(0)), Agent(0.29986694866130487, 0.14601894262351897, Status(0)), Agent(0.7647848234301434, 0.17890608705005423, Status(0)), Agent(0.2787237391948311, 0.9315182963524401, Status(0)), Agent(0.10926508554857994, 0.1608955931029933, Status(0)), Agent(0.5625575389383872, 0.7521569710317891, Status(0)), Agent(0.5428303290772912, 0.6921747929893204, Status(0)), Agent(0.24603272387830258, 0.6211076963309974, Status(0)), Agent(0.1696156903662015, 0.7830269051415584, Status(0))]\n [Agent(0.1475994076610492, 0.05728360702545383, Status(2)), Agent(0.2104025154616464, 0.3473648269878591, Status(0)), Agent(0.12952990148806384, 0.3729681968508524, Status(0)), Agent(0.8292217506288794, 0.7342504892749083, Status(0)), Agent(0.1842556687907271, 0.12305715364616406, Status(0)), Agent(0.3330736738669264, 0.8535859896532277, Status(0)), Agent(0.07050723884138584, 0.505516938961337, Status(0)), Agent(0.8293130853787644, 0.49216813729517817, Status(0)), Agent(0.9627348821880611, 0.5799291638059758, Status(0)), Agent(0.21689420456751016, 0.3060084314898251, Status(0))  …  Agent(0.32141538664074304, 0.2802464157212028, Status(0)), Agent(0.5398313202831649, 0.8487315796501279, Status(0)), Agent(0.3002200676794857, 0.14720302686906092, Status(0)), Agent(0.7634962771346817, 0.17775284424998875, Status(0)), Agent(0.2779054430859544, 0.9309702449422853, Status(0)), Agent(0.10835065410158747, 0.1613106312089081, Status(0)), Agent(0.5608151521627879, 0.7517600865701674, Status(0)), Agent(0.5442700177942152, 0.6929394059511046, Status(0)), Agent(0.2463009967673587, 0.6220280841182976, Status(0)), Agent(0.16988704151960257, 0.7832199979927832, Status(0))]\n [Agent(0.1490022807451637, 0.05791517737975388, Status(2)), Agent(0.20987860522030086, 0.34770370931593214, Status(0)), Agent(0.1306927785845246, 0.3746076297303853, Status(0)), Agent(0.8284899163920655, 0.7341593543224819, Status(0)), Agent(0.1839804903937941, 0.12395774931287762, Status(0)), Agent(0.3331557066973869, 0.8527253646887559, Status(0)), Agent(0.06842502357998917, 0.5039675423196223, Status(0)), Agent(0.8289111588153537, 0.49251456421396733, Status(0)), Agent(0.9635147231583103, 0.5802635209713861, Status(0)), Agent(0.21623013861323045, 0.30800134900322984, Status(0))  …  Agent(0.32162127653968753, 0.2809486365929742, Status(0)), Agent(0.5385255897664146, 0.8488437109311187, Status(0)), Agent(0.29985736509482136, 0.14821707032423287, Status(0)), Agent(0.7647640154641339, 0.17756837908967238, Status(0)), Agent(0.2775133280946522, 0.9293772475220201, Status(0)), Agent(0.10778700011196626, 0.16240609476623483, Status(0)), Agent(0.5623421178500068, 0.7518900783768837, Status(0)), Agent(0.5453580414291451, 0.692480905427414, Status(0)), Agent(0.24842766352518492, 0.622714942364725, Status(0)), Agent(0.16924662596273596, 0.7826517889394818, Status(0))]\n [Agent(0.14907527381602032, 0.05922602289249182, Status(2)), Agent(0.20795275962783374, 0.3461067233442315, Status(0)), Agent(0.13097606415235313, 0.3760575979849254, Status(0)), Agent(0.8279617800188728, 0.732912793523332, Status(0)), Agent(0.1838099005351841, 0.12516731352788904, Status(0)), Agent(0.33334559817263204, 0.8506845115449738, Status(0)), Agent(0.06720779937902831, 0.5042079607087947, Status(0)), Agent(0.8294741410235003, 0.4918244082465365, Status(0)), Agent(0.9657124999174259, 0.5807871721837397, Status(0)), Agent(0.2158784247038485, 0.30648630242576147, Status(0))  …  Agent(0.3217950384999007, 0.2813239903376273, Status(0)), Agent(0.5400037117475194, 0.8516928752606392, Status(0)), Agent(0.2995029134720776, 0.14780947762074753, Status(0)), Agent(0.764773698433959, 0.1790045117744854, Status(0)), Agent(0.2783258944247565, 0.9291828205937115, Status(0)), Agent(0.1081660666447461, 0.1646518471603538, Status(0)), Agent(0.5625152130783297, 0.7511264308205503, Status(0)), Agent(0.544401432655885, 0.6921327217263246, Status(0)), Agent(0.24829791463310233, 0.6248202963975766, Status(0)), Agent(0.16963078234424506, 0.7820301692171705, Status(0))]\n [Agent(0.14868370757479726, 0.058713987927299864, Status(2)), Agent(0.20715405501319897, 0.3454971903954492, Status(0)), Agent(0.1301298461665389, 0.37483983934617826, Status(0)), Agent(0.8284329579470497, 0.7330722238817932, Status(0)), Agent(0.1841045336837907, 0.12594500290189925, Status(0)), Agent(0.3324247027074761, 0.8518341417775053, Status(0)), Agent(0.06775980620500222, 0.5039470853633436, Status(0)), Agent(0.8309428681981802, 0.49176799068086846, Status(0)), Agent(0.9648740007501508, 0.5814672864854213, Status(0)), Agent(0.2156546021631534, 0.3081664116214254, Status(0))  …  Agent(0.3230170184526541, 0.2818397528297411, Status(0)), Agent(0.5401427971670486, 0.8507082658040974, Status(0)), Agent(0.29875812028300214, 0.14745326124530517, Status(0)), Agent(0.7654207337791954, 0.17910018897024535, Status(0)), Agent(0.27717364779304793, 0.9289486441270466, Status(0)), Agent(0.10725911693914743, 0.16525429943521905, Status(0)), Agent(0.5641773711364991, 0.7491201674342084, Status(0)), Agent(0.5444221213664742, 0.6918178223553145, Status(0)), Agent(0.24820569828196706, 0.624031030623186, Status(0)), Agent(0.17062633604284583, 0.783610512940736, Status(0))]\n ⋮\n [Agent(0.13055834463811783, 0.056591768728180364, Status(2)), Agent(0.20879879502340107, 0.35399624948193825, Status(0)), Agent(0.13341203188204906, 0.38313538889683674, Status(0)), Agent(0.8336276007319982, 0.7370564213320647, Status(0)), Agent(0.19171637211228199, 0.1269235460364859, Status(0)), Agent(0.3268247851214068, 0.8607543883601179, Status(0)), Agent(0.06778213670985675, 0.5202351514180652, Status(0)), Agent(0.8231042556928145, 0.4856994171029608, Status(0)), Agent(0.9605015116290513, 0.572746333317641, Status(0)), Agent(0.22724945171725444, 0.31228169363892705, Status(0))  …  Agent(0.3289544498424584, 0.2799508258483283, Status(0)), Agent(0.5441738577388013, 0.8494436665985611, Status(0)), Agent(0.31889383304173036, 0.15099951645919069, Status(0)), Agent(0.7636148315678957, 0.19375820673526375, Status(0)), Agent(0.2813298247205795, 0.9131741522851832, Status(0)), Agent(0.1085536851883608, 0.15673661070406084, Status(0)), Agent(0.569048015487158, 0.7468211476224087, Status(0)), Agent(0.5412380284537309, 0.693703931741484, Status(0)), Agent(0.2511730103548943, 0.6138095969558385, Status(0)), Agent(0.1575626978973379, 0.7822602190980198, Status(0))]\n [Agent(0.13086318011768486, 0.05666680435880787, Status(2)), Agent(0.20862320632952758, 0.35579390933324334, Status(0)), Agent(0.13287764246626377, 0.38232873751968816, Status(0)), Agent(0.8343798912550437, 0.7374566226860206, Status(0)), Agent(0.1914360920269415, 0.1293608915102816, Status(0)), Agent(0.3263085592123911, 0.8630595990786737, Status(0)), Agent(0.06732696922279152, 0.5207979838275122, Status(0)), Agent(0.8227354546845032, 0.48754121695418445, Status(0)), Agent(0.9603642707562585, 0.5736168580491973, Status(0)), Agent(0.2280816857736658, 0.3124444513733611, Status(0))  …  Agent(0.3303183306532563, 0.2811695297235067, Status(0)), Agent(0.5436110536448934, 0.8481009097977087, Status(0)), Agent(0.31807669725656684, 0.15284666460948967, Status(0)), Agent(0.7641465001613482, 0.19602805475939625, Status(0)), Agent(0.2810583150051764, 0.9136489650483535, Status(0)), Agent(0.10974175146280774, 0.15623309967003488, Status(0)), Agent(0.5697944420732809, 0.7479749545056819, Status(0)), Agent(0.5411708762353382, 0.694717637162357, Status(0)), Agent(0.24988570859159168, 0.6142908031679762, Status(0)), Agent(0.15700511326193167, 0.7821887831548962, Status(0))]\n [Agent(0.13232649419708184, 0.059567633084835384, Status(2)), Agent(0.21008927934479232, 0.35633338552658034, Status(0)), Agent(0.13294420537847587, 0.3825628442506681, Status(0)), Agent(0.8339170721689473, 0.7365112331312726, Status(0)), Agent(0.19065518017200359, 0.13121489077158793, Status(0)), Agent(0.3254285196350085, 0.8619986765285171, Status(0)), Agent(0.06882616065002864, 0.5198678032398929, Status(0)), Agent(0.8228041149779081, 0.4879823179877786, Status(0)), Agent(0.9611743513013874, 0.5719965775608895, Status(0)), Agent(0.22703523139032245, 0.3143983465963539, Status(0))  …  Agent(0.3286452403931677, 0.28027927844603745, Status(0)), Agent(0.5448220850485361, 0.8488496218828075, Status(0)), Agent(0.31860342967094224, 0.15263832609953487, Status(0)), Agent(0.7655783227331134, 0.19648731892997937, Status(0)), Agent(0.28009069943111153, 0.9135951148902414, Status(0)), Agent(0.11003078797912488, 0.15573656690007448, Status(0)), Agent(0.568910142120768, 0.7469060939696542, Status(0)), Agent(0.5423074910626076, 0.6934335846386123, Status(0)), Agent(0.25073590986870353, 0.6118700877554972, Status(0)), Agent(0.1562138310417973, 0.7836988856996623, Status(0))]\n [Agent(0.13128305449191807, 0.05891846810071485, Status(2)), Agent(0.21208957489191085, 0.35526581278362945, Status(0)), Agent(0.13139976948552728, 0.38257383839553377, Status(0)), Agent(0.8356669498059948, 0.7366839937424365, Status(0)), Agent(0.18994309832556677, 0.13182202288817335, Status(0)), Agent(0.3264384196964382, 0.8631667757323216, Status(0)), Agent(0.06800666313860942, 0.519815309174606, Status(0)), Agent(0.8222053627135082, 0.4897533931210209, Status(0)), Agent(0.9618999926945627, 0.5696404681583397, Status(0)), Agent(0.22520640269347336, 0.3149111025836889, Status(0))  …  Agent(0.32937327154590335, 0.2798131787053247, Status(0)), Agent(0.5454785842737968, 0.8488212512405308, Status(0)), Agent(0.3198223860828435, 0.15328550270677704, Status(0)), Agent(0.7653379557429215, 0.19658705771394644, Status(0)), Agent(0.2805637688871705, 0.915706415169843, Status(0)), Agent(0.10925187788530534, 0.15414071551992042, Status(0)), Agent(0.570585593493937, 0.7470603417662173, Status(0)), Agent(0.5405189914813026, 0.6929976572072666, Status(0)), Agent(0.25077199428230773, 0.6124875863722867, Status(0)), Agent(0.15551163025590192, 0.7844818209237557, Status(0))]\n [Agent(0.13121805082847765, 0.059942789913600594, Status(2)), Agent(0.21169672317258773, 0.3552207950849555, Status(0)), Agent(0.12999094031464695, 0.38338120766182926, Status(0)), Agent(0.8351246077129206, 0.7357892733077984, Status(0)), Agent(0.1908638577708027, 0.13318177671861076, Status(0)), Agent(0.32610553163922434, 0.8625977577896461, Status(0)), Agent(0.06851854913374407, 0.5196779687687463, Status(0)), Agent(0.8243056837961031, 0.49007998137548064, Status(0)), Agent(0.9636807874403033, 0.5717393125718165, Status(0)), Agent(0.22709861046864235, 0.31588029824601505, Status(0))  …  Agent(0.33194557930851215, 0.27973204948846664, Status(0)), Agent(0.5457492087917173, 0.8487079439091403, Status(0)), Agent(0.3200162333413769, 0.15322512360356882, Status(0)), Agent(0.7661314816556029, 0.1957770954044427, Status(0)), Agent(0.2807109371984848, 0.9141972795912511, Status(0)), Agent(0.11080679265804462, 0.15526414820423848, Status(0)), Agent(0.5703158990474189, 0.7473734656512827, Status(0)), Agent(0.5415494030915858, 0.6944796528814412, Status(0)), Agent(0.24976768640817917, 0.6131986865822429, Status(0)), Agent(0.15477759859597107, 0.7841389352483211, Status(0))]\n [Agent(0.13285328862775944, 0.060676639903640535, Status(2)), Agent(0.21059472043725358, 0.35444360801053504, Status(0)), Agent(0.1298386826385244, 0.3830446185143596, Status(0)), Agent(0.8342670987830854, 0.7372521553527286, Status(0)), Agent(0.19169870978243592, 0.1321728745379897, Status(0)), Agent(0.3245055150975167, 0.8635568170966671, Status(0)), Agent(0.0691561544589401, 0.5210591382405036, Status(0)), Agent(0.8247226438713066, 0.4888110466591789, Status(0)), Agent(0.9647474747421523, 0.5706698132410486, Status(0)), Agent(0.2273111613761904, 0.3145150225098271, Status(0))  …  Agent(0.33149081143943515, 0.27927350591496863, Status(0)), Agent(0.5463372965728185, 0.8486284801182519, Status(0)), Agent(0.3195782048477128, 0.15309132092799785, Status(0)), Agent(0.7665494617745843, 0.1958430761672314, Status(0)), Agent(0.281474061742277, 0.9153892793660274, Status(0)), Agent(0.11216526770899309, 0.15617429268818142, Status(0)), Agent(0.5683242677618796, 0.747928296718188, Status(0)), Agent(0.5418768804801095, 0.6935054899194122, Status(0)), Agent(0.25052742466511074, 0.6146188480241206, Status(0)), Agent(0.15274011061909487, 0.7855715874607034, Status(0))]\n [Agent(0.13323123247032764, 0.06230489533372291, Status(2)), Agent(0.2109256394366175, 0.3565782868940742, Status(0)), Agent(0.12938370597433063, 0.38362146641252376, Status(0)), Agent(0.8341779074209241, 0.7365656739865165, Status(0)), Agent(0.1926626589736719, 0.1323892048503349, Status(0)), Agent(0.32505037803204523, 0.864651859510107, Status(0)), Agent(0.06818826996239553, 0.52120507697346, Status(0)), Agent(0.8240727642265282, 0.48924462840285515, Status(0)), Agent(0.9633163220558025, 0.5702350303480331, Status(0)), Agent(0.22531268154066986, 0.31532249537959484, Status(0))  …  Agent(0.3309531990374097, 0.2795653407977885, Status(0)), Agent(0.5481056892058324, 0.8472801024354653, Status(0)), Agent(0.3199454963112084, 0.15257324829745955, Status(0)), Agent(0.7653201552668992, 0.19489253846962262, Status(0)), Agent(0.28140130068580765, 0.9158833534792594, Status(0)), Agent(0.11293949832520128, 0.15687945533124917, Status(0)), Agent(0.5680744651873341, 0.7487957757719471, Status(0)), Agent(0.5427953540893695, 0.6924638156860259, Status(0)), Agent(0.2506560193754757, 0.6158958536442286, Status(0)), Agent(0.1520319875310294, 0.7878051914448337, Status(0))]\n [Agent(0.13403793938670516, 0.06198244837464722, Status(2)), Agent(0.2121901007882736, 0.35680902379226537, Status(0)), Agent(0.13082322864291557, 0.38362362175578907, Status(0)), Agent(0.8319678419435894, 0.7371778787304523, Status(0)), Agent(0.1933802084796915, 0.13368689760484173, Status(0)), Agent(0.3246221577439305, 0.863973598995827, Status(0)), Agent(0.0690651463204628, 0.51995020183789, Status(0)), Agent(0.8242017577813284, 0.49062438836856165, Status(0)), Agent(0.9628241386557235, 0.5707560982395148, Status(0)), Agent(0.22466623620361278, 0.3164943273668668, Status(0))  …  Agent(0.33161220146657466, 0.2788953042728017, Status(0)), Agent(0.5474765614129273, 0.8453767572875155, Status(0)), Agent(0.320022669123569, 0.15158225615453916, Status(0)), Agent(0.7657974216071975, 0.1955028829780989, Status(0)), Agent(0.2810015055084629, 0.9148123875402071, Status(0)), Agent(0.11253929593565648, 0.15785883803145537, Status(0)), Agent(0.5698468771797808, 0.7507579516171016, Status(0)), Agent(0.541893593962732, 0.6926371847908654, Status(0)), Agent(0.25215050436690617, 0.616633434802053, Status(0)), Agent(0.15188135860841398, 0.787339206983939, Status(0))]\n [Agent(0.13452616842692278, 0.06203815712264374, Status(2)), Agent(0.21262381907655376, 0.35694008014176304, Status(0)), Agent(0.13148005334457, 0.3825624031913727, Status(0)), Agent(0.8316778725024127, 0.7337412764501786, Status(0)), Agent(0.19173829521987615, 0.1331132815251592, Status(0)), Agent(0.3270773937089955, 0.8645595746223924, Status(0)), Agent(0.06838108630216937, 0.5197491029956008, Status(0)), Agent(0.8236461542812904, 0.49306577202149343, Status(0)), Agent(0.961671889072684, 0.5728610122793977, Status(0)), Agent(0.2255424913214682, 0.31657932278505874, Status(0))  …  Agent(0.33176086298575475, 0.2773836856872243, Status(0)), Agent(0.5467781477900276, 0.84489303161457, Status(0)), Agent(0.31909057143810726, 0.15276946279222062, Status(0)), Agent(0.7671165423448445, 0.19353612628369662, Status(0)), Agent(0.28055431753689564, 0.9135651705208242, Status(0)), Agent(0.11210569380970377, 0.1597854607506177, Status(0)), Agent(0.5700530102483936, 0.7491240866917991, Status(0)), Agent(0.5426132570861103, 0.6926103107007051, Status(0)), Agent(0.2523970570595777, 0.6174336350074853, Status(0)), Agent(0.15128829169060806, 0.7884680181652349, Status(0))]\n\n\nCompute statistics along a simulated path for \\(n_I\\), \\(n_S\\), \\(n_R\\). Plot and compare with the basic SIR model\n\ncount(pop::Vector{Agent}, state) = sum(a.status==state for a in pop)\n\ncount (generic function with 1 method)\n\n\n\ncount(pop0, SUSCEPTIBLE)\ncount(pop0, SUSCEPTIBLE)\n\n99\n\n\n\np0.\n\nErrorException: syntax: incomplete: premature end of input\n\n\n\nParameters( )\n\nParameters\n\n\n\np0 = Parameters(0.5, 0.5, 0.1, 0.5)\n\n\nParameters(0.5, 0.5, 0.1, 0.5)\n\n\n\n\npop0 = [(  i<500 ? Agent() : Agent(rand(), rand(),INFECTED))  for i=1:1000]\n\n1000-element Vector{Agent}:\n Agent(0.34601881483822994, 0.4833601843652213, Status(0))\n Agent(0.31871272453786015, 0.5227179829696845, Status(0))\n Agent(0.40497775771527744, 0.42728672976027526, Status(0))\n Agent(0.39281924909063404, 0.5462989133830746, Status(0))\n Agent(0.8791346554511515, 0.07112433718776112, Status(0))\n Agent(0.33821912271807497, 0.6530759309596189, Status(0))\n Agent(0.02011787161960521, 0.9245434941230084, Status(0))\n Agent(0.06917495257137729, 0.8086018393407772, Status(0))\n Agent(0.5168215737273881, 0.9527479765632932, Status(0))\n Agent(0.7172381447406931, 0.4684780188160621, Status(0))\n ⋮\n Agent(0.7673487108840666, 0.7760552875935144, Status(1))\n Agent(0.5612292591999373, 0.16270509894676477, Status(1))\n Agent(0.166345546162893, 0.9702601622966601, Status(1))\n Agent(0.46495756132573607, 0.36372401842244917, Status(1))\n Agent(0.9186814802176809, 0.3822277278220495, Status(1))\n Agent(0.4752041344027216, 0.8191230363590178, Status(1))\n Agent(0.6026340900048122, 0.005039448929130774, Status(1))\n Agent(0.010134071464535821, 0.814845640795315, Status(1))\n Agent(0.26362881063872246, 0.04032720776489529, Status(1))\n\n\n\nsim = simulate(pop0, p0; T=100);\n\n\nsim_n_S = [count(pop, SUSCEPTIBLE) for pop in sim]\nsim_n_I = [count(pop, INFECTED) for pop in sim]\nsim_n_R = [count(pop, RECOVERED) for pop in sim]\n\n101-element Vector{Int64}:\n   0\n 247\n 369\n 436\n 467\n 489\n 495\n 498\n 499\n 500\n   ⋮\n 501\n 501\n 501\n 501\n 501\n 501\n 501\n 501\n 501\n\n\n\npl = plot(sim_n_S, label=\"Susceptible\")\nplot!(pl, sim_n_I, label=\"Infected\")\nplot!(pl, sim_n_R, label=\"Recovered\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHave fun by trying to answer one of these questions: - change probability of infection so that it depends on the number of infected people in the vincinity (with some suitable functional formulation for) - compute an animation of the transition - compute an interactive visualisation (with Interact.jl if available)"
  },
  {
    "objectID": "tutorials/1_1_Julia_Basics.html",
    "href": "tutorials/1_1_Julia_Basics.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "developped at MIT on top of opensource technologies\n\nlinux / git / llvm\n\nsyntax inspired by Matlab but:\n\nmore consistent\nlots of features from high level languages\n\neverything is JIT-compiled\n\ninterpreted vs compiled treadeoff\n-> very fast\nmost of the base library is written in Julia\n\nopensource/free + vibrant community\n\nSome useful links from QuantEcon:\n\nJulia cheatsheet\nJulia-Matlab comparison\nJulia essentials\nVectors, arrays and matrices\n\nExcellent resources at: julialang - checkout JuliaAcademy, it’s free\n\n\n\nHow I learnt: interpreted code is slow, so vectorize your coe.\n\nfunction stupid_loop(I,J,K)\n    t = 0.0\n    for i=1:I\n        for j=1:J\n            for k = 1:K\n                t += 1.0\n            end        \n        end\n    end\n    return t\nend\n@time [ stupid_loop(1000,1000,i) for i =1:10]\n\nCode is translated to LLVM code then to instructions for the processor. Note that processor instructions are shorter than LLVM code.\n\n@code_llvm stupid_loop(10,10,10)\n\n\n@code_native stupid_loop(10,10,10)\n\n\n\n\n\n\nAssignement operator is = (equality is ==, identity is ===)\n\n# Assign the value 10 to the variable x\nx = 10\n\n\n2 == 3\n\n\n# Variable names can have Unicode characters\n# To get ϵ in the REPL, type \\epsilon<TAB>\nϵ = 1e-4\n\nDefault semantic is pass-by-reference:\n\na = [1,2,3,4]\nb = a\na[1] = 10\nb\n\nTo work on a copy: copy or deepcopy\n\na = [1,2,3,4]\nb = copy(a)\na[1]=10\nb\n\n\na .== b\n\n\na === b\n\n\n\n\n\n# for any object `typeof` returns the type\n?typeof\n\n\ntypeof(a)\n\n\n\n\n\ny = 2 + 2\n\n\n-y\n\n\n0.34*23\n\n\n3/4\n\n\n# Scalar multiplication doesn't require *\n3(4 - 2)\n\n\nx = 4\n2x\n\n\ntypeof(x)\n\n\nsizeof(a)\n\n\n\n\nEquality\n\n0 == 1\n\n\n2 != 3\n\n\n3 <= 4\n\nIdentity\n\na = [34, 35]\nb = [34, 35]\nc = a\n\n\nc === a\n\n\nb === a\n\nBoolean operator\n\ntrue && false\n\n\ntrue || false\n\n\n!true\n\n\n\n\n\n# Strings are written using double quotes\nstr = \"This is a string\"\n\n\nch = 'k' # this is a character\n\n\n# Strings can also contain Unicode characters\nfancy_str = \"α is a string\"\n\n\n# String interpolation using $\n# The expression in parentheses is evaluated and the result is \n# inserted into the string\na = 2+2\n\"2 + 2 = $(a)\"\n\n\nprintln(\"It took me $(a) iterations\")\n\n\n# String concatenation using *\n\"hello\" * \"world\"\n\n\nprintln(\"hello \", \"world\")\n\n\n\n\nJulia has one-dimensional arrays. They are also called Vector.\n\nA = [1, 2]\n\n2-element Array{Int64,1}:\n 1\n 2\n\n\n\nsizeof(A)\n\n16\n\n\n\ntypeof(A) == Vector{Int64}\n\n\n# vectors have one dimension: they are indexed by an integer\nA[1]\n\n1\n\n\n2d arrays are also called matrices… and can be used for matrix multiplications.\n\nB = [0.1 0.2 0.3; 4 5 6]\n\n2×3 Array{Float64,2}:\n 0.1  0.2  0.3\n 4.0  5.0  6.0\n\n\n\nB*B'\n\n2×2 Array{Float64,2}:\n 0.14   3.2\n 3.2   77.0\n\n\nVectorized operations take a ., even comparisons:\n\nB.*B\n\n2×3 Array{Float64,2}:\n  0.01   0.04   0.09\n 16.0   25.0   36.0\n\n\n\nB .* B .< B\n\n2×3 BitArray{2}:\n 1  1  1\n 0  0  0\n\n\nElements are always accessed with square brackets:\n\nB[1,2]\n\n0.2\n\n\n\nB[:,1]\n\n2-element Array{Float64,1}:\n 0.1\n 4.0\n\n\n\nB[:,1:end-1]\n\n2×2 Array{Float64,2}:\n 0.1  0.2\n 4.0  5.0\n\n\n\n\n\nConditions\n\nx = -3\nif x < 0\n    println(\"x is negative\")\nelseif x > 0 # optional and unlimited\n    println(\"x is positive\")\nelse         # optional\n    println(\"x is zero\")\nend\n\nx is negative\n\n\n\nprint(\"a\")\nprint(\"b\")\nprint(\"c\")\n\nabc\n\n\n\nprintln(\"a\")\nprintln(\"b\")\nprintln(\"c\")\n\na\nb\nc\n\n\nWhile\n\ni = 3\nwhile i > 0\n    println(i)\n    i = i - 1\nend\n\n3\n2\n1\n\n\nFor loops\n\n# Iterate through ranges of numbers\nfor i = 1:3\n    println(i)\n    \n    if i == 2\n        break\n    end\nend\n\n1\n2\n\n\n\n# Iterate through arrays\ncities = [\"Boston\", \"New York\", \"Philadelphia\"]\nfor city in cities\n    println(city)\nend\n\nBoston\nNew York\nPhiladelphia\n\n\n\nstates = [\"MA\", \"NY\", \"PA\"]\n\n3-element Array{String,1}:\n \"MA\"\n \"NY\"\n \"PA\"\n\n\n\n( zip(cities, states) )\n\nzip([\"Boston\", \"New York\", \"Philadelphia\"], [\"MA\", \"NY\", \"PA\"])\n\n\n\ncollect( zip(cities, states) )\n\n3-element Array{Tuple{String,String},1}:\n (\"Boston\", \"MA\")\n (\"New York\", \"NY\")\n (\"Philadelphia\", \"PA\")\n\n\n\nfor t in zip(cities, states)\n    println(t)\nend\n\n(\"Boston\", \"MA\")\n(\"New York\", \"NY\")\n(\"Philadelphia\", \"PA\")\n\n\n\n# Iterate through arrays of tuples using zip\nfor (city, state) in zip(cities, states)\n    println(\"$city, $state\")\nend\n\nBoston, MA\nNew York, NY\nPhiladelphia, PA\n\n\n\n# Iterate through arrays and their indices using enumerate\nfor (i, city) in enumerate(cities)\n    println(\"City number $i is $city\")\nend\n\nCity number 1 is Boston\nCity number 2 is New York\nCity number 3 is Philadelphia\n\n\n\n\n\n\n[i^2 for i=1:10]\n\n10-element Array{Int64,1}:\n   1\n   4\n   9\n  16\n  25\n  36\n  49\n  64\n  81\n 100\n\n\n\n[i^2 for i=1:10 if mod(i,2)==0]\n\n5-element Array{Int64,1}:\n   4\n  16\n  36\n  64\n 100\n\n\n\n\n\n\n\nBasic functions\n\nfunction f(a,b,c)\n    res = a + b +c\n    return res\nend\n\nf (generic function with 1 method)\n\n\n\nf(3,4,3)\n\n10\n\n\nOptional arguments\n\nfunction f(a,b,c=1)\n    res = a + b +c\n    return res\nend\n\nf (generic function with 2 methods)\n\n\n\nf(1,2,3)\n\n6\n\n\n\nf(1,2)\n\n4\n\n\nKeyword arguments\n\nfunction g(a,b,c; operator=(+), add_one=false)\n    res = operator(a, operator( b , c) )\n    if add_one\n        res +=1\n    end\n    return res\nend\n\ng (generic function with 1 method)\n\n\n\ng(1,2,3)\n\n6\n\n\n\ng(1.0,2.9,3.0; operator=(/))\n\n1.0344827586206897\n\n\n\ng(1.0,2.9,3.0; operator=(/), add_one=true)\n\n2.0344827586206895\n\n\n\ng(1.0,2.9,3.0; add_one=true, operator=(/), )\n\n2.0344827586206895\n\n\nOne liners:\n\ng(x,y) = x^2 + y^2\n\ng (generic function with 2 methods)\n\n\nAnonymous function:\n\nfun = (x,y) -> x^2 + 1 + y\n\n#12 (generic function with 1 method)\n\n\n\nf(1,2,3; operator=fun)\n\n10\n\n\n\n\n\n\nA composite type is a collection of named fields that can be treated as a single value. They bear a passing resemblance to MATLAB structs.\nAll fields must be declared ahead of time. The double colon, ::, constrains a field to contain values of a certain type. This is optional for any field.\n\nstruct Parameter_without_types\n    value\n    name\nend\n\n\ns = Parameter_without_types(4.4, \"no type at all\")\n\nParameter_without_types(4.4, \"no type at all\")\n\n\n\n# Type definition\nstruct Parameter\n    value::Float64\n    transformation::Function # Function is a type!\n    tex_label::String\n    description::String\nend\n\n\nParameter(4,fun,\"\\\\Gamma\", \"My parameter\")\n\nParameter(4.0, var\"#12#13\"(), \"\\\\Gamma\", \"My parameter\")\n\n\nWhen a type with \\(n\\) fields is defined, a constructor (function that creates an instance of that type) that takes \\(n\\) ordered arguments is automatically created. Additional constructors can be defined for convenience.\n\n# Creating an instance of the Parameter type using the default\n# constructor\nβ = Parameter(0.9, identity, \"\\beta\", \"Discount rate\")\n\nParameter(0.9, identity, \"\\beta\", \"Discount rate\")\n\n\n\nβ.value\n\n0.9\n\n\n\nParameter(value, transformation, tex) = Parameter(value, transformation, tex, \"no description\")\n\nParameter\n\n\n\nParameter(0.34, identity, \"\\beta\")\n\nParameter(0.34, identity, \"\\beta\", \"no description\")\n\n\n\n# constructor A\nParameter(value, tex) = Parameter(value, identity, tex, \"no description\")\n\nParameter\n\n\n\nParameter(0.1, \"\\beta\")\n\nParameter(0.1, identity, \"\\beta\", \"no description\")\n\n\n\n# constructor B\nParameter(value, transformation)  = Parameter(value, transformation, \"notex\", \"no description\")\n\nParameter\n\n\n\nParameter(0.1, \"\\beta\")\n\nLoadError: MethodError: \u001b[0mCannot `convert` an object of type \u001b[92mString\u001b[39m\u001b[0m to an object of type \u001b[91mFunction\u001b[39m\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at essentials.jl:205\n\n\n\n# here Julia doesn't know whether it should call constructor A or constructor B\n\n\n# solution : give different signatures to the various constructors\nParameter(value, tex::String)               = Parameter(value, identity, tex, \"no description\")\nParameter(value, transformation::Function)  = Parameter(value, transformation, \"notex\", \"no description\")\n\nParameter\n\n\n\nParameter(0.5, \"\\beta\")\n\nParameter(0.5, identity, \"\\beta\", \"no description\")\n\n\n\nParameter(0.9, u->u^2)\n\nParameter(0.9, var\"#14#15\"(), \"notex\", \"no description\")\n\n\n\nmethods( Parameter )\n\n# 6 methods for type constructor: Parameter(value::Float64, transformation::Function, tex_label::String, description::String) in Main at In[35]:3  Parameter(value, tex::String) in Main at In[55]:2  Parameter(value, transformation::Function) in Main at In[55]:3  Parameter(value, transformation) in Main at In[50]:2  Parameter(value, transformation, tex) in Main at In[45]:1  Parameter(value, transformation, tex_label, description) in Main at In[35]:3 \n\n\n\n# Alternative constructors end with an appeal to the default\n# constructor\nfunction Parameter(value::Float64, tex_label::String)\n    transformation = identity\n    description = \"No description available\"\n    return Parameter(value, transformation, tex_label, description)\nend\n\nα = Parameter(0.5, \"\\alpha\")\n\nParameter(0.5, identity, \"\\alpha\", \"No description available\")\n\n\nNow the function Parameter has two different methods with different signatures:\n\nmethods(Parameter)\n\n# 4 methods for type constructor: Parameter(value::Float64, transformation::Function, tex_label::String, description::String) in Main at In[1]:3  Parameter(value::Float64, tex_label::String) in Main at In[8]:4  Parameter(value, transformation, tex) in Main at In[5]:1  Parameter(value, transformation, tex_label, description) in Main at In[1]:3 \n\n\n\ngun(x::Int64, y::Int64) = x^3 + y\n\ngun (generic function with 1 method)\n\n\n\ngun(x::Float64, y::Int64) = x/2 + y\n\ngun (generic function with 2 methods)\n\n\n\ngun(2, 2)\n\n10\n\n\n\ngun(2.0, 2)\n\n3.0\n\n\n\n# Find the fields of an instance of a composite type\nfieldnames(α)\n\n\nα.tex_label\n\n\n# Access a particular field using .\nα.value\n\n\n# Fields are modifiable and can be assigned to, like \n# ordinary variables\nα.value = 0.75\n\n\nsizeof(Int8)\n\n1\n\n\n\nsizeof(Float16)\n\n2\n\n\n\neps(Float16)\n\nFloat16(0.000977)\n\n\n\na\n\n\n# smallest epsilon one can represent with a given float type\nϵ = sqrt(eps(Float64))\n\n1.4901161193847656e-8\n\n\n\na = 2 + ϵ\n\n2.000000014901161\n\n\n\na - 2\n\n1.4901161193847656e-8\n\n\n\nf(x) = x^2\n\nf (generic function with 1 method)\n\n\n\n(f(2+ϵ) - f(2))/ϵ\n\n4.0\n\n\n\neps(Float32)\n\n1.1920929f-7\n\n\n\nDict(:a=>3)\n\nDict{Symbol, Int64} with 1 entry:\n  :a => 3\n\n\n\nd = (;a=4)\nd[:a]\nd.a\n\n4\n\n\n\ntypeof(d)\n\nNamedTuple{(:a,), Tuple{Int64}}\n\n\n\nstruct Point\n    x::Float64\n    y::Float64\nend\n\n\np = Point(4.3, 0.2)\n\nPoint(4.3, 0.2)\n\n\n\np.x =43\n\nLoadError: setfield!: immutable struct of type Point cannot be changed\n\n\n\n\n\n\nby default structures in Julia are non-mutable\n\nβ.value = 0.6\n\nLoadError: setfield! immutable struct of type Parameter cannot be changed\n\n\n\nmutable struct Params\n    x:: Float64\n    y:: Float64\nend\n\n\npos = Params(0.4, 0.2)\n\nParams(0.4, 0.2)\n\n\n\npos.x = 0.5\n\n0.5\n\n\n\nt = (1,2,3)\ntypeof( t )\n\nTuple{Int64, Int64, Int64}\n\n\n\nt[1]\n\n1\n\n\n\nt2 = (\"a\", \"b\", \"c\")\ntypeof( t2 )\n    \n\nTuple{String, String, String}\n\n\n\nt2[1]\n\n\"a\"\n\n\n\ntypeof( (; a=4))\n\nNamedTuple{(:a,), Tuple{Int64}}\n\n\n\ntypeof( [3.0, 4.0])\n\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\ntypeof( [3 4;5 9])\n\nMatrix{Int64} (alias for Array{Int64, 2})\n\n\n\n\n\nParameterized types are data types that are defined to handle values identically regardless of the type of those values.\nArrays are a familiar example. An Array{T,1} is a one-dimensional array filled with objects of any type T (e.g. Float64, String).\n\nstruct BPoint\n    x\n    y\nend\n\n\n# Defining a parametric point\nstruct Duple{T} # T is a parameter to the type Duple\n    x::T\n    y::T\nend\n\n\nDuple(3, -1.0)\n\nLoadError: MethodError: no method matching Duple(::Int64, ::Float64)\n\u001b[0mClosest candidates are:\n\u001b[0m  Duple(::T, \u001b[91m::T\u001b[39m) where T at In[29]:3\n\n\n\nDuple{Int64}\n\nDuple{Int64}\n\n\n\nstruct Truple{T}\n    x::Duple{T}\n    z::T\nend\n\nThis single declaration defines an unlimited number of new types: Duple{String}, Duple{Float64}, etc. are all immediately usable.\n\nsizeof(3.0)\n\n8\n\n\n\nsizeof( Duple(3.0, -15.0) )\n\n16\n\n\n\nsizeof( Truple{Int64} )\n\n24\n\n\n\n# What happens here?\nDuple(1.5, 3)\n\n\nstruct Truple3{T,S}\n    x::Tuple{T,S}\n    z::S\nend\n\n\nTruple3( ( 3.4, 5), 4 )\n\nTruple3{Float64, Int64}((3.4, 5), 4)\n\n\nWe can also restrict the type parameter T:\n\ntypeof(\"S\")\n\nString\n\n\n\ntypeof(\"S\") <: Number\n\nfalse\n\n\n\ntypeof(4.6) <: Float64\n\ntrue\n\n\n\nFloat64 <: Number\n\ntrue\n\n\n\n# T can be any subtype of Number, but nothing else\nstruct PlanarCoordinate{T<:Number}\n    x::T\n    y::T\nend\n\n\nPlanarCoordinate(\"4th Ave\", \"14th St\")\n\nLoadError: MethodError: no method matching PlanarCoordinate(::String, ::String)\n\n\n\nPlanarCoordinate(2//3, 8//9)\n\nPlanarCoordinate{Rational{Int64}}(2//3, 8//9)\n\n\n\nNumber:\n\n\n349//80 + 3//4 # rational \n\n409//80\n\n\n\ntypeof( factorial(20) )\n\nInt64\n\n\n\ntypeof( big(20) )\n\nBigInt\n\n\n\nfactorial(20)\n\n2432902008176640000\n\n\n\n\n\n\n\n\nYou can write all your code without thinking about types at all. If you do this, however, you’ll be missing out on some of the biggest benefits of using Julia.\nIf you understand types, you can:\n\nWrite faster code\nWrite expressive, clear, and well-structured programs (keep this in mind when we talk about functions)\nReason more clearly about how your code works\n\nEven if you only use built-in functions and types, your code still takes advantage of Julia’s type system. That’s why it’s important to understand what types are and how to use them.\n\n# Example: writing type-stable functions\nfunction sumofsins_unstable(n::Integer)  \n    sum = 0:: Integer\n    for i in 1:n  \n        sum += sin(3.4)  \n    end  \n    return sum \nend  \n\nfunction sumofsins_stable(n::Integer)  \n    sum = 0.0 :: Float64\n    for i in 1:n  \n        sum += sin(3.4)  \n    end  \n    return sum \nend\n\n# Compile and run\nsumofsins_unstable(Int(1e5))\nsumofsins_stable(Int(1e5))\n\n-25554.110202663698\n\n\n\n@time sumofsins_unstable(Int(1e5))\n\n  0.000268 seconds\n\n\n-25554.110202663698\n\n\n\n@time sumofsins_stable(Int(1e5))\n\n  0.000130 seconds\n\n\n-25554.110202663698\n\n\nIn sumofsins_stable, the compiler is guaranteed that sum is of type Float64 throughout; therefore, it saves time and memory. On the other hand, in sumofsins_unstable, the compiler must check the type of sum at each iteration of the loop. Let’s look at the LLVM intermediate representation.\n\n\n\n\n\nfunction fun(N, x0)\n    Σ = x0\n    for n=1:N\n        Σ = Σ + n*x0\n    end\n    return Σ\nend\n\nfun (generic function with 1 method)\n\n\n\n@time fun(100000000, [3.0, 1.0])\n\n 12.349387 seconds (200.00 M allocations: 14.901 GiB, 10.04% gc time)\n\n\n2-element Vector{Float64}:\n 1.500000016125468e16\n 5.000000050000001e15\n\n\n\nfunction fun2(N, x0)\n    a, b = x0\n    A, B = a,b\n    for n=1:N\n        A = A + n*a\n        B = B + n*b\n    end\n    return [A,B]\nend\n\nfun2 (generic function with 1 method)\n\n\n\n@time fun2(100000000, [3.0, 1.0])\n\n  0.151957 seconds (2 allocations: 160 bytes)\n\n\n2-element Vector{Float64}:\n 1.500000016125468e16\n 5.000000050000001e15\n\n\n\nfunction fun_inplace(N, x0)\n    Σ = copy(x0)\n    I = length(x0)\n    for n=1:N\n        for i=1:I\n            Σ[i] = Σ[i] + n*x0[i]\n        end\n    end\n    return Σ\nend\n\nfun_inplace (generic function with 1 method)\n\n\n\n@time fun_inplace(100000000, [3.0, 1.0])\n\n  0.455785 seconds (2 allocations: 160 bytes)\n\n\n2-element Vector{Float64}:\n 1.500000016125468e16\n 5.000000050000001e15\n\n\n\nfunction fun(N, x0)\n    Σ = x0\n    for n=1:N\n        Σ = Σ + n*x0\n    end\n    return Σ\nend\n\nfun (generic function with 1 method)\n\n\n\nusing StaticArrays\n\n\ns = @MVector [3.0, 1.0]\n\n2-element MVector{2, Float64} with indices SOneTo(2):\n 3.0\n 1.0\n\n\n\n@time fun_inplace(100000000, s)\n\n  0.188607 seconds (1 allocation: 32 bytes)\n\n\n2-element MVector{2, Float64} with indices SOneTo(2):\n 1.500000016125468e16\n 5.000000050000001e15\n\n\n\ns = @SVector [3.0, 1.0]\n\n2-element SVector{2, Float64} with indices SOneTo(2):\n 3.0\n 1.0\n\n\n\n@time fun( 100000000, s)\n\n  0.162312 seconds (1 allocation: 32 bytes)\n\n\n2-element SVector{2, Float64} with indices SOneTo(2):\n 1.500000016125468e16\n 5.000000050000001e15\n\n\n\n\nSo far we have defined functions over argument lists of any type. Methods allow us to define functions “piecewise”. For any set of input arguments, we can define a method, a definition of one possible behavior for a function.\n\n# Define one method of the function print_type\nfunction print_type(x::Number)\n    println(\"$x is a number\")\nend\n\nprint_type (generic function with 1 method)\n\n\n\n# Define another method\nfunction print_type(x::String)\n    println(\"$x is a string\")\nend\n\nprint_type (generic function with 2 methods)\n\n\n\n# Define yet another method\nfunction print_type(x::Number, y::Number)\n    println(\"$x and $y are both numbers\")\nend\n\nprint_type (generic function with 3 methods)\n\n\n\n# See all methods for a given function\nmethods(print_type)\n\n# 3 methods for generic function print_type: print_type(x::String) in Main at In[53]:3  print_type(x::Number) in Main at In[51]:3  print_type(x::Number, y::Number) in Main at In[54]:3 \n\n\nJulia uses multiple dispatch to decide which method of a function to execute when a function is applied. In particular, Julia compares the types of all arguments to the signatures of the function’s methods in order to choose the applicable one, not just the first (hence “multiple”).\n\nprint_type(5)\n\n5 is a number\n\n\n\nprint_type(\"foo\")\n\nfoo is a string\n\n\n\nprint_type([1, 2, 3])\n\nMethodError: MethodError: no method matching print_type(::Array{Int64,1})\nClosest candidates are:\n  print_type(!Matched::String) at In[53]:3\n  print_type(!Matched::Number) at In[51]:3\n  print_type(!Matched::Number, !Matched::Number) at In[54]:3\n\n\n\n\nJulia supports a short function definition for one-liners\n\nf(x::Float64) = x^2.0\nf(x::Int64) = x^3\n\nAs well as a special syntax for anonymous functions\n\nu->u^2\n\n\nmap(u->u^2, [1,2,3,4])\n\n\n\n\n\n\nf(a,b,c=true; algo=\"newton\")\n\nUndefVarError: UndefVarError: f not defined\n\n\n\n\n\n\nt = (1,2,4)\n\n(1, 2, 4)\n\n\n\na,b,c = t\n\n(1, 2, 4)\n\n\n\n[(1:10)...]\n\n10-element Array{Int64,1}:\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n\n\n\ncat([4,3], [0,1]; dims=1)\n\n4-element Array{Int64,1}:\n 4\n 3\n 0\n 1\n\n\n\nl = [[4,3], [0,1], [0, 0], [1, 1]]\n# how do I concatenate it ?\n\ncat(l...; dims=1) ### see python's f(*s)\n\n8-element Array{Int64,1}:\n 4\n 3\n 0\n 1\n 0\n 0\n 1\n 1\n\n\n\n\n\nAs we’ve seen, you can use Julia just like you use MATLAB and get faster code. However, to write faster and better code, attempt to write in a “Julian” manner:\n\nDefine composite types as logically needed\nWrite type-stable functions for best performance\nTake advantage of multiple dispatch to write code that looks like math\nAdd methods to existing functions\n\n\n\n\nHow is Julia so fast? Julia is just-in-time (JIT) compiled, which means (according to this StackExchange answer):\n\nA JIT compiler runs after the program has started and compiles the code (usually bytecode or some kind of VM instructions) on the fly (or just-in-time, as it’s called) into a form that’s usually faster, typically the host CPU’s native instruction set. A JIT has access to dynamic runtime information whereas a standard compiler doesn’t and can make better optimizations like inlining functions that are used frequently.\n\n\nThis is in contrast to a traditional compiler that compiles all the code to machine language before the program is first run.\n\nIn particular, Julia uses type information at runtime to optimize how your code is compiled. This is why writing type-stable code makes such a difference in speed!\n\n\n\n\nTaken from QuantEcon’s Julia Essentials and Vectors, Arrays, and Matrices lectures.\n\nConsider the polynomial \\[p(x) = \\sum_{i=0}^n a_0 x^0\\] Using enumerate, write a function p such that p(x, coeff) computes the value of the polynomial with coefficients coeff evaluated at x.\nWrite a function solve_discrete_lyapunov that solves the discrete Lyapunov equation \\[S = ASA' + \\Sigma \\Sigma'\\] using the iterative procedure \\[S_0 = \\Sigma \\Sigma'\\] \\[S_{t+1} = A S_t A' + \\Sigma \\Sigma'\\] taking in as arguments the \\(n \\times n\\) matrix \\(A\\), the \\(n \\times k\\) matrix \\(\\Sigma\\), and a number of iterations."
  },
  {
    "objectID": "tutorials/3a_Optimization_pushups.html",
    "href": "tutorials/3a_Optimization_pushups.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "The spirit of this simple tutorial consists in learning how to write simple solution algorithms. For each algorithm, test that it works, using simple test functions whose solution is known.\nWrite a function fixed_point(f::Function, x0::Float64) which computes the fixed point of f starting from initial point x0.\nWrite a function bisection(f::Function, a::Float64, b::Float64) which computes a zero of function f within (a,b) using a bisection method.\nWrite a function golden(f::Function, a::Float64, b::Float64) which computes a zero of function f within (a,b) using a golden ratio method.\nWrite a function zero_newton(f::Function, x0::Float64) which computes the zero of function f starting from initial point x0.\nAdd an option zero_newton(f::Function, x0::Float64, backtracking=true) which computes the zero of function f starting from initial point x0 using backtracking in each iteration.\nWrite a function min_gd(f::Function, x0::Float64) which computes the minimum of function f using gradient descent. Assume f returns a scalar and a gradient.\nWrite a function min_nr(f::Function, x0::Float64) which computes the minimum of function f using Newton-Raphson method. Assume f returns a scalar, a gradient, and a hessian.\nWrite a method zero_newton(f::Function, x0::Vector{Float64}) which computes the zero of a vector valued function f starting from initial point x0.\nAdd an method zero_newton(f::Function, x0::Vector{Float64}, backtracking=true) which computes the zero of function f starting from initial point x0 using backtracking in each iteration.\nAdd a method zero_newton(f::Function, x0::Vector{Float64}, backtracking=true, lb=Vector{Float64}) which computes the zero of function f starting from initial point x0 taking complementarity constraint into account x>=lb using the Fischer-Burmeister method."
  },
  {
    "objectID": "tutorials/2_solow.html",
    "href": "tutorials/2_solow.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "Tutorial: Convergence\n\nSolow Model\nA representative agent uses capital \\(k_t\\) to produce \\(y_t\\) using the following production function:\n\\[y_t = k_t^{\\alpha}\\]\nHe chooses to consume an amount \\(c_t \\in ]0, y_t]\\) and invests what remains:\n\\[i_t = y_t - c_t\\]\nHe accumulates capital \\(k_t\\) according to:\n\\[k_{t+1} = \\left( 1-\\delta \\right) k_{t} + i_{t}\\]\nwhere \\(\\delta\\) is the depreciation rate and \\(i_t\\) is the amount invested.\nThe goal of the representative agent is to maximize:\n\\[\\sum_{t\\geq 0} \\beta^t U(c_t)\\]\nwhere \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\beta<1\\) is the discount factor.\nFor now, we ignore the objective and assume that the saving rate \\(s=\\frac{c_t}{y_t}\\) is constant over time.\nCreate a NamedTuple to hold parameter values \\(\\beta=0.96\\), \\(\\delta=0.1\\), \\(\\alpha=0.3\\), \\(\\gamma=4\\).\n\nt = (0.96, 0.1,0.3, 4 )\nt[1]\nt[2]\n\n0.1\n\n\n\np = (;  β=0.96, δ=0.1, α=0.3, γ=4 )\np[1]\np.β\n\n0.96\n\n\n\n# other option\n# Dictionary: \nd = Dict( :β=>0.96, :δ=>0.1)\nd[:δ]\n\n0.1\n\n\nWrite down the formula of function \\(f\\) such that \\(k_{t+1}\\): \\(k_{t+1} = f(k_t)\\).\n\\[k_{t+1} = (1-δ) k_t + (1- s) k_t^{\\alpha}\\]\nDefine a function f(k::Float64, p::NamedTuple)::Float64 to represent \\(f\\) for a given calibration\n\n# many ways to define functions\n\n# full version\nfunction myfun(x)\n    y = x^2 + 1\n    return y\nend\n\n#inline version\nmyfun_inline(x) = x^2+1\n\n# anonymous\nx -> (x^2+1)\n\nmyfun_inline (generic function with 1 method)\n\n\n\nmyfun(0.1) == myfun_inline(0.1) == (x -> (x^2+1))(0.1)\n\ntrue\n\n\n\n# syntactic for named tuples\na = 0.3\nb = 10\n(;a, b) # equivalent to (;a=a, b=b)\n\n(a = 0.3, b = 10)\n\n\n\n(;α, δ) = p\n# equivalent to \n# δ = p.δ\n# α = p.α\n\n(β = 0.96, δ = 0.1, α = 0.3, γ = 4)\n\n\n\n(;x,y,z) = (;z=3, x=1,y=2)\nx\ny\nz\n\nErrorException: syntax: invalid assignment location \"(((parameters x y z) a),)\" around /home/pablo/Teaching/eco309/tutorials/2_solow.ipynb:1\n\n\n\nfunction f(k, p; s=0.5)\n\n    (;α, δ) = p\n\n    # δ = p.δ\n    # α = p.α\n    \n    # s = p.s\n\n    kn = k*(1-δ) + k^α*(1-s)\n\n    return kn\n\nend\n\nf (generic function with 1 method)\n\n\n\nf(0.5, p; s=0.7)\n\n0.6936757189068707\n\n\n\n# names arguments\n\n# optional arguments\n# varying number of parameters but no keyword\n\n\nfun(x,y=0.1) = x + y\n\nfun (generic function with 2 methods)\n\n\n\nmethods(fun)\n\n# 2 methods for generic function fun: fun(x) in Main at /home/pablo/Teaching/eco309/tutorials/2_solow.ipynb:1  fun(x, y) in Main at /home/pablo/Teaching/eco309/tutorials/2_solow.ipynb:1 \n\n\n\nfun(0.1)\nfun(0.2, 0.2)\n\n0.4\n\n\n\ngun(x ; y = 0.2) = x^2+ y\n\ngun (generic function with 1 method)\n\n\n\nmethods(gun)\n\n# 1 method for generic function gun: gun(x; y) in Main at /home/pablo/Teaching/eco309/tutorials/2_solow.ipynb:1 \n\n\n\ngun(0.4)\ngun(0.4; y=0.3)\ngun(0.4, 0.1)\n\nMethodError: MethodError: no method matching gun(::Float64, ::Float64)\nClosest candidates are:\n  gun(::Any; y) at ~/Teaching/eco309/tutorials/2_solow.ipynb:1\n\n\nWrite a function simulate(k0::Float64, T::Int, p::NamedTuple)::Vector{Float64} to compute the simulation over T periods starting from initial capital level k0.\n\nfunction simulate(k0, T, p; s=0.5)\n\n    sim = [k0]\n\n    for i ∈ 1:T    # same as for i in ... or for i=...\n        # in Julia, intervals contain the lower and upper bound\n        k1 = f(k0, p; s=s)\n\n        # add new value to simulation vector\n        push!(sim, k1)\n\n        k0 = k1\n    end\n\n    return sim\nend\n\nsimulate (generic function with 1 method)\n\n\n\nsim = simulate(0.5, 100, p;)\n\n101-element Vector{Float64}:\n 0.5\n 0.8561261981781177\n 1.2477475382753753\n 1.6573008927807404\n 2.073393171590884\n 2.4883176067712327\n 2.8967527254553693\n 3.2950061580751355\n 3.680539839343968\n 4.051654372933684\n ⋮\n 9.949900641171165\n 9.951039677408726\n 9.952099018857133\n 9.95308423905062\n 9.954000522065433\n 9.954852689688693\n 9.95564522669805\n 9.956382304382648\n 9.957067802427053\n\n\nMake a nice plot to illustrate the convergence. Do we get convergence from any initial level of capital?\n\nusing Plots\n\n\npl= plot(simulate(0.5, 100, p;); label=\"baseline\", title=\"Convergence of Solow Model\")\nplot!(pl, simulate(6.0, 100, p;); label=\"high initial capital\")\nplot!(pl, simulate(0.5, 100, p;s=0.2); label=\"lower saving rate\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose you were interested in using f to compute the steady-state. What would you propose to measure convergence speed? To speed-up convergence? Implement these ideas."
  },
  {
    "objectID": "slides/ddp.html",
    "href": "slides/ddp.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "Say something about dynamic optimization…\n\nThe imperialism of Dynamic Programming\n— Recursive Macroeconomic Theory (Ljunqvist & Sargent)\n\n\nI spent the Fall quarter (of 1950) at RAND. My first task was to find a name for multistage decision processes. An interesting question is, “Where did the name, dynamic programming, come from?” The 1950s were not good years for mathematical research. We had a very interesting gentleman in Washington named Wilson. He was Secretary of Defense, and he actually had a pathological fear and hatred of the word “research”. I’m not using the term lightly; I’m using it precisely. His face would suffuse, he would turn red, and he would get violent if people used the term research in his presence. You can imagine how he felt, then, about the term mathematical. The RAND Corporation was employed by the Air Force, and the Air Force had Wilson as its boss, essentially. Hence, I felt I had to do something to shield Wilson and the Air Force from the fact that I was really doing mathematics inside the RAND Corporation. What title, what name, could I choose? In the first place I was interested in planning, in decision making, in thinking. But planning, is not a good word for various reasons. I decided therefore to use the word “programming”. I wanted to get across the idea that this was dynamic, this was multistage, this was time-varying. I thought, let’s kill two birds with one stone. Let’s take a word that has an absolutely precise meaning, namely dynamic, in the classical physical sense. It also has a very interesting property as an adjective, and that is it’s impossible to use the word dynamic in a pejorative sense. Try thinking of some combination that will possibly give it a pejorative meaning. It’s impossible. Thus, I thought dynamic programming was a good name. It was something not even a Congressman could object to. So I used it as an umbrella for my activities.\n\n— Richard Bellman, Eye of the Hurricane: An Autobiography (1984, page 159)\n\n\n\n\n\n\n\n\n\nStochastic process: family of random variables indexed by time\nA stochastic process has the Markov property if its future evolution depends only on its current state.\nSpecial cases:\n\n\n\n\n\n\n\n\n\n\nDiscrete States\nContinuous States\n\n\n\n\nDiscrete Time\nDiscrete Markov Chain\nContinuous Markov Chain\n\n\nContinuous Time\nMarkov Jump Process\nMarkov Process\n\n\n\n\n\n\n\na matrix \\(M \\in R^n\\times R^n\\) matrix is said to be stochastic if\n\nall coefficents are non-negative\nall the lines lines sum to 1 (\\(\\forall i, \\sum_j M_{ij} = 1\\))\n\na probability density is a vector \\(\\mu \\in R^n\\) such that :\n\nall components are non-negative\nall coefficients sum to 1 (\\(\\sum_{i=1}^n \\mu_{i} = 1\\))\n\na distribution is a vector with such that:\n\nall components are non-negative\n\n\n\n\n\n\n\nConsider: \\(\\mu_{i,t+1}' =\\mu_t' P\\)\nWe have \\(\\mu_{i,t+1} = \\sum_{k=1}^n \\mu_{k,t} P_{k, i}\\)\nAnd: \\(\\sum_i\\mu_{i,t+1} = \\sum_i \\mu_{i,t}\\)\nPostmultiplication by a stochastic matrix preserves the mass.\nInterpretation: \\(P_{ij}\\) is the fraction of the mass initially in state \\(i\\) which ends up in \\(j\\)\n\n\n\n\n\n\\[\n\\begin{eqnarray}\n\\underbrace{\n\\begin{pmatrix}\n0.5 & 0.3 & 0.2\n\\end{pmatrix}\n}\\_{\\mu_t'} \\begin{pmatrix}\n0.4 & 0.6 & 0.0 \\\\\\\\\n0.2 & 0.5 & 0.3 \\\\\\\\\n0 & 0 & 1.0\n\\end{pmatrix} && \\\\\\\\\n\\underbrace{\n\\begin{pmatrix}\n0.5\\times0.4+0.3\\times 0.2 & 0.5\\times0.6+0.3\\times 0.5 & 0.3\\times 0.3 + 0.2\\times 1.0\n\\end{pmatrix}\n}\\_{\\mu_{t+1}'}&&\n\\end{eqnarray}\n\\]\n\n\n\n\n\n\nDenote by \\(S=(s_1,...s_n)\\) a finite set with \\(n\\) elements (\\(|S|=n\\)).\nA Markov Chain with values in \\(S\\) and with transitions given by a stochastic matrix \\(P\\in R^n\\times R^n\\) corresponds to a stochastic process \\((X\\_t)\\_{t\\geq 0}\\) such that \\[P\\_{ij} = Prob(X\\_{t+1}=s\\_j|X\\_t=s_i)\\]\nIn words, line \\(i\\) describes the conditional distribution of \\(X_{t+1}\\) conditional on \\(X_t=s_i\\).\n\n\n\n\n\n\nIt is easy to show that for any \\(k\\), \\(P^k\\) is a stochastic matrix.\n\\(P^k_{ij}\\) denotes the probability of ending in \\(j\\), after \\(k\\) periods, starting from \\(i\\)\nGiven an initial distribution \\(\\mu_0\\in R^{+ n}\\)\n\nWhich states will be visited with positive probability between t=0 and t=k?\nWhat happens in the very long run?\n\nWe need to study a little bit the properties of Markov Chains\n\n\n\n\n\n\nTwo states \\(s_i\\) and \\(s_j\\) are connected if \\(P_{ij}>0\\)\nWe call incidence matrix: \\(\\mathcal{I}(P)=(\\delta_{P_{ij}>0})_{ij}\\)\nTwo states \\(i\\) and \\(j\\) communicate with each other if there are \\(k\\) and \\(l\\) such that: \\((P^k)_ {i,j}>0\\) and \\((P^l)_ {j,i}>0\\)\n\nit is an equivalence relation\nwe can define equivalence classes\n\nA stochastic matrix \\(P\\) is irreducible if all states communicate\n\nthere is a unique communication class\n\n\n\n\n\n\n\n\n\n\n\nAll states can be reached with positive probably from any other initial state.\n\n\n\n\n\n\nThere is a subset of states (poor), which absorbs all the mass coming in.\n\n\n\n\n\n\n\n\nAre there cycles? Starting from a state \\(i\\), how long does it take to return to \\(i\\)?\nThe period of a state is defined as \\[gcd( {k\\geq 1 | (P^k)_{i,i}>0} )\\]\nIf a state has a period d>1 the chain returns to the state only at dates multiple of d.\n\n\n\n\n\n\n\n\n\n\nIf you start from some states, you return to it, but not before two periods.\n\n\n\n\n\n\nIf some mass leaves a state, some of it returns to the state in the next period.\n\n\n\n\n\n\n\n\n\\(\\mu\\) is a stationary distribution if \\(\\mu' = \\mu' P\\)\nTheorem: there always exists such a distribution that is not \\(\\mu=0\\)\n\nproof: Brouwer theorem (fixed-point result for compact-convex set)\n\\(f: \\mu\\rightarrow (\\mu'P)'\\)\n\nTheorem:\n\nif P is irreducible the fixed point \\(\\mu^{\\star}\\) is unique\nif P is irreducible and aperiodic \\(|\\mu_0' P^k - \\mu^{\\star}| \\underset{k\\to+\\infty}{\\longrightarrow} 0\\) for any initial distribution \\(\\mu_0\\)\n\nWe then say the Markov chain is ergodic\n\\(\\mu^{\\star}\\) is the ergodic distribution\n\nit is the best guess, one can do for the state of the chain in the very far future\n\n\n\n\n\n\n\nBrouwer’s theorem: Let \\(\\mathcal{C}\\) be a compact convex subset of \\(R^n\\) and \\(f\\) a continuous mapping \\(\\mathcal{C}\\rightarrow \\mathcal{C}\\). Then there exists a fixed point \\(x_0\\in \\mathcal{C}\\) such that \\(f(x_0)=x_0\\)\nResult hinges on:\n\ncontinuity of \\(f: \\mu \\mapsto \\mu P\\)\nconvexity of \\(\\\\{x \\in R^{+,n} ,\\\\; |x|_1=1 \\\\}\\) (easy to check)\ncompactness of \\(\\\\{x \\in R^{+,n} ,\\\\; |x|_1=1 \\\\}\\)\n\nit is bounded\nand closed (the inverse image of 1 for \\(u\\mapsto |u|_1\\) which is continuous)\n\n\n\n\n\n\n\nHow do we compute the stationary distribution?\n\nSimulation\nLinear algebra\nDecomposition\n\n\n\n\n\n\nVery simple idea:\n\nstart with any \\(\\mu_0\\) and compute the iterates recursively\n\\(\\mu_{n+1}' = \\mu_n' P\\)\nconvergence is linear:\n\n\\(|\\mu_{n+1} - \\mu_n| \\leq |P| |\\mu_n - \\mu_{n-1}|\\)\n\n\n\n\n\n\n\n\nFind the solution of \\(\\mu'(P-I) = 0\\) ?\n\nnot well defined, 0 is a solution\nwe need to incorporate the constraint \\(\\sum_i(\\mu_i)=1\\)\nsince P-I is at most of rank \\(n-1\\) we can replace one column by this condition\n\nMethod:\n\nDefine \\(M_{ij} = \\begin{cases} 1 &\\text{if} & j =1 \\\\\\\\ (P-I)_{ij} & \\text{if} & j> 1 \\end{cases}\\)\nDefine \\(D_i = \\begin{cases} 1 & \\text{if} & j = 1 \\\\\\\\0 & \\text{if} & j>0 \\end{cases}\\)\nWith a linear algebra solver\n\nlook for a solution \\(\\mu\\) of \\(\\mu' M = D\\)\nor \\(M^{\\prime} \\mu = D\\prime\\)\nif you find a solution, it is unique! (theorem)\n\n\nAlternative:\n\nminimize residual squares of overidentified system\n\n\n\n\n\n\n\njulia [1-2|3-6|7-9|10-12|13-14|15-17] # we use the identity matrix and the \\ operator using LinearAlgebra: I, \\ # define a stochastic matrix (lines sum to 1) P = [  0.9  0.1 0.0  ;        0.05 0.9 0.05 ;        0.0  0.9 0.1  ] # define an auxiliary matrix M = P' - I M[end,:] .= 1.0 # define rhs R = zeros(3) R[end] = 1 # solve the system μ = M\\R # check that you have a solution: @assert sum(μ) == 1 @assert all(abs.(μ'P - μ').<1e-10)\n\n\n\n\n\nKnowledge about the structure of the Markov Chain can help speedup the calculations\nThere are methods for potentially very-large linear system\n\nNewton-Krylov based methods, GMRES\n\nBasic algorithms are easy to implement by hand\nQuantEcon toolbox has very good methods to study markov chains\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarkov Decision Problem\n\nstates: \\(s \\in S\\)\nactions: \\(x \\in X(s)\\)\ntransitions: \\(\\pi(s'| s, x) \\in S\\)\n\n\\(probability\\) of going to \\(s'\\) in state \\(s\\)…\n… given action \\(x\\)\n\n\n\n\n\n\n\nReward: \\(r(s,x) \\in R\\)\n\naka felicity, intratemporal utility\n\n\nPolicy: \\(x(): s \\rightarrow x\\in X(s)\\)\n\na.k.a. decision rule\nwe consider deterministic policy\ngiven \\(x()\\), the evolution of \\(s\\) is a Markov process\n\n\\(\\pi(. |s, x())\\) is a distribution for \\(s'\\) over \\(S\\)\nit depends only on \\(s\\)"
  },
  {
    "objectID": "slides/ddp.html#finite-horizon-dmdp",
    "href": "slides/ddp.html#finite-horizon-dmdp",
    "title": "Introduction to Computational Economics",
    "section": "Finite horizon DMDP",
    "text": "Finite horizon DMDP\n\n\nFinite horizon DMDP\nWhen \\(T<\\infty\\). With discrete action the problem can be represented by a tree.\n[GRAPH]\n\n\n\nFinite horizon DMDP\n\nIntuition: backward induction.\n\nFind optimal policy \\(x_T(s_T)\\) in all terminal states \\(s_T\\). Set \\(V_T(s_T)\\) equal to \\(r(s_T, \\pi_T)\\)\nGiven \\(V_k(s_k)\\), for each state \\(s_{k-1}\\in S\\) find \\(x_{k-1}\\in X(s_{k-1})\\) which maximizes \\[V_{k-1}(s_{k-1}) = \\max_{x_{k-1}(s_{k-1})\\in X(s_{k-1})}r(s_{k-1},x_{k-1}) + \\delta \\underbrace{ \\sum_{s_k\\in S} \\pi(s_k | s_{k-1}, x_{k-1} ) V_k(s_k)} _{ \\textit{expected continuation value} }\\]\n\nPolicies \\(x_0(), ... x_T()\\) are Markov-perfect:\n\nthey maximize utility on all subsets of the “game”\nalso from t=0\n\n\n\n\n\nRemarks\n\nCan we do better than this naive algorithm?\n\nnot really\nbut we can try to limit \\(S\\) to make the maximization step faster\nexclude a priori some branches in the tree using knowledge of the problem"
  },
  {
    "objectID": "slides/ddp.html#infinite-horizon-dmdp",
    "href": "slides/ddp.html#infinite-horizon-dmdp",
    "title": "Introduction to Computational Economics",
    "section": "Infinite horizon DMDP",
    "text": "Infinite horizon DMDP\n\n\nInfinite horizon DMDP\n\nHorizon is infinite: \\[V(s; x()) =  \\max E_0 \\sum_{t=0}^{\\infty} \\delta^t r(s_t, x_t) \\]\n\nwe focus on time-consistent case where optimal choices are given by a time-invariant optimal rule \\(x(s)\\)\n\nIntuition:\n\nlet’s consider the finite horizon version \\(T<\\infty\\) and \\(T >> 1\\)\ncompute the solution, increase \\(T\\) until the solution doesn’t change\nin practice: take an initial guess for \\(V_{T}\\) then compute optimal \\(V_{T-1}\\), \\(V_{T_2}\\) and so on, until convergence of the \\(V\\)s\n\n\n\n\n\nInfinite horizon DMDP (2)\n\nThis is possible, it’s called Successive Approximation or Value Function Iteration\n\nhow fast does it converge? linearly\ncan we do better? yes, quadratically\n\nwith howard improvement steps\n\n\n\n\n\n\nSuccessive Approximation\n\nConsider the decomposition: \\[V(s; x()) = E_0 \\sum_{t=0}^{\\infty} \\delta^t r(s_t, x_t) = E_0 \\left[ r(s, x(s)) + \\sum_{t=1}^{\\infty} \\delta^t r(s_t, x_t) \\right]\\]\n\n\\[V(s; x()) = r(s, x(s)) +  E_0  \\left[ \\underbrace{ \\sum_{t=1}^{\\infty} \\delta^t r(s_t, x_t) }\\_{ \\delta  V(s_{t+1}; x())} \\right]\\]\nor with different notations\n\\[V(s; x()) =  r(s, x(s)) + \\delta \\sum_{s'} p(s'|s,x(s)) V(s'; x()) \\]\n\n\n\nSuccessive Approximation (2)\n\nTaking continuation value as given we can certainly improve the value in every state \\(\\tilde{V}\\) by choosing \\(\\tilde{x}()\\) so as to maximze \\[\\tilde{V}(s; x(), \\tilde{x}()) =  r(s, \\tilde{x}(s)) + \\delta \\sum_{s'} \\pi(s'|s,\\tilde{x}(s) )V(s'; x()) \\]\nBy construction: \\(\\forall s, \\tilde{V}(s, \\tilde{x}(), x()) > {V}(s, x())\\)\n\nit is an improvement step\n\nCan \\({V}(s, \\tilde{x}())\\) be worse for some states than \\({V}(s, {x}())\\) ?\n\nactually no\n\n\n\n\n\nBellman equation\n\nIdea:\n\nit should not be possible to improve upon the optimal solution.\nHence the optimal value \\(V\\) and policy \\(x^{\\star}\\) should satisfy: \\[\\forall s\\in S, V(s) = \\max_{y(s)} r(s, y(s)) + \\delta \\sum_{s^{\\prime}\\in S} \\pi(s^{\\prime}| s, y(s)) V(s^{\\prime})\\] with the maximum attained at \\(x(s)\\).\n\nThis is referred to as the Bellman equation.\nConversely, it is possible to show that a solution to the Bellman equation is also an optimal solution to the initial problem.\n\n\n\n\nBellman operator\n\nThe function \\(G\\) is known as the Bellman operator: \\[G: V \\rightarrow \\max\\_{y(s)} r(s, y(s)) + \\delta \\sum\\_{s^{\\prime}\\in S} \\pi(s^{\\prime}| s, y(s)) V(s^{\\prime})\\]\nDefine sequence \\(V_n = G(V_{n-1})\\)\n\nit goes back in time\nbut is not the time-iteration operator\n\nOptimal value is a fixed point of G\nDoes \\(G\\) converges to it ? Yes, if \\(G\\) is a contraction mapping.\n\n\n\n\nBlackwell’s theorem\n\nLet \\(X\\subset R^n\\) and let \\(\\mathcal{C}(X)\\) be a space of bounded functions \\(f: X\\rightarrow R\\), with the sup-metric. \\(B: \\mathcal{C}(X)\\rightarrow \\mathcal{C}(X)\\) be an operator satisfying two conditions:\n\n(monotonicity) if \\(f,g \\in \\mathcal{C}(X)\\) and \\(\\forall x\\in X, f(x)\\leq g(x)\\) then\n\n\\(\\forall x \\in X (Bf)(x)\\leq(Bg)(x)\\)\n\n(discounting) there exists some \\(\\delta\\in]0,1[\\) such that: \\(B.(f+a)(x)\\leq (B.f)(x) + \\delta a, \\forall f \\in \\mathcal{C}(X), a\\geq 0, x\\in X\\)\n\nThen \\(B\\) is a contraction mapping with modulus \\(\\delta\\).\n\n\n\n\nSuccessive Approximation\n\nUsing the Blackwell’s theorem, we can prove the Bellman operator is a contraction mapping (do it).\nThis justifies the Value Function Iteration algorithm:\n\nchoose an initial \\(V_0\\)\ngiven \\(V_n\\) compute \\(V_{n+1} = G(V_n)\\)\niterate until \\(|V_{n+1}- V_n|\\leq \\eta\\)\n\nPolicy rule is deduced from \\(V\\) as the maximand in the Bellman step\n\n\n\n\nSuccessive Approximation (2)\n\nNote that convergence of \\(V_n\\) is geometric\nBut \\(x_n\\) converges after a finite number of iterations (\\(X\\) is finite)\n\nsurely the latest iterations are suboptimal\nthey serve only to evaluate the value of \\(x^{\\star}\\)\n\nIn fact:\n\n\\(V_n\\) is never the value of \\(x_n()\\)\nshould we try to keep both in sync?\n\n\n\n\n\nPolicy iteration for DMDP\n\nChoose initial policy \\(x_0()\\)\nGiven initial guess \\(x_n()\\)\n\ncompute the value function \\(V_n=V( ;x_n)\\) which satisfies\n\\(\\forall s, V_n(s) = r(s, x_n(s)) + \\delta \\sum_{s'} \\pi(s'| s, x_n(s)) V_n(s')\\)\nimprove policy by maximizing in \\(x_n()\\) \\[\\max_{x_n()} r(s, x_n(s)) + \\delta \\sum_{s^{\\prime}\\in S} \\pi(s^{\\prime}| s, x_n(s)) V_{n-1}(s^{\\prime})\\]\n\nRepeat until convergence, i.e. \\(x_n=x_{n+1}\\)\nOne can show the speed of convergence (for \\(V_n\\)) is quadratic\n\nit “corresponds” the Newton-Raphson steps applied to \\(V\\rightarrow G(V)-V\\)\n\n\n\n\n\nHow do we compute the value of a policy?\n\nGiven \\(x_n\\), goal is to find \\(V_n(s)\\) in \\[\\forall s,  V_n(s) = r(s, x_n(s)) + \\delta \\sum_{s'} \\pi(s'| s, x_n(s)) V_n(s')\\]\nTwo(three) approaches:\n\nsimulate the policy rule and compute \\(E\\left[ \\sum_t \\delta^t r(s_t, x_t) \\right]\\) with Monte-Carlo draws\nsuccessive approximation:\n\nput \\(V_k\\) in the rhs and recompute the lhs \\(V_{k+1}\\), replace \\(V_k\\) by \\(V_{k+1}\\) and iterate until convergence\n\nsolve a linear system in \\(V_n\\)\n\nFor 2 and 3 it helps representing a linear operator \\(M\\) such that \\(V_{n+1} = R_n + \\delta M_n . V_n\\)"
  },
  {
    "objectID": "slides/ddp.html#example-the-mccall-model",
    "href": "slides/ddp.html#example-the-mccall-model",
    "title": "Introduction to Computational Economics",
    "section": "Example : the McCall Model",
    "text": "Example : the McCall Model\n\n\nIdea\n\nMcCall model:\n\nwhen should an unemployed person accept a job offer?\nchoice between:\n\nwait for a better offer (and receive low unemp. benefits)\naccept a suboptimal job offer\n\n\nWe present a variant of it, with a small probability of loosing a job.\n\n\n\n\nFormalization\n\nWhen unemployed in date, a job-seeker\n\nconsumes unemployment benefit \\(c_t = \\underline{c}\\)\nreceives in every date \\(t\\) a job offer \\(w_t\\)\n\n\\(w_t\\) is i.i.d.,\ntakes values \\(w_1, w_2, w_3\\) with probabilities \\(p_1, p_2, p_3\\)\n\nif job-seeker accepts, becomes employed at rate \\(w_t\\) in the next period\nelse he stays unemployed\n\nWhen employed at rate \\(w\\)\n\nworker consumes salary \\(c_t = w\\)\nwith small probability \\(\\lambda>0\\) looses his job:\n\nstarts next period unemployed\n\notherwise stays employed at same rate\n\nObjective: \\(\\max E_0 \\left\\\\{ \\sum \\beta^t \\log(c_t) \\right\\\\}\\)\n\n\n\n\nStates / reward\n\nWhat are the states?\n\nemployement status: Unemployed / Employed\nif Unemployed:\n\nthe level \\(w\\in {w_1, w_2, w_3}\\) of the salary that is currently proposed\n\nif Employed:\n\nthe level \\(w\\in {w_1, w_2, w_3}\\) at which worker was hired\n\ncurrent state, can be represented by a 2x3 index\n\nWhat are the actions?\n\nif Unemployed:\n\nreject (false) / accept (true)\n\nif Employed: None\nactions (when unemployed) are represented by a 3 elements binary vector\n\nWhat is the (intratemporal) reward?\n\nif Unemployed: \\(U(c)\\)\nif Employed at rate w: \\(U(w)\\)\nhere it doesn’t depend on the action\n\n\n\n\n\nValue function\n\\(\\newcommand{\\E}{\\mathbb{E}}\\)\n\nWhat is the value of being in a given state?\nIf Unemployed, facing current offer \\(w\\):\n\\[V^U(w) = U(\\underline{c}) + \\max_{a} \\begin{cases} \\beta V^E(w) & \\text{if $a(w)$ is true} \\\\\\\\ \\beta  \\\\E_{w'}\\left[ V^U(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\]\nIf Employed, at rate \\(w\\) \\[V^E(w) = U(w) +  (1-\\lambda) \\beta V^E(w) +  \\lambda \\beta \\\\E_{w'}\\left[ V^U(w^{\\prime}) \\right] \\]\nWe can represent value as two functions \\(V^U\\) and \\(V^E\\) of the states as\n\ntwo vectors of Floats, with three elements (recall: value-function is real valued)\n\n\n\n\n\nValue function iteration\n\nTake a guess for value function \\(\\tilde{V^E}\\), \\(\\tilde{V^U}\\), tomorrow\nUse it to compute value function today: \\[V^U(w) = U(\\underline{c}) + \\max_{a(w)} \\begin{cases} \\beta \\tilde{V}^E(w) & \\text{if $a(w)$ is true} \\\\\\\\ \\beta  \\\\E_{w'}\\left[ \\tilde{V}^U(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\] \\[V^E(w) = U(w) +  (1-\\lambda) \\beta \\tilde{V}^E(w) +  \\lambda \\beta \\\\E_{w'}\\left[\\tilde{V}^U(w^{\\prime}) \\right] \\]\n\\((\\tilde{V}^E, \\tilde{V}^U)\\mapsto (V^E, V^U)\\) is one value iteration step\nNote that we don’t have to keep track of policies tomorrow\n\nall information about future decisions is contained in \\(\\tilde{V}^E, \\tilde{V}^U\\)\nbut we can keep track of current policy: \\(a(w): \\arg\\max \\cdots\\)\n\n\n\n\n\nValue evaluation\n\nSuppose we take a policy \\(a(w)\\) as given. What is the value of following this policy forever?\nThe value function \\(V_a^E\\), \\(V_a^U\\) satisfies \\[V_a^U(w) = U(\\underline{c}) + \\begin{cases} \\beta \\tilde{V}^E_a(w) & \\text{if $a(w)$ is true} \\\\\\\\ \\beta  \\\\E_{w'}\\left[ \\tilde{V}^U_a(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\] \\[V_a^E(w) = U(w) +  (1-\\lambda) \\beta \\tilde{V}^E_a(w) +  \\lambda \\beta \\\\E_{w'}\\left[\\tilde{V}^U_a(w^{\\prime}) \\right]\\]\nNote the absence of the max function: we don’t reoptimize\n\n\n\n\nValue evaluation (2)\n\nHow do you compute value of policy \\(a(w)\\) recursively?\nIterate: \\((\\tilde{V}^E_a, \\tilde{V}^U)\\mapsto (V^E_a, V^U_a)\\) \\[V_a^U(w) \\leftarrow U(\\underline{c}) + \\begin{cases} \\beta \\tilde{V}^E_a(w) & \\text{if $a(w)$ is true} \\\\\\\\ \\beta  \\\\E_{w'}\\left[ \\tilde{V}^U_a(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\] \\[V_a^E(w) \\leftarrow U(w) +  (1-\\lambda) \\beta \\tilde{V}^E_a(w) +  \\lambda \\beta \\\\E_{w'}\\left[\\tilde{V}^U_a(w^{\\prime}) \\right] \\]\nNote the absence of the max function:\n\nwe don’t reoptimize\nwe we keep the same policy all along\n\n\n\n\n\nPolicy iteration\n\nstart with policy \\(a(w)\\)\nevaluate the value of this policy \\(V^E_a, V^U_a\\)\n\ncompute the optimal policy in the Bellman iteration\nkeep the improved policy \\(a(w)\\)\n\nhere: \\(a(w) = \\arg\\max_{a(w)} \\begin{cases} \\beta \\tilde{V}^E(w)\\\\\\\\ \\beta \\\\E_{a'}\\left[ \\tilde{V}^U(a^{\\prime}) \\right] \\end{cases}\\)\n\n\niterate until \\(a(w)\\) converges"
  },
  {
    "objectID": "slides/discretization.html",
    "href": "slides/discretization.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "approximate operator with a finite number of iterations:\n\ncompute \\(\\int_a^b f(x) dx\\)\ncompute \\(E_\\omega f(\\omega)\\)\n\nrepresent an infinite dimensional object with a finite set of parameters:\n\n\\(f \\equiv (f(x_i))_{i=1:N}\\) with \\(x_i=a+\\frac{i-1}{N-1}(b-a)\\)\n\ndiscretize arguments\n\n\\(\\omega \\equiv (\\mu_i, \\omega_i)_{i=1:N}\\) such that \\(E_\\omega f(\\omega) \\approx \\sum_i \\mu_i f(\\omega_i)\\) (quantization)\n\ndiscretize continous process by a discrete one:\n\ncontinuous markov chain to discrete markov Chain\n\n\n\n\n\n\n\n\n\n\n\nTake \\(AR1\\) process \\[x_t = \\rho x_{t-1} + \\epsilon_t\\]\n\nwith \\(|\\rho| <1\\) and \\(\\epsilon \\sim N(0,\\sigma)\\)\n\nCan we replace \\((x_t)\\) by a discrete markov chain?\n\napproximate version:\n\ngood time \\(x^g\\) and bad time \\(x^b\\). Probability \\(\\pi\\) of staying in the same, \\(1-\\pi\\) of switching.\n\ntwo systematic methods (available in QuantEcon.jl)\n\nTauchen\nRouwenhorst\n\n\n\n\n\n\n\n\nThe unconditional distribution of an AR1 is a normal law \\(\\mathcal{N}(0,\\frac{\\sigma}{\\sqrt{1-\\rho^2}})\\)\nChoose \\(m>0\\), typically \\(m=3\\)\nBound the process: \\(\\underline{x} = -m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\) and \\(\\overline{x} = m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\)\nDefine the \\(N\\) discretized points (\\(i\\in[1,n]\\)): \\(y_i = \\underline{x} + \\frac{i-1}{N-1}(\\overline{x}-\\underline{x})\\)\nDefine the transitions:\n\n\\[\\begin{eqnarray}\n\\pi_{ij} & = & prob \\\\left( y_{t+1}=y_j|y_t=y_i\\\\right)\\\\\\\\\n         & = & prob \\\\left( |y_{t+1}-x_j| = \\inf_k |y_{t+1}-x_k| \\left| y_t=y_i \\right. \\right)\n\\end{eqnarray}\\]\n\n\n\n\n\nFormulas \\(\\delta=\\frac{\\overline{x}-\\underline{x}}{N}\\):\n\nif \\(1<k<N-1\\)\n\\[\\pi_{jk} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) - F(y_k + \\delta/2-\\rho y_j)\\]\nif \\(k=1\\)\n\\[\\pi_{j} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) \\]\nif \\(k=N\\)\n\\[\\pi_{j} = 1- F(\\frac{y_k - \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) \\]\n\n\n\n\n\n\n\ncompare generated stationary moments between discretized process and true AR1:\n\nE(), Var(), ACor()\n\nby looking at the exact ergodic distribution or by doing some simulations\nnot very precise when then process is very persistent \\(\\rho\\approx 1\\)\n\n\n\n\n\n\nN = 2\n\nchoose \\(y_1=-\\psi\\), \\(y_2=\\psi\\)\ndefine transition matrix: \\[\\Theta_2 = \\begin{bmatrix}\np & 1-p\\\\\\\\\n1-q & q\n\\end{bmatrix}\\]\nchoose \\(p\\), \\(q\\) and \\(\\psi\\) to match some moments: \\(E()\\), \\(Var()\\), \\(ACor()\\)\n\nthey can be computed analytically for AR1 and for discretized version.\n\n\n\n\n\n\n\n\nN >2 \\[\\Theta_N =\np \\begin{bmatrix}  \n\\Theta_{N-1}  & 0\\\\\\\\\n0 & 0\n\\end{bmatrix} +\n(1-p) \\begin{bmatrix}  \n0 & \\Theta_{N-1} \\\\\\\\\n0 & 0\n\\end{bmatrix} +\n(1-q) \\begin{bmatrix}  \n0 & 0\\\\\\\\\n\\Theta_{N-1} & 0\n\\end{bmatrix} +\nq \\begin{bmatrix}  \n0 & 0\\\\\\\\\n0 & \\Theta_{N-1}\n\\end{bmatrix}\n\\]\nNormalize all lines\n\n\n\n\n\n\nProcedure converges to Bernouilli distribution.\nMoments can be computed in closed form:\n\n\\(E() = \\frac{(q-p)\\psi}{2-(p+q)}\\)\n\\(Var() = \\psi^2 \\left[ 1-4 s (1-s) + \\frac{4s(1-s)}{N-1}\\right]\\)\n\\(Acor()= p+q-1\\)\n\nRouwenhorst method performs better for highly correlated processes\n\n\n\n\n\n\n\n\n\n\nGiven \\(f\\), and an iid process \\(\\epsilon \\sim N(0,\\sigma^2)\\), how to approximate \\(E_{\\epsilon} f(\\epsilon)\\) ?\nIdeas:\n\ndraw lots of random \\((\\epsilon\\_n)\\_{n=1:N}\\) and compute \\[\\frac{1}{N}\\sum_{n=1}^N f(\\epsilon_n)\\]\n\naka Monte-Carlo simulations\n\ngiven a method to approximate integrals, compute \\[\\int_{u=-\\infty}^{\\infty} f(u) \\mu(u) du\\] with \\(\\mu(u)=\\frac{1}{\\sigma\\sqrt{2 \\pi}}e^{-\\frac{u^2}{2\\sigma^2}}\\)\ndiscretize (or quantize) the signal \\(\\epsilon\\) as \\((w_i, \\epsilon_i)_{i=1:N}\\) and compute:\n\n\n\\[\\frac{1}{N} \\sum_n w_n f(\\epsilon_n)\\]\n\n\n\n\n\nLet’s take an exemple:\n\nconsumption is \\(C(\\epsilon)=U(e^{\\epsilon})\\)\nwith \\({\\sigma}\\_{\\epsilon}=0.05\\) and \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\gamma=40\\).\n\nLet’s compute \\(E_{\\epsilon}(C(\\epsilon))\\) precisely.\nDiscuss value of \\(\\gamma\\): is it crazy? (risk return)\n\n\n\n\n\nCompute expectation\n```julia [1-3|4-7|9-10|14] # imports: using Distributions: Normal"
  },
  {
    "objectID": "slides/optimization.html#introduction-1",
    "href": "slides/optimization.html#introduction-1",
    "title": "Optimization",
    "section": "Introduction",
    "text": "Introduction\nOptimization is everywhere in economics:\n\nto model agent’s behaviour: what would a rational agent do?\n\nconsumer maximizes utility from consumption\nfirm maximizes profit\n\nan economist tries to solve a model:\n\nfind prices that clear the market"
  },
  {
    "objectID": "slides/optimization.html#plan",
    "href": "slides/optimization.html#plan",
    "title": "Optimization",
    "section": "Plan",
    "text": "Plan\n\ngeneral consideration about optimization problems\none-dimensional root-finding\none-dimensional optimization\nlocal root-finding\nlocal optimization\nconstrained optimization\nconstrained root-finding"
  },
  {
    "objectID": "slides/optimization.html#optimization-tasks-come-in-many-flavours",
    "href": "slides/optimization.html#optimization-tasks-come-in-many-flavours",
    "title": "Optimization",
    "section": "Optimization tasks come in many flavours",
    "text": "Optimization tasks come in many flavours\n\ncontinuous versus discrete optimization\nconstrained and unconstrained optimization\nglobal and local\nstochastic and deterministic optimization\nconvexity"
  },
  {
    "objectID": "slides/optimization.html#continuous-versus-discrete-optimization",
    "href": "slides/optimization.html#continuous-versus-discrete-optimization",
    "title": "Optimization",
    "section": "Continuous versus discrete optimization",
    "text": "Continuous versus discrete optimization\n\nChoice is picked from a given set (\\(x\\in X\\)) which can be:\n\ncontinuous: choose amount of debt \\(b_t \\in [0,\\overline{b}]\\), of capital \\(k_t \\in R^{+}\\)\ndiscrete: choose whether to repay or default \\(\\delta\\in{0,1}\\), how many machines to buy (\\(\\in N\\)), at which age to retire…\na combination of both: mixed integer programming"
  },
  {
    "objectID": "slides/optimization.html#continuous-versus-discrete-optimization-2",
    "href": "slides/optimization.html#continuous-versus-discrete-optimization-2",
    "title": "Optimization",
    "section": "Continuous versus discrete optimization (2)",
    "text": "Continuous versus discrete optimization (2)\n\nDiscrete optimization requires a lot of combinatorial thinking\n\nWe don’t cover it today.\n…if needed, we just test all choices until we find the best one\n\nSometimes a discrete choice can be approximated by a mixed strategy (i.e. a random strategy).\n\nInstead of \\(\\delta\\in{0,1}\\) we choose \\(x\\) in \\(prob(\\delta=1)=\\sigma(x)\\)\nwith \\(\\sigma(x)=\\frac{2}{1+\\exp(-x)}\\)"
  },
  {
    "objectID": "slides/optimization.html#constrained-and-unconstrained-optimization",
    "href": "slides/optimization.html#constrained-and-unconstrained-optimization",
    "title": "Optimization",
    "section": "Constrained and Unconstrained optimization",
    "text": "Constrained and Unconstrained optimization\n\nUnconstrained optimization: \\(x\\in R\\)\nConstrained optimization: \\(x\\in X\\)\n\nbudget set: \\(p_1 c_1 + p_2 c_2 \\leq I\\)\npositivity of consumption: \\(c \\geq 0\\).\n\nIn good cases, the optimization set is convex…\n\npretty much always in this course"
  },
  {
    "objectID": "slides/optimization.html#stochastic-vs-determinstic",
    "href": "slides/optimization.html#stochastic-vs-determinstic",
    "title": "Optimization",
    "section": "Stochastic vs Determinstic",
    "text": "Stochastic vs Determinstic\n\nCommon case, especially in machine learning \\[f(x) = E_{\\epsilon}[ \\xi (\\epsilon, x)]\\]\nOne wants to maximize (resp solve) w.r.t. \\(x\\) but it is costly to compute expectation precisely using Monte-Carlo draws (there are other methods).\nA stochastic optimization method allows to use noisy estimates of the expectation, and will still converge in expectation.\nFor now we focus on deterministic methods. Maybe later…"
  },
  {
    "objectID": "slides/optimization.html#local-vs-global-algorithms",
    "href": "slides/optimization.html#local-vs-global-algorithms",
    "title": "Optimization",
    "section": "Local vs global Algorithms",
    "text": "Local vs global Algorithms\n\nIn principle, there can be many roots (resp maxima) within the optimization set.\nAlgorithms that find them all are called “global”. For instance:\n\ngrid search\nsimulated annealing\n\nWe will deal only with local algorithms, and consider local convergence properties.\n\n->then it might work or not\nto perform global optimization just restart from different points."
  },
  {
    "objectID": "slides/optimization.html#math-vs-practice",
    "href": "slides/optimization.html#math-vs-practice",
    "title": "Optimization",
    "section": "Math vs practice",
    "text": "Math vs practice\n\nThe full mathematical treatment will typically assume that \\(f\\) is smooth (\\(\\mathcal{C}_1\\) or \\(\\mathcal{C}_2\\) depending on the algorithm).\nIn practice we often don’t know about these properties\n\nwe still try and check thqt we have a local optimal\n\nSo: fingers crossed"
  },
  {
    "objectID": "slides/optimization.html#math-vs-practice-1",
    "href": "slides/optimization.html#math-vs-practice-1",
    "title": "Optimization",
    "section": "Math vs practice",
    "text": "Math vs practice\nHere is the surface representing the objective that a deep neural network training algorithm tries to minimize.\n\nAnd yet, neural networks do great things!"
  },
  {
    "objectID": "slides/optimization.html#what-do-you-need-to-know",
    "href": "slides/optimization.html#what-do-you-need-to-know",
    "title": "Optimization",
    "section": "What do you need to know?",
    "text": "What do you need to know?\n\nbe able to handcode simple algos (Newton, Gradient Descent)\nunderstand the general principle of the various algorithms to compare them in terms of\n\nrobustness\nefficiency\naccuracy\n\nthen you can just switch the various options, when you use a library…"
  },
  {
    "objectID": "slides/optimization.html#bisection",
    "href": "slides/optimization.html#bisection",
    "title": "Optimization",
    "section": "Bisection",
    "text": "Bisection\n\nFind \\(x \\in [a,b]\\) such that \\(f(x) = 0\\). Assume \\(f(a)f(b) <0\\).\nAlgorithm\n\nStart with \\(a_n, b_n\\). Set \\(c_n=(a_n+b_n)/2\\)\nCompute \\(f(c_n)\\)\n\n\nif \\(f(c_n)f(a_n)<0\\) then set \\((a_{n+1},b_{n+1})=(a_n,c_n)\\)\nelse set \\((a_{n+1},b_{n+1})=(c_n,b_n)\\)\n\n\nIf \\(|f(c_n)|<\\epsilon\\) and/or \\(\\frac{b-a}{2^n}<\\delta\\) stop. Otherwise go back to 1."
  },
  {
    "objectID": "slides/optimization.html#bisection-2",
    "href": "slides/optimization.html#bisection-2",
    "title": "Optimization",
    "section": "Bisection (2)",
    "text": "Bisection (2)\n\nNo need for initial guess: globally convergent algorithm\n\nnot a global algorithm…\n… in the sense that it doesn’t find all solutions\n\n\\(\\delta\\) is a guaranteed accuracy on \\(x\\)\n\\(\\epsilon\\) is a measure of how good the solution is\nthink about your tradeoff: (\\(\\delta\\) or \\(\\epsilon\\) ?)"
  },
  {
    "objectID": "slides/optimization.html#newton-algorithm",
    "href": "slides/optimization.html#newton-algorithm",
    "title": "Optimization",
    "section": "Newton algorithm",
    "text": "Newton algorithm\n\nFind \\(x\\) such that \\(f(x) = 0\\). Use \\(x_0\\) as initial guess.\n\\(f\\) must be \\(\\mathcal{C_1}\\) and we assume we can compute its derivative \\(f^{\\prime}\\)\nGeneral idea:\n\nobserve that the zero \\(x^{\\star}\\) must satisfy \\[f(x^{\\star})=0=f(x_0)+f^{\\prime}(x_0)(x^{\\star}-x_0) + o(x-x_0)\\]\nHence a good approximation should be \\[x^{\\star}\\approx = x_0- f(x_0)/f^{\\prime}(x_0)\\]\nCheck it is good. otherwise, replace \\(x_0\\) by \\(x^{\\star}\\)"
  },
  {
    "objectID": "slides/optimization.html#newton-algorithm-2",
    "href": "slides/optimization.html#newton-algorithm-2",
    "title": "Optimization",
    "section": "Newton algorithm (2)",
    "text": "Newton algorithm (2)\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- \\frac{f(x_n)}{f^{\\prime}(x_n)}=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|<\\eta\\) or \\(|f(x_n)| < \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization.html#quasi-newton",
    "href": "slides/optimization.html#quasi-newton",
    "title": "Optimization",
    "section": "Quasi-Newton",
    "text": "Quasi-Newton\n\nWhat if we can’t compute \\(f^{\\prime}\\) or it is expensive to do so?\n\nIdea: try to approximate \\(f^{\\prime}(x_n)\\) from the last iterates\n\nSecant method: \\[f^{\\prime}(x_n)\\approx \\frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}\\] \\[x_{n+1} = x_n- f(x_n)\\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\\]\n\nrequires two initial guesses: \\(x_1\\) and \\(x_0\\)\nsuperlinear convergence: \\(\\lim \\frac{x_t-x^{\\star}}{x_{t-1}-x^{\\star}}\\rightarrow 0\\)"
  },
  {
    "objectID": "slides/optimization.html#limits-of-newtons-method",
    "href": "slides/optimization.html#limits-of-newtons-method",
    "title": "Optimization",
    "section": "Limits of Newton’s method",
    "text": "Limits of Newton’s method\n\nHow could Newton method fail?\n\nbad guess\n\n-> start with a better guess\n\novershoot\n\n-> dampen the update (problem: much slower)\n-> backtrack\n\nstationary point\n\n-> if root of multiplicity \\(m\\) try \\(x_{n+1} = x_n- m \\frac{f(x_n)}{f^{\\prime}(x_n)}\\)"
  },
  {
    "objectID": "slides/optimization.html#backtracking",
    "href": "slides/optimization.html#backtracking",
    "title": "Optimization",
    "section": "Backtracking",
    "text": "Backtracking\n\nSimple idea:\n\nat stage \\(n\\) given \\(f(x_n)\\) compute Newton step \\(\\Delta_n=-\\frac{f(x_n)}{f^{\\prime}(x_n)}\\)\nfind the smallest \\(k\\) such that \\(|f(x_n-\\Delta/2^k)|<|f(x_n)|\\)\nset \\(x_{n+1}=x_n-\\Delta/2^k\\)"
  },
  {
    "objectID": "slides/optimization.html#golden-section-search",
    "href": "slides/optimization.html#golden-section-search",
    "title": "Optimization",
    "section": "Golden section search",
    "text": "Golden section search\n\nMinimize \\(f(x)\\) for \\(x \\in [a,b]\\)\nChoose \\(\\Phi \\in [0,0.5]\\)\nAlgorithm:\n\nstart with \\(a_n < b_n\\) (initially equal to \\(a\\) and \\(b\\))\ndefine \\(c_n = a_n+\\Phi(b_n-a_n)\\) and \\(d_n = a_n+(1-\\Phi)(b_n-a_n)\\)\n\nif \\(f(c_n)<f(d_n)\\) set \\(a_{n+1},b_{n+1}=a_n, d_n\\)\nelse set \\(a_{n+1}, b_{n+1}= c_n, b_n\\)"
  },
  {
    "objectID": "slides/optimization.html#golden-section-search-2",
    "href": "slides/optimization.html#golden-section-search-2",
    "title": "Optimization",
    "section": "Golden section search (2)",
    "text": "Golden section search (2)\n\nThis is guaranteed to converge to a local minimum\nIn each step, the size of the interval is reduced by a factor \\(\\Phi\\)\nBy choosing \\(\\Phi=\\frac{\\sqrt{5}-1}{2}\\) one can save one evaluation by iteration.\n\nyou can check that either \\(c_{n+1} = d_n\\) or \\(d_{n+1} = c_n\\)\n\nRemark that bisection is not enough"
  },
  {
    "objectID": "slides/optimization.html#newton-raphson-algorithm-2",
    "href": "slides/optimization.html#newton-raphson-algorithm-2",
    "title": "Optimization",
    "section": "Newton-Raphson Algorithm (2)",
    "text": "Newton-Raphson Algorithm (2)\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-\\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nstop if \\(|x_{n+1}-x_n|<\\eta\\) or \\(|f^{\\prime}(x_n)| < \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization.html#unconstrained-problems",
    "href": "slides/optimization.html#unconstrained-problems",
    "title": "Optimization",
    "section": "Unconstrained problems",
    "text": "Unconstrained problems\n\nMinimize \\(f(x)\\) for \\(x \\in R^n\\) given initial guess \\(x_0 \\in R^n\\)\nMany intuitions from the 1d case, still apply\n\nreplace derivatives by gradient, jacobian and hessian\nrecall that matrix multiplication is not commutative\n\nSome specific problems:\n\nupdate speed can be specific to each dimension\nsaddle-point issues (for minimization)"
  },
  {
    "objectID": "slides/optimization.html#quick-terminology",
    "href": "slides/optimization.html#quick-terminology",
    "title": "Optimization",
    "section": "Quick terminology",
    "text": "Quick terminology\nFunction \\(f: R^p \\rightarrow R^q\\)\n\nJacobian: \\(J(x)\\) or \\(f^{\\prime}\\_x(x)\\), \\(p\\times q\\) matrix such that: \\[J(x)\\_{ij} = \\frac{\\partial f(x)\\_i}{\\partial x_j}\\]\nGradient: \\(\\nabla f(x) = J(x)\\), gradient when \\(q=1\\)\nHessian: denoted by \\(H(x)\\) or \\(f^{\\prime\\prime}\\_{xx}(x)\\) when \\(q=1\\): \\[H(x)\\_{jk} = \\frac{\\partial f(x)}{\\partial x_j\\partial x_k}\\]\nIn the following explanations, \\(|x|\\) denotes the supremum norm, but most of the following explanations also work with other norms."
  },
  {
    "objectID": "slides/optimization.html#multidimensional-newton-raphson",
    "href": "slides/optimization.html#multidimensional-newton-raphson",
    "title": "Optimization",
    "section": "Multidimensional Newton-Raphson",
    "text": "Multidimensional Newton-Raphson\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- J(x_{n})^{-1}f(x_n)=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|<\\eta\\) or \\(|f(x_n)| < \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization.html#multidimensional-newton-root-finding-2",
    "href": "slides/optimization.html#multidimensional-newton-root-finding-2",
    "title": "Optimization",
    "section": "Multidimensional Newton root-finding (2)",
    "text": "Multidimensional Newton root-finding (2)\n\nwhat matters is the computation of the step \\(\\Delta_n = {\\color{\\red}{J(x_{n})^{-1}}} f(x_n)\\)\ndon’t compute \\(J(x_n)^{-1}\\)\n\nit takes less operations to compute \\(X\\) in \\(AX=Y\\) than \\(A^{-1}\\) then \\(A^{-1}Y\\)\nin Julia: X = A \\ Y\n\nstrategies to improve convergence:\n\ndampening: \\(x_n = (1-\\lambda)x_{n-1} - \\lambda \\Delta_n\\)\nbacktracking: choose \\(k\\) such that \\(|f(x_n-2^{-k}\\Delta_n)|\\)<\\(|f(x_{n-1})|\\)\nlinesearch: choose \\(\\lambda\\in[0,1]\\) so that \\(|f(x_n-\\lambda\\Delta_n)|\\) is minimal"
  },
  {
    "objectID": "slides/optimization.html#multidimensional-gradient-descent",
    "href": "slides/optimization.html#multidimensional-gradient-descent",
    "title": "Optimization",
    "section": "Multidimensional Gradient Descent",
    "text": "Multidimensional Gradient Descent\n\nMinimize \\(f(x) \\in R\\) for \\(x \\in R^n\\) given \\(x_0 \\in R^n\\)\nAlgorithm\n\nstart with \\(x_n\\) \\[x_{n+1} = (1-\\lambda) x_n - \\lambda \\nabla f(x_n)\\]\nstop if \\(|x_{n+1}-x_n|<\\eta\\) or \\(|f(x_n)| < \\epsilon\\)\n\nComments:\n\nlots of variants\nautomatic differentiation software makes gradient easy to compute\nconvergence is typically linear"
  },
  {
    "objectID": "slides/optimization.html#gradient-descent-variants",
    "href": "slides/optimization.html#gradient-descent-variants",
    "title": "Optimization",
    "section": "Gradient descent variants",
    "text": "Gradient descent variants"
  },
  {
    "objectID": "slides/optimization.html#multidimensional-newton-minimization",
    "href": "slides/optimization.html#multidimensional-newton-minimization",
    "title": "Optimization",
    "section": "Multidimensional Newton Minimization",
    "text": "Multidimensional Newton Minimization\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-{\\color{\\red}{H(x_{n})^{-1}}}\\color{\\green}{ J(x_n)'}\\)\nstop if \\(|x_{n+1}-x_n|<\\eta\\) or \\(|f(x_n)| < \\epsilon\\)\n\nConvergence: quadratic\nProblem:\n\n\\(H(x_{n})\\) hard to compute efficiently\nrather unstable"
  },
  {
    "objectID": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization",
    "href": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization",
    "title": "Optimization",
    "section": "Quasi-Newton method for multidimensional minimization",
    "text": "Quasi-Newton method for multidimensional minimization\n\nRecall the secant method:\n\n\\(f(x_{n-1})\\) and \\(f(x_{n-2})\\) are used to approximate \\(f^{\\prime}(x_{n-2})\\).\nIntuitively, \\(n\\) iterates would be needed to approximate a hessian of size \\(n\\)….\n\nBroyden method: takes \\(2 n\\) steps to solve a linear problem of size \\(n\\)\n\nuses past information incrementally"
  },
  {
    "objectID": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization-1",
    "href": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization-1",
    "title": "Optimization",
    "section": "Quasi-Newton method for multidimensional minimization",
    "text": "Quasi-Newton method for multidimensional minimization\n\nConsider the approximation: \\[f(x_n)-f(x_{n-1}) \\approx J(x_n) (x_n - x_{n-1})\\]\n\n\\(J(x_n)\\) is unknown and cannot be determined directly as in the secant method.\nidea: \\(J(x_n)\\) as close as possible to \\(J(x_{n-1})\\) while solving the secant equation\nformula: \\[J_n = J_{n-1} + \\frac{(f(x_n)-f(x_{n-1})) - J_{n-1}(x_n-x_{n-1})}{||x_n-x_{n-1}||^2}(x_n-x_{n-1})^{\\prime}\\]"
  },
  {
    "objectID": "slides/optimization.html#gauss-newton-minimization",
    "href": "slides/optimization.html#gauss-newton-minimization",
    "title": "Optimization",
    "section": "Gauss-Newton Minimization",
    "text": "Gauss-Newton Minimization\n\nRestrict to least-square minimization: $min_x _i f(x)_i^2 R $\nThen up to first order, \\(H(x_n)\\approx J(x_n)^{\\prime}J(x_n)\\)\nUse the step: \\(({J(x_n)^{\\prime}J(x_n)})^{-1}\\color{\\green}{ J(x_n)}\\)\nConvergence:\n\ncan be quadratic at best\nlinear in general"
  },
  {
    "objectID": "slides/optimization.html#levenberg-marquardt",
    "href": "slides/optimization.html#levenberg-marquardt",
    "title": "Optimization",
    "section": "Levenberg-Marquardt",
    "text": "Levenberg-Marquardt\n\nLeast-square minimization: $min_x _i f(x)_i^2 R $\nreplace \\({J(x_n)^{\\prime}J(x_n)}^{-1}\\) by \\({J(x_n)^{\\prime}J(x_n)}^{-1} +\\mu I\\)\n\nadjust \\(\\lambda\\) depending on progress\n\nuses only gradient information like Gauss-Newton\nequivalent to Gauss-Newton close to the solution (\\(\\mu\\) small)\nequivalent to Gradient far from solution (\\(\\mu\\) high)"
  },
  {
    "objectID": "slides/optimization.html#consumption-optimization",
    "href": "slides/optimization.html#consumption-optimization",
    "title": "Optimization",
    "section": "Consumption optimization",
    "text": "Consumption optimization\nConsider the optimization problem: \\[\\max U(x_1, x_2)\\]\nunder the constraint \\(p_1 x_1 + p_2 x_2 \\leq B\\)\nwhere \\(U(.)\\), \\(p_1\\), \\(p_2\\) and \\(B\\) are given.\nHow do you find a solution by hand?"
  },
  {
    "objectID": "slides/optimization.html#consumption-optimization-1",
    "href": "slides/optimization.html#consumption-optimization-1",
    "title": "Optimization",
    "section": "Consumption optimization (1)",
    "text": "Consumption optimization (1)\n\nCompute by hand\nEasy:\n\nsince the budget constraint must be binding, get rid of it by stating \\(x_2 = B - p_1 x_1\\)\nthen maximize in \\(x_1\\), \\(U(x_1, B - p_1 x_1)\\) using the first order conditions.\n\nIt works but:\n\nbreaks symmetry between the two goods\nwhat if there are other constraints: \\(x_1\\geq \\underline{x}\\)?\nwhat if constraints are not binding?\nis there a better way to solve this problem?"
  },
  {
    "objectID": "slides/optimization.html#consumption-optimization-2",
    "href": "slides/optimization.html#consumption-optimization-2",
    "title": "Optimization",
    "section": "Consumption optimization (2)",
    "text": "Consumption optimization (2)\n\nAnother method, which keeps the symmetry. Constraint is binding, trying to minimize along the budget line yields an implicit relation between \\(d x_1\\) and \\(d x_2\\) \\[p_1 d {x_1} + p_2 d {x_2} = 0\\]\nAt the optimal: \\(U^{\\prime}\\_{x_1}(x_1, x_2)d {x_1} + U^{\\prime}\\_{x_2}(x_1, x_2)d {x_2} = 0\\)\nEliminate \\(d {x_1}\\) and \\(d {x_2}\\) to get one condition which characterizes optimal choices for all possible budgets. Combine with the budget constraint to get a second condition."
  },
  {
    "objectID": "slides/optimization.html#penalty-function",
    "href": "slides/optimization.html#penalty-function",
    "title": "Optimization",
    "section": "Penalty function",
    "text": "Penalty function\n\nTake a penalty function \\(p(x)\\) such that \\(p(x)=K>0\\) if \\(x>0\\) and \\(p(x)=0\\) if \\(x \\leq 0\\). Maximize: \\(V(x_1, x_2) = U(x_1, x_2) - p( p_1 x_1 + p_2 x_2 - B)\\)\nClearly, \\(\\min U \\iff \\min V\\)\nProblem: \\(\\nabla V\\) is always equal to \\(\\nabla U\\).\nSolution: use a smooth solution function like \\(p(x) = x^2\\)\nProblem: distorts optimization\n\nSolution: adjust weight of barrier and minimize \\(U(x_1, x_2) - \\kappa p(x)\\)\n\nPossible but hard to choose the weights/constraints."
  },
  {
    "objectID": "slides/optimization.html#penalty-function-1",
    "href": "slides/optimization.html#penalty-function-1",
    "title": "Optimization",
    "section": "Penalty function",
    "text": "Penalty function\n\nAnother idea: is there a canonical way to choose \\(\\lambda\\) such that at the minimum it is equivalent to minimize the original problem under constraint or to minimize \\[V(x_1, x_2) = U(x_1, x_2) - \\lambda (p_1 x_1 + p_2 x_2 - B)\\]\nClearly, when the constraint is not binding we must have \\(\\lambda=0\\). What should be the value of \\(\\lambda\\) when the constraint is binding ?"
  },
  {
    "objectID": "slides/optimization.html#karush-kuhn-tucker-conditions",
    "href": "slides/optimization.html#karush-kuhn-tucker-conditions",
    "title": "Optimization",
    "section": "Karush-Kuhn-Tucker conditions",
    "text": "Karush-Kuhn-Tucker conditions\n\nIf \\((x^{\\star},y^{\\star})\\) is optimal there exists \\(\\lambda\\) such that:\n\n\\((x^{\\star},y^{\\star})\\) maximizes lagrangian \\(\\mathcal{L} = U(x_1, x_2) + \\lambda (B- p_1 x_1 - p_2 x_2)\\)\n\\(\\lambda \\geq 0\\)\n\\(B- p_1 x_1 - p_2 x_2 \\geq 0\\)\n\\(\\lambda (B - p_1 x_1 - p_2 x_2 ) = 0\\)\n\nThe three latest conditions are called “complementarity” or “slackness” conditions\n\nthey are equivalent to \\(\\min(\\lambda, B - p_1 x_1 - p_2 x_2)=0\\)\nwe denote \\(\\lambda \\geq 0 \\perp B- p_1 x_1 + p_2 x_2 \\geq 0\\)\n\n\\(\\lambda\\) can be interpreted as the welfare gain of relaxing the constraint."
  },
  {
    "objectID": "slides/optimization.html#karush-kuhn-tucker-conditions-1",
    "href": "slides/optimization.html#karush-kuhn-tucker-conditions-1",
    "title": "Optimization",
    "section": "Karush-Kuhn-Tucker conditions",
    "text": "Karush-Kuhn-Tucker conditions\n\nWe can get first order conditions that factor in the constraints:\n\n\\(U^{\\prime}_x - \\lambda p_1 = 0\\)\n\\(U^{\\prime}_y - \\lambda p_2 = 0\\)\n\\(\\lambda \\geq 0 \\perp B-p_1 x_1 -p_2 x_2 \\geq 0\\)\n\nIt is now a nonlinear system of equations with complementarities (NCP)\n\nthere are specific solution methods to deal with it"
  },
  {
    "objectID": "slides/optimization.html#solution-strategies-for-ncp-problems",
    "href": "slides/optimization.html#solution-strategies-for-ncp-problems",
    "title": "Optimization",
    "section": "Solution strategies for NCP problems",
    "text": "Solution strategies for NCP problems\n\nGeneral formulation for vector-valued functions \\[f(x)\\geq 0 \\perp g(x)\\geq 0\\] means \\[\\forall i, f_i(x)\\geq 0 \\perp g_i(x)\\geq 0\\]\n\nNCP do not necessarily arise from a single optimization problem\n\nThere are robust (commercial) solvers for NCP problems (PATH, Knitro) for that\nHow do we solve it numerically?\n\nassume constraint is binding then non-binding then check which one is good\n\nOK if not too many constraints\n\nreformulate it as a smooth problem\napproximate the system by a series of linear complementarities problems (LCP)"
  },
  {
    "objectID": "slides/optimization.html#optimization-libraries",
    "href": "slides/optimization.html#optimization-libraries",
    "title": "Optimization",
    "section": "Optimization libraries",
    "text": "Optimization libraries\n\nRobust optimization code is contained in the following libraries:\n\nRoots.jl: one-dimensional root finding\nNLSolve.jl: multidimensional root finding (+complementarities)\nOptim.jl: minimization\n\nThe two latter libraries have a somewhat peculiar API, but it’s worth absorbing it.\n\nin particular they provide non-allocating algorithms for functions that modify arguments in place\nthey are compatible with automatic differentiation\n\n\njulia> f(x) = [x[1] - x[2] - 1, x[1] + x[2]]\nf (generic function with 1 method)\n\njulia> NLsolve.nlsolve(f, [0., 0.0])\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [0.5000000000009869, -0.5000000000009869]\n * Inf-norm of residuals: 0.000000       \n * Iterations: 1                       \n * Convergence: true\n   * |x - x'| < 0.0e+00: false\n   * |f(x)| < 1.0e-08: true                           \n * Function Calls (f): 2\n * Jacobian Calls (df/dx): 2"
  },
  {
    "objectID": "slides/rbc.html",
    "href": "slides/rbc.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "Real Business Cycle\n\nLike the neo-classical growth model\nWith shocks\nWith labour\nWith a decentralized interpretation\n\nExplains short term fluctuations\n\nwithout demand shocks / money\n\n\n\n\n\n\n\n\n\nstates:\n\nproductivity: \\(z_t\\)\ncapital: \\(k_t\\)\n\ntwo independent control variables:\n\nconsumption: \\(c_t \\in [0,y_t], c_t\\geq 0, c_t\\leq y_t\\)\nlabor: \\(n_t\\)\n\nshock:\n\ntfp shock: \\(\\epsilon_t \\sim \\mathcal{N}(0,\\sigma)\\)\n\nobjective: \\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0, y_t \\geq c_t, n_t \\geq 0, 1 \\geq n_t\\end{matrix}} \\mathbb{E}_0 \\left[ \\sum \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\nU and V satisfy Inada conditions, ie \\(U^{\\prime}>0, U^{\\prime \\prime}<0, U^{\\prime}(0)=\\infty\\)\n\n\n\n\ndefinitions:\n\nproduction: \\[y_t  = \\exp(z_t) k_t^{\\alpha} n^{1-\\alpha} + i_t\\]\ninvestment: \\[i_t = y_t - c_t\\]\n\ntransitions: \\[\\begin{eqnarray}\nz_t = (1-\\rho) z_{t-1} + \\epsilon_t\\\\\\\\\nk_t = (1-\\delta) k_{t-1} + i_{t-1}\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\nTwo variables optimization: \\[\\max_{\\begin{matrix}c_1, c_2\\\\\\\\p_1 c_1 + p_2 c_t \\leq B\\end{matrix}} U(c_1, c_2)\\]\nDeterministic opimization (finite horizon) \\[\\max_{\\begin{matrix}c_0, c_1, c_2, ... c_T \\\\\\\\ c_0 + c_1 + \\cdots + c_T \\leq B\\\\\\\\c_0\\geq0, \\cdots c_T \\geq 0 \\end{matrix}} \\sum_{i=1}^{T} \\beta^i U(c_i)\\]\nDeterministic opimization (infinite horizon) \\[\\max_{\\begin{matrix}c_0, c_1, ... \\\\\\\\ c_0 + c_1 + \\cdots \\leq B\\\\\\\\c_0\\geq0, c_1\\geq 0, \\cdots \\end{matrix}} \\sum_{i=1}^{\\infty} \\beta^i U(c_i)\\]\n\n\n\n\n\n\n\n\nexogenous process defines an event tree \\((s)\\)\n\nit is a very useful concept to understand stochastic optimization, complete markets, etc.\nmath for continuous processes a bit involved (filtrations, …), but most intuition can be gained from discrete process\n\n\n[graph ]\n\n\n\nconsider a discrete process (for instance \\(\\epsilon_t \\in [ \\overline{\\epsilon}, \\underline{\\epsilon}]\\))\n\nan event is defined as the history of the shocks so far\nex: \\((\\overline{\\epsilon} , \\overline{\\epsilon}, \\underline{\\epsilon}, \\overline{\\epsilon})\\)\n\nif \\(s^{\\prime}\\) is the sucessor of \\(s\\) we denote \\(s \\subset s^{\\prime}\\)\n\n\\(s\\) is in the history of \\(s^{\\prime}\\)\ntransition probabilities \\(\\tau(s,s^{\\prime})\\)\n\n\\(1 = \\sum_{s^{\\prime} | s\\subset s^{\\prime}} \\tau(s, s^{\\prime})\\)\n\n\neach node has a given probability \\(p(s)\\). By construction:\n\n\\(p(s^{\\prime}) = p(s) \\tau(s,s^{\\prime})\\)\n\nsometimes, we keep time subscript:\n\nex: \\(s_4 = (\\overline{\\epsilon} , \\overline{\\epsilon}, \\underline{\\epsilon}, \\overline{\\epsilon})\\)\nbut for each \\(t\\) there are many possible \\(s_t\\)\n\n\n\n\n\n\n\n\n\nStochastic optimization (infinite horizon) \\[\\max_{ c_t } \\mathbb{E_0} \\left[ \\sum_{t=1}^{\\infty} \\beta^i U(c_t) \\right]\\]\nWhat it really means (\\(|s|\\) is time of event \\(s\\)) \\[\\max_{ \\forall s,  c(s)} \\sum_{s} p(s) \\beta^{|s|} U(c(s))\\]\nOr: \\[\\max_{ c(s_t) } \\sum_{t}  \\beta^{t} \\sum_{s_t} p(s_t)U(c(s_t))\\]\nThink of it as a regular sum\nWhen you differentiate the lagrangian, you are differentiating w.r.t. all \\(c(s_t)\\), i.e the values of \\(c\\) on each of the nodes.\nExample: cake eating\n\n\n\n\n\n\\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0\\\\\\\\ y_t \\geq c_t\\\\\\\\n_t \\geq 0\\\\\\\\1 \\geq n_t\\end{matrix}} \\mathbb{E}_0 \\left[ \\sum \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\n\nWe know that optimally \\(c_t>0\\), \\(c_t<y_t\\) and \\(n_t>0\\)\n\nequality cases lead to zero production, i.e. infinite marginal utility\n\n\n\n\n\n\n\\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0\\\\\\\\ k_{t+1} \\geq 0 \\\\\\\\n_t \\geq 0\\\\\\\\1 \\geq n_t \\\\\\\\ y_t \\geq c_t - i_t  \\\\\\\\ k_{t+1} = (1-\\delta) k_t  + i_t \\\\\\\\ y_t = e^{z_t} k_t^{\\alpha} n_t^{1-\\alpha} \\end{matrix}} \\mathbb{E}_0 \\left[ \\sum_t \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\n\nWe know that optimally \\(c_t>0\\), and \\(n_t>0\\), \\(k_{t+1}>0\\)\n\nequality cases lead to zero production, i.e. infinite marginal utility\nwe can drop the corresponding constraints\n\nWe assume \\(n_t=1\\) is never binding (this would correspond to unemployment)\n\n\n\n\n\n\\[\\mathcal{L} = \\mathbb{E}\\_0 \\left[ \\sum_t \\beta^t \\left\\\\{ \\begin{matrix} U(c_t) + \\chi V(1-n_t) \\\\\\\\ + \\lambda_t (y_t - c_t) \\\\\\\\  + q_t (k\\_{t+1} - (1-\\delta) k_t - i_{t} ) \\\\\\\\ + \\nu_t (y_t - e^{z_t} k_t^{\\alpha}n_t^{1-\\alpha})  \\end{matrix} \\right\\\\} \\right]\\]\n\nLet’s derive w.r.t. all nonpredetermined values within the sum:\n\n… explain\n\n\n\n\n\n\n\\[\\begin{eqnarray}\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left(\n         (1-\\delta) + \\alpha e^{z\\_{t+1}} k\\_{t+1}^{\\alpha-1} n\\_{t+1}^{1-\\alpha}\n             \\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = &  (1-\\alpha) e^{z_t} k_t^{\\alpha} (n_t)^{-\\alpha} U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\n\n\n\n\nSet \\(U(x) = \\frac{c_t^{1-\\gamma}}{1-\\gamma}\\), \\(V(x) = \\frac{(1-x)^{1-\\eta}}{1-\\eta}\\)\nTry to find the steady state\n\nit is impossible to do so in closed-form\n\nSet \\(\\overline{n} = 0.33\\) and adjust \\(\\chi\\) so that it is a steady-state\n\n\n\n\n\n\n\n\n\n\nSo far, we have assumed, that the same agent decides on consumption and labour supply\nWhat if some decisions are taken in some decentralized markets?\nNew structure:\n\ndecentralized competitive firms\n\nrent capital and workers\nsell goods\n\na representative household\n\nsupplies labour\naccumulates capital and rents it to firms\nconsume goods\n\n\n\n\n\n\n\n\nFirm \\(i\\)\n\nchooses capital \\(k^i\\) and labour \\(n^i\\)\n\nCobb Douglas production: \\(y_i = f(k_i, n_i) = (k_i)^{\\alpha} (n_i)^(1-\\alpha)\\)\nSince there is only one good, its price can be set to \\(1\\)\nFirm takes wages \\(w\\) and rental price of capital \\(r\\) as given: \\[max_{k_i, n_i} \\pi(k_i, n_i) =  f(k_i, n_i) - r  k_i - w n_i\\]\nOptimally:\n\n\\(f_k^{\\prime}(k_i, n_i) = \\alpha k_i^{\\alpha-1} n_i^{1-\\alpha} = r\\)\n\\(f_n^{\\prime}(k_i, n_i) = (1-\\alpha) k_i^{\\alpha-1} n_i^{-\\alpha} = w\\)\n\nRemark:\n\ncapital share: \\(\\frac{r k_i}{y_i} = \\alpha\\)\nlabour share: \\(\\frac{w n_i}{y_i} = 1- \\alpha\\)\nprofits are zero\n\n\n\n\n\n\n\nWhat is the production of all firms if total capital is \\(K\\) and total labour is \\(L\\) ?\nNote that for each firm \\[(1 - \\alpha) \\frac{k_i}{l_i} = \\alpha \\frac{w}{r}\\]\nWe can sum over all firms to get: \\[(1-\\alpha){K} = \\alpha \\frac{w}{r}L\\]\nwe can write: \\[y_i = (k_i)^{\\alpha} (n_i)^{1-\\alpha} = k_i \\left( \\frac{k_i}{n_i} \\right)^{1-\\alpha} = k_i (K/L)^{1-\\alpha}\\]\nand sum over all firms: \\[Y = K (K/L)^{1-\\alpha} = K^\\alpha L ^{1-\\alpha}\\]\nThe sum of many cobb douglas-firms is a big cobb-douglas firm !\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + r_t k_t + w_t n_t - i_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)\n\n\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + (1-\\tau) w_t n_t + r_t k_t - i_t + g_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\nNote the new budget constraint\n\nlabour income is taxed, but a lump-sum subsidy ensures nothing is destroyed\n\\(g_t =\\tau w_t k_t\\) is not taken into account for intertemporal optimization\n\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & (1-\\tau) w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)"
  },
  {
    "objectID": "slides/differentiation.html",
    "href": "slides/differentiation.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "Manual\nFinite Differences\nSymbolic Differentiation\nAutomatic Differentiation\n\n\n\n\n\n\nTrick:\n\nnever use \\(\\frac{d}{dx} \\frac{u(x)}{v(x)} = \\frac{u'(x)v(x)-u(x)v'(x)}{v(x)^2}\\)\nuse instead \\[\\frac{d}{dx} {u(x)v(x)} = {u'(x)v(x)+u(x)v'(x)}\\] and \\[\\frac{d}{dx} u(x) = -\\frac{u^{\\prime}}{u(x)^2}\\]\n\nJust kidding.\n\n\n\n\n\n\nChoose small \\(\\epsilon>0\\), typically \\(\\sqrt{ \\textit{machine eps}}\\)\nForward Difference scheme:\n\n\\(f'(x) \\approx \\frac{f(x+\\epsilon) - f(x)}{\\epsilon}\\)\nprecision: \\(o(\\epsilon)\\)\nbonus: if \\(f(x+\\epsilon)\\) can compute \\(f(x)-f(x-\\epsilon)\\) instead (Backward)\n\nCentral Difference scheme:\n\n\\(f'(x) \\approx \\frac{f(x+\\epsilon) - f(x-\\epsilon)}{2\\epsilon}\\)\naverage of forward and backward\nprecision: \\(o(\\epsilon^2)\\)\n\n\n\n\n\n\n\nCentral formula: \\[\\begin{aligned}\nf''(x) & \\approx & \\frac{f'(x)-f'(x-\\epsilon)}{\\epsilon} \\approx \\frac{(f(x+\\epsilon))-f(x))-(f(x)-f(x-\\epsilon))}{\\epsilon^2}  \\\\ & = & \\frac{f(x+\\epsilon)-2f(x)+f(x-\\epsilon)}{\\epsilon^2}\n\\end{aligned}\\]\n\nprecision: \\(o(\\epsilon)\\)\n\nGeneralizes to higher order but becomes more and more innacurate\n\n\n\n\n\n\nmanipulate the tree of algebraic expressions\n\nimplements various simplification rules\n\nrequires mathematical expression\ncan produce mathematical insights\nsometimes inaccurate:\n\ncf: \\(\\left(\\frac{1+u(x)}{1+v(x)}\\right)^{100}\\)\n\n\n\n\n\n\n\nLots of packages\nFiniteDiff.jl, FiniteDifferences.jl, SparseDiffTools.jl\n\ncareful implementation of finite diff\n\nCalculus.jl:\n\npure julia\nfinite difference\nsymbolic calculation\n\nSymEngine.jl\n\nfast symbolic calculation\n\nSymbolics.jl\n\nfast, pure Julia\nless complete than SymEngine\n\n\n\n\n\n\n\ndoes not provide mathematical insights but solves the other problems\ncan differentiate any piece of code\ntwo flavours\n\nforward accumulation\nreverse accumulation\n\n\n\n\n\n\nfunction f(x::Float64)\n    a = x + 1\n    b = x^2\n    c = sin(a) + a + b\nend\n\n\n\n\nfunction f(x::Float64)\n\n    # x is an argument\n    x_dx = 1.0\n\n    a = x + 1\n    a_dx = x_dx\n\n    b = x^2\n    b_dx = 2*x*x_dx\n\n    t = sin(a)\n    t_x = cos(a)*a_dx\n\n    c = t + b\n    c_x = t_dx + b_dx\n\n    return (c, c_x)\nend\n\n\n\n\nstruct DN\n    x::Float64\n    dx::Float64\nend\n\n+(a::DN,b::DN) = DN(a.x+b.x, a.dx+b.dx)\n-(a::DN,b::DN) = DN(a.x-b.x, a.dx-b.dx)\n*(a::DN,b::DN) = DN(a.x*b.x, a.x*b.dx+a.dx*b.x)\n/(a::DN,b::DN) = DN(a.x/b.x, (a.dx*b.x-a.x*b.dx)/b.dx^2)\n\n...\n\n\n\n\nimport ForwardDiff: Dual\n\nx = Dual(1.0, 1.0)\na = 0.5*x\nb = sum([(x)^i/i*(-1)^(i+1) for i=1:5000])\n# compare with log(1+x)\n\ngeneralizes nicely to gradient computations\n\nx = Dual(1.0, 1.0, 0.0)\ny = Dual(1.0, 0.0, 1.0)\nexp(x) + log(y)\n\n\n\n\n\nautodiff libraries, use special types and operator overloading to perform operations (like Dual numbers)\nthis relies on Julia duck-typing ability\n\nso don’t specify type arguments for functions you want to autodiff\n\nThis works:\n\nusing ForwardDiff\nf(x) = [x[1] + x[2], x[1]*x[2]]\nForwardDiff.jacobian(f, [0.4, 0.1])\n\nThis doesn’t:\n\nusing ForwardDiff\ng(x::Vector{Float64}) = [x[1] + x[2], x[1]*x[2]]\nForwardDiff.jacobian(g, [0.4, 0.1])\n\n\n\n\n\nForward Accumulation mode: isomorphic to dual number calculation\n\ncompute tree with values and derivatives at the same time\nefficient for \\(f: R^n\\rightarrow R^m\\), with \\(n<<m\\)\n\n(keeps lots of empty gradients when \\(n>>m\\))\n\n\n\n\n\n\n\n\nReverse Accumulation / Back Propagation\n\nefficient for \\(f: R^n\\rightarrow R^m\\), with \\(m<<n\\)\nrequires data storage (to keep intermediate values)\ngraph / example\n\nVery good for machine learning:\n\n\\(\\nabla_{\\theta} F(x;\\theta)\\) where \\(F\\) can be an objective\n\n\n\n\n\n\n\nSee JuliaDiff: http://www.juliadiff.org/\n\nForwardDiff.jl\nReverseDiff.jl\n\nZygote.jl\nDeep learning framework:\n\nhigher order diff w.r.t. any vector -> tensor operations\nFlux.jl, MXNet.jl, Tensorflow.jl\n\n\n\n\n\n\n\nOther libraries like NLsolve or Optim.jl rely on on the former libraries to perform automatic differentiation automatically.\n\nusing NLSolve\nfunction fun!(F, x)\n    F[1] = (x[1]+3)*(x[2]^3-7)+18\n    F[2] = sin(x[2]*exp(x[1])-1)\nend\nnlsolve(fun!, [0.1, 0.2], autodiff = :forward)"
  },
  {
    "objectID": "slides/7_ddp_mccall.html",
    "href": "slides/7_ddp_mccall.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "When unemployed in date, a job-seeker\n\nconsumes unemployment benefit \\(c_t = \\underline{c}\\)\nreceives in every date \\(t\\) a job offer \\(w_t\\)\n\n\\(w_t\\) is i.i.d.,\ntakes values \\(w_1, w_2, w_3\\) with probabilities \\(p_1, p_2, p_3\\)\n\nif job-seeker accepts, becomes employed at rate \\(w_t\\) in the next period\nelse he stays unemployed\n\nWhen employed at rate \\(w\\)\n\nworker consumes salary \\(c_t = w\\)\nwith small probability \\(\\lambda>0\\) looses his job:\n\nstarts next period unemployed\n\notherwise stays employed at same rate\n\nObjective: \\(\\max E_0 \\left\\{ \\sum \\beta^t \\log(w_t) \\right\\}\\)\n\nWhat are the states, the controls, the reward of this problem ? Write down the Bellman equation.\nDefine a parameter structure for the model.\nDefine a function value_update(V_U::Vector{Float64}, V_E::Vector{Float64}, x::Vector{Bool}, p::Parameters)::Tuple{Vector, Vector}, which takes in value functions tomorrow and a policy vector and return updated values for today.\nDefine a function Define a function policy_eval(x::Vector{Bool}, p::Parameter)::Tuple{Vector, Vector} which takes in a policy vector and returns the value(s) of following this policies forever. You can add relevant arguments to the function. which takes in a policy vector and returns the value(s) of following this policies forever. You can add relevant arguments to the function.\nDefine a function bellman_step(V_E::Vector, V_U::Vector, p::Parameters)::Tuple{Vector, Vector, Vector} which returns updated values, together with improved policy rules.\nImplement Value Function\nImplement Policy Iteration and compare rates of convergence.\nDiscuss the Effects of the Parameters\n\n\n\nChoose a 2x2 matrix \\(P\\) (with spectral radius <1) and a 2x2 matrix Q.\nConsider the VAR1 process \\(x_t = P x_{t-1} + Q \\epsilon_t\\) where \\(\\epsilon_t= (\\eta_{1,t}, \\eta_{2,t})\\) with \\(\\eta_1\\sim\\mathcal{N}(0,1)\\) and \\(\\eta_1\\sim\\mathcal{N}(0,1)\\)\nCompute impulse response functions.\nSimulate the process for \\(T\\) periods.\nSimulate the process \\(N=1000\\) times for \\(T=1000\\) periods. How would you store the results?\nMake density plots to illustrate the ergodic property of the process\nCompute the asymptotic variance of the process. Compare with the theoretical one."
  },
  {
    "objectID": "slides/convergence.html#life-of-a-computational-economist",
    "href": "slides/convergence.html#life-of-a-computational-economist",
    "title": "Convergence of sequences",
    "section": "Life of a computational economist",
    "text": "Life of a computational economist"
  },
  {
    "objectID": "slides/convergence.html#life-of-a-computational-economist-1",
    "href": "slides/convergence.html#life-of-a-computational-economist-1",
    "title": "Convergence of sequences",
    "section": "Life of a computational economist",
    "text": "Life of a computational economist\nVideo\n\n\nWe spend a lot of time waiting for algorithms to converge!\n\n\nsolution 1: program better\n\nsolution 2: better algorithms\n\neven better: understand convergence properties (information about the model)"
  },
  {
    "objectID": "slides/convergence.html#recursive-sequence",
    "href": "slides/convergence.html#recursive-sequence",
    "title": "Convergence of sequences",
    "section": "Recursive sequence",
    "text": "Recursive sequence\nConsider a function \\(f: R\\rightarrow R\\) and a recursive sequence \\((x_n)\\) defined by \\(x_0\\) and \\(x_n = f(x_{n-1})\\).\nWe want to compute a fixed point of \\(f\\) and study its properties."
  },
  {
    "objectID": "slides/convergence.html#example-growth-model",
    "href": "slides/convergence.html#example-growth-model",
    "title": "Convergence of sequences",
    "section": "Example: growth model",
    "text": "Example: growth model\n\n\n\nSolow growth model:\n\ncapital accumulation: \\[k_t = (1-\\delta)k_{t-1} + i_{t-1}\\]\nproduction: \\[y_t = k_t^\\alpha\\]\nconsumption: \\[c_t = (1-{\\color{red}s})y_t\\] \\[i_t = s y_t\\]\n\n\n\n\n\n\nFor a given value of \\({\\color{red} s}\\in\\mathbb{R}^{+}\\) ( \\({\\color{red} s}\\) is a decision rule) \\[k_{t+1} = f(k_t, {\\color{red} s})\\]\n\nbackward-looking iterations\nSolow hypothesis: saving rate is invariant\n\n\n\n\n\nQuestions:\n\nWhat is the steady-state?\nCan we characterize the transition back the steady-state?\nCharacterize the dynamics close to the steady-state?\n\nnext session\n\nwhat is the optimal \\(s\\) ?"
  },
  {
    "objectID": "slides/convergence.html#another-example-linear-new-keynesian-model",
    "href": "slides/convergence.html#another-example-linear-new-keynesian-model",
    "title": "Convergence of sequences",
    "section": "Another example: linear new keynesian model",
    "text": "Another example: linear new keynesian model\n\n\n\nBasic New Keynesian model (full derivation if curious )\n\nnew philips curve (PC):\\[\\pi_t = \\beta \\mathbb{E}_t \\pi_{t+1} + \\kappa y_t\\]\ndynamic investment-saving equation (IS):\\[y_t = \\beta \\mathbb{E}_t y_{t+1} - \\frac{1}{\\sigma}(i_t - \\mathbb{E}_t(\\pi_{t+1}) ) - {\\color{green} z_t}\\]\ninterest rate setting (taylor rule): \\[i_t = \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t\\]\n\n\n\n\nSolving the system:\nsolution: \\(\\begin{bmatrix}\\pi_t \\\\\\\\ y_t \\end{bmatrix} = {\\color{red} c} z_t\\)\n\n\n\n\n\nforward looking:\n\ntake \\(\\begin{bmatrix}\\pi_{t+1} \\\\\\\\ y_{t+1} \\end{bmatrix} = {\\color{red} {c_n}} z_{t+1}\\)\ndeduce \\(\\begin{bmatrix}\\pi_{t} \\\\\\\\ y_{t} \\end{bmatrix} = {\\color{red} {c_{n+1}}} z_{t}\\)\n\\(\\mathcal{T}: \\underbrace{c_{n}}_{t+1: \\; \\text{tomorrow}} \\rightarrow \\underbrace{c_{n+1}}_{t: \\text{today}}\\) is the time-iteration operator (a.k.a. Coleman operator)\n\n\n\n\n\nQuestions:\n\nWhat is the limit to \\(c_{t+1} = \\mathcal{T} c_n\\) ?\nUnder wich conditions (on \\(\\alpha_{\\pi}, \\alpha_y\\)) is it convergent ?\n\ndeterminacy conditions\ninterpretation: does the central bank manage to control inflation expectations?"
  },
  {
    "objectID": "slides/convergence.html#recursive-series-2",
    "href": "slides/convergence.html#recursive-series-2",
    "title": "Convergence of sequences",
    "section": "Recursive series (2)",
    "text": "Recursive series (2)\n\nWait: does a fixed point exist?\n\nwe’re not very concerned by the existence problem here\nwe’ll be happy with local conditions (existence, uniqueness) around a solution\n\nWe can assume there is an interval such that \\(f([a,b])\\subset[a,b]\\). Then we know there exists \\(x\\) in \\([a,b]\\) such that \\(f(x)=x\\). But there can be many such points."
  },
  {
    "objectID": "slides/convergence.html#example-growth-model-with-multiple-fixed-points",
    "href": "slides/convergence.html#example-growth-model-with-multiple-fixed-points",
    "title": "Convergence of sequences",
    "section": "Example: growth model with multiple fixed points",
    "text": "Example: growth model with multiple fixed points\n\n\n\nIn the growth model, if we change the production function: \\(y=k^{\\alpha}\\) for a nonconvex/nonmonotonic one, we can get multiple fixed points."
  },
  {
    "objectID": "slides/convergence.html#convergence",
    "href": "slides/convergence.html#convergence",
    "title": "Convergence of sequences",
    "section": "Convergence",
    "text": "Convergence\n\nHow do we characterize behaviour around \\(x\\) such that \\(f(x)=x\\)?\n\nif \\(|f^{\\prime}(x)|>1\\): series is unstable and will not converge to \\(x\\) except by chance\nif \\(|f^{\\prime}(x)|<1\\): \\(x\\) is a stable fixed point\nif \\(|f^{\\prime}(x)|=1\\): ??? (look at higher order terms, details ↓)"
  },
  {
    "objectID": "slides/convergence.html#section",
    "href": "slides/convergence.html#section",
    "title": "Convergence of sequences",
    "section": "",
    "text": "To get the intution about local convergence assume, you have an initial point \\(x_n\\) close to the steady state and consider the following expresion:\n\\(x_{n+1} - x = f(x_n) - f(x) = f^{\\prime}(x) (x_n-x) + o( (x_n-x) )\\)\nIf one sets aside the error term (which one can do with full mathematical rigour), the dynamics for very small perturbations are given by:\n\\(|x_{n+1} - x| = |f^{\\prime}(x)| |x_n-x|\\)\nWhen \\(|f^{\\prime}(x)|<1\\), the distance to the target decreases at each iteration and we have convergence. When \\(|f^{\\prime}(x)|>1\\) there is local divergence."
  },
  {
    "objectID": "slides/convergence.html#section-1",
    "href": "slides/convergence.html#section-1",
    "title": "Convergence of sequences",
    "section": "",
    "text": "What about the case \\(|f^{\\prime}(x)=1|\\)? Many cases are possible. To distinguish between them, one needs to inspect higher order derivatives.\n\nwhen \\(|f^{\\prime}(x)=1|\\), \\(|f^{\\prime\\prime}(x)|\\neq 0\\) the series will convergence, only if \\((x_0-x)f^{\\prime\\prime}(x)<0\\), i.e. starting from one side of the fixed point. The steady-state is not stable.\nWhen \\(|f^{\\prime}(x)=1|\\), \\(|f^{\\prime\\prime}(x)| = 0\\), \\(|f^{\\prime \\prime\\prime}(x)|\\neq 0\\) the series will converge, only if \\(f^{\\prime}(x)(f^{\\prime\\prime\\prime}(x))<1\\)\n\nIn general, there is stability only if the function \\(f\\) is crossing the 45 degrees line (when \\(f^ {\\prime}(x)=1)\\), or the -45 degrees line (when \\(f^ {\\prime}(x)=1\\))\nMathematically, this involves, that: - the first non-zero coefficient \\(f^{k}(x)\\) with \\(k>1\\) has odd order (\\(k\\) odd) - it has the right sign"
  },
  {
    "objectID": "slides/convergence.html#change-the-problem",
    "href": "slides/convergence.html#change-the-problem",
    "title": "Convergence of sequences",
    "section": "Change the problem",
    "text": "Change the problem\n\nSometimes, we are interested in tweaking the convergence speed:\n\n\\[x_{n+1} = (1-\\lambda) x_n + \\lambda f(x_n)\\]\n\n\\(\\lambda\\) is the learning rate:\n\n\\(\\lambda>1\\): acceleration\n\\(\\lambda<1\\): dampening\n\nWe can also replace the function by another one \\(g\\) such that \\(g(x)=x\\iff f(x)=x\\), for instance:\n\n\\[g(x)=x-\\frac{f(x)-x}{f^{\\prime}(x)-1}\\]"
  },
  {
    "objectID": "slides/convergence.html#dynamics-around-a-stable-point",
    "href": "slides/convergence.html#dynamics-around-a-stable-point",
    "title": "Convergence of sequences",
    "section": "Dynamics around a stable point",
    "text": "Dynamics around a stable point\n\nWe can write successive approximation errors:\n\n\\[|x_t - x_{t-1}| =  | f(x_{t-1}) - f(x_{t-2})| \\]\n\\[|x_t - x_{t-1}| \\sim |f^{\\prime}(x_{t-1})| |x_{t-1} - x_{t-2}| \\]\n\nRatio of successive approximation errors \\[\\lambda_t =  \\frac{ |x_{t} - x_{t-1}| } { |x_{t-1} - x_{t-2}|}\\]\n\\(\\lambda_t \\rightarrow | f^{\\prime}(\\overline{x}) |\\)"
  },
  {
    "objectID": "slides/convergence.html#dynamics-around-a-stable-point-2",
    "href": "slides/convergence.html#dynamics-around-a-stable-point-2",
    "title": "Convergence of sequences",
    "section": "Dynamics around a stable point (2)",
    "text": "Dynamics around a stable point (2)\nHow do we derive an error bound? Suppose that we have \\(\\overline{\\lambda}>|f^{\\prime}(x_k)|\\) for all \\(k\\geq k_0\\):\n\\[|x_t - x| \\leq |x_t - x_{t+1}| + |x_{t+1} - x_{t+2}| + |x_{t+2} - x_{t+3}| + ... \\]\n\\[|x_t - x| \\leq |x_t - x_{t+1}| + |f(x_{t}) - f(x_{t+1})| + |f(x_{t+1}) - f(x_{t+2})| + ... \\]\n\\[|x_t - x| \\leq |x_t - x_{t+1}| + \\overline{\\lambda} |x_t - x_{t+1}| + \\overline{\\lambda}^2 |x_t - x_{t+1}| + ... \\]\n\\[|x_t - x| \\leq \\frac{1} {1-\\overline{\\lambda}} | x_t - x_{t+1} |\\]"
  },
  {
    "objectID": "slides/convergence.html#how-do-we-improve-convergence",
    "href": "slides/convergence.html#how-do-we-improve-convergence",
    "title": "Convergence of sequences",
    "section": "How do we improve convergence ?",
    "text": "How do we improve convergence ?\n\\[\\frac{|x_{t-1} - x_{t-2}|} {|x_t - x_{t-1}|} \\sim |f^{\\prime}(x_{t-1})|  \\]\ncorresponds to the case of linear convergence (kind of slow)."
  },
  {
    "objectID": "slides/convergence.html#aitkens-extrapolation",
    "href": "slides/convergence.html#aitkens-extrapolation",
    "title": "Convergence of sequences",
    "section": "Aitken’s extrapolation",
    "text": "Aitken’s extrapolation\nWhen convergence is geometric, we have: \\[ \\lim_{x\\rightarrow \\infty}\\frac{ x_{t+1}-x}{x_t-x} = \\lambda \\in \\mathbb{R}^{\\star}\\]\nWhich implies:\n\\[\\frac{ x_{t+1}-x}{x_t-x} \\sim \\frac{ x_{t}-x}{x_{t-1}-x}\\]"
  },
  {
    "objectID": "slides/convergence.html#aitkens-extrapolation-2",
    "href": "slides/convergence.html#aitkens-extrapolation-2",
    "title": "Convergence of sequences",
    "section": "Aitken’s extrapolation (2)",
    "text": "Aitken’s extrapolation (2)\nTake \\(x_{t-1}, x_t\\) and \\(x_{t+1}\\) as given and solve for \\(x\\):\n\\[x = \\frac{x_{t+1}x_{t-1} - x_{t}^2}{x_{t+1}-2x_{t} + x_{t-1}}\\]\nor after some reordering\n\\[x = x_{t-1} - \\frac{(x_t-x_{t-1})^2}{x_{t+1}-2 x_t + x_{t-1}}\\]"
  },
  {
    "objectID": "slides/convergence.html#steffensens-method",
    "href": "slides/convergence.html#steffensens-method",
    "title": "Convergence of sequences",
    "section": "Steffensen’s Method:",
    "text": "Steffensen’s Method:\n\nstart with a guess \\(x_0\\), compute \\(x_1=f(x_0)\\) and \\(x_2=f(x_1)\\)\nuse Aitken’s guess for \\(x^{\\star}\\). If required tolerance is met, stop.\notherwise, set \\(x_0 = x^{\\star}\\) and go back to step 1.\n\nIt can be shown that the sequence generated from Steffensen’s method converges quadratically, that is\n\\(\\lim_{t\\rightarrow\\infty} \\frac{x_{t+1}-x_t}{(x_t-x_{t-1})^2} \\leq M \\in \\mathbb{R}^{\\star}\\)"
  },
  {
    "objectID": "slides/convergence.html#convergence-speed",
    "href": "slides/convergence.html#convergence-speed",
    "title": "Convergence of sequences",
    "section": "Convergence speed",
    "text": "Convergence speed\nRate of convergence of series \\(x_t\\) towards \\(x^{\\star}\\) is:\n\nlinear: \\[{\\lim}\\_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|} = \\mu \\in R^+\\]\nsuperlinear: \\[{\\lim}\\_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|} = 0\\]\nquadratic: \\[{\\lim}\\_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|^{\\color{red}2}} = \\mu \\in R^+\\]"
  },
  {
    "objectID": "slides/convergence.html#convergence-speed-1",
    "href": "slides/convergence.html#convergence-speed-1",
    "title": "Convergence of sequences",
    "section": "Convergence speed",
    "text": "Convergence speed\nRemark: in the case of linear convergence:\n\\[{\\lim}_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x_t|}{|x_{t}-x_{t-1}|} = \\mu \\in R^+ \\iff {\\lim}\\_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|}=\\frac{1}{1-\\mu}\\]"
  },
  {
    "objectID": "slides/convergence.html#in-practice",
    "href": "slides/convergence.html#in-practice",
    "title": "Convergence of sequences",
    "section": "In practice",
    "text": "In practice\n\nProblem:\n\nSuppose one is trying to find \\(x\\) solving the model \\(G(x)=0\\)\nAn iterative algorithm provides a function \\(f\\) defining a recursive series \\(x_{t+1}\\).\n\nThe best practice consists in monitoring at the same time:\n\nthe success criterion: \\[\\epsilon_n = |G(x_n)|\\]\n\n\nhave you found the solution?\n\nthe successive approximation errors \\[\\eta_n = |x_{n+1} - x_n|\\]\n\n\nare you making progress?\n\nthe ratio of successive approximation errors \\[\\lambda_n = \\frac{\\eta_n}{\\eta_{n-1}}\\]\n\n\nwhat kind of convergence? (if \\(|\\lambda_n|<1\\): OK, otherwise: ❓)"
  },
  {
    "objectID": "slides/perturbation.html",
    "href": "slides/perturbation.html",
    "title": "Introduction to Computational Economics",
    "section": "",
    "text": "Many models with continuous values/states\n\ndon’t have a closed form solution…\nare subject to the curse of dimensionality…\nand other approximation challenges…\n…unless we can solve them around a steady-state\n\nPerturbation analysis\n\nassume a model has a steady-state\nconsiders small deviations around the steady-state\n\nrelatively easy to implement\nscales well (-> DSGE modelling in Central Banks)\n\n\n\n\n\n\n\nTo compute the perturbed solution, we need:\n\na suitable representation of the model\n\n\nget rid of \\(\\max\\) operator\nfirst order conditions\n\n\nthe steady-state\nthe derivatives of the model at the steady-state\n\n\na linear representation\n\n\nto solve the linear system\n\n\nlinear time iteration\n\nIn practice, 2., 3. and 4. are done automatically\n\n\n\n\n\n\n\n\n\n\nFirst order conditions can be obtained using two approaches\n\nUsing the Bellman representation\n\nderive first order\nuse enveloppe condition \\[V(s) = \\max_{x} ... + \\beta \\left[ V(s') \\right]\\]\n\nUsing the infinite sum representation\n\nusing the lagrangian (today: 😋) \\[\\max \\sum \\beta^t U(c_t)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaby constrained problem: \\[\\max_{x,y} f(x,y)\\] \\[g(x,y)-c=0\\]\nLagrangian approach: \\[\\mathcal{L}(x,y) = f(x,y) + \\lambda \\left(g(x,y) - c \\right)\\]\nOptimal solution satisfies: \\[\\mathcal{L}^{\\prime}_x(x,y)=\\mathcal{L}^{\\prime}_y(x,y)=0\\]\nOr \\[\\begin{bmatrix} f^{\\prime}_x\\\\\\\\f^{\\prime}_y\\end{bmatrix} = - \\lambda \\begin{bmatrix} g^{\\prime}_x\\\\\\\\g^{\\prime}_y\\end{bmatrix} \\]\n\n\n\n\n\n\n\n\nLook at the optimization problem: \\[\\max_{c_1, c_2} \\log(c_1) + \\beta \\log(c_2)\\] \\[c_1+c_2= C\\]\nWrite down the lagrangian: \\[\\mathcal{L}(c_1, c_2) =  \\log(c_1) + \\beta \\log(c_2) - \\lambda (c_1 + c_2 - C)\\]\nFirst order conditions: \\[ \\frac{1}{c_1} = \\beta \\frac{1}{c_2} = \\lambda\\]\n\n\n\n\n\n\nLook at the infinite horizon optimization problem: \\[\\max_{c_0, ,... c_t, ...} \\sum_{t=0}^{\\infty} \\beta^t \\log(c_t)\\] \\[\\sum_{t=0}^{\\infty} c_t = C\\]\nThis problem is known as a cake-eating problem (usually there is also \\(c_t\\geq0\\))\nWrite the lagrangian to the infinite (and beyond ??) \\[\\mathcal{L}(c_0, c_1, ..., c_t, ...) =  \\sum_{t=0}^{\\infty} \\beta^t \\log(c_t) - \\lambda \\left( \\sum_t c_t  - C \\right)\\]\nFirst order conditions: \\[ \\beta^t \\frac{1}{c_t}  = \\lambda\\]\n\n\n\n\n\n\nThe key consists in finding which terms to derive in the sum\nConsider the reformulation of the former problem: \\[\\max \\sum_{t=0}^{\\infty} \\beta^t \\log(c_t)\\] \\[\\forall t, \\\\; C_{t+1} = C_t - c_t\\]\nThis time the maximum is taken over \\(c_0, c_1, ...\\), \\(C_1, C_2, ...\\)\n\npay attention to the timing: \\(C_0\\) is predetermined\n\nSet a different lagrange multplier \\(\\lambda_t\\) for each date. You should get: \\[\\forall t, \\\\; \\beta^t U^{\\prime}(c_t) = \\lambda_t\\] \\[\\lambda_t = \\lambda_{t+1}\\]\nIt can be reformulated as \\(U^{\\prime}(c_t) = \\beta U^{\\prime}(c_{t+1})\\) (Euler equation)\nNote that we are missing one condition to close the model (for instance \\(C_t\\geq 0\\))\n\n\n\n\n\n\nThe approach outlined, works in the same way when there are several constraints.\nNext steps:\n\nstochastic problem \\[\\max \\mathbb{E}  \\left[\\sum_t\\beta^t U(c_t) \\right]\\]\nineqality constraints\n\nnot very different but multipliers can be 0 (binding) or positive (nonbinding)\ntheory due to Karush-Kuhn-Tucker rather than Lagrange\n\n\n\n\n\n\n\n\n\n\n\n\nTransition Equation \\[\\begin{eqnarray}\nk_t & = & (1-\\delta) k_{t-1} + i_{t-1} \\\\\\\\\nz_t & = & \\rho z_{t-1}\n\\end{eqnarray}\n\\]\nBudget constraint: \\[c_t = \\exp(z_t) k_t^\\alpha - i_t\\]\nControl \\(c_t \\in [0, \\exp(z_t) k_t^{\\alpha}]\\)\nObjective (satisfying the constraints) \\[\\max_{i_t} \\sum_{t\\geq0} \\beta^t U(c_t)\\]\n\n\n\n\nCalibration:\n\n\\(\\beta = 0.96\\)\n\\(\\delta = 0.1\\)\n\\(\\gamma = 4.0\\)\n\\(\\alpha = 0.3\\)\n\\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\)\n\nRemark: optimally agent will never choose \\(c_t=0\\) or \\(c_t= \\exp(z_t) k_t^{\\alpha}\\)\n\nwe ignore associated inequality constraints\n\n\n\n\n\n\n\nInitial Conditions (predetermined states): \\(z_0\\), \\(k_0\\)\nProblem: \\[V(z_0, k_0) = \\max_{\\begin{matrix}i_0, i_1, i_2, \\cdots \\\\\\\\c_0, c_1, c_2 \\cdots \\\\\\\\ k_1, k_2, \\cdots\\end{matrix}} \\sum_{t \\geq 0}\\beta^t U(c_t)\\] s.t. \\(\\forall t\\geq 0\\) \\[\\begin{eqnarray}\n\\lambda_t:\\quad &  i_t & = & \\exp(z_t) k_t^{\\alpha} - c_t\\\\\\\\\nq_t:\\quad &  k_{t+1} & = & (1-\\delta) k_{t} + i_{t}\n\\end{eqnarray}\\]\nLagrangian: \\[\\mathcal{L(z_0, k_0)} =   \\sum_{t \\geq 0} \\beta^t\\left\\\\{ U(c_t) +  \\lambda_t \\left(\\exp(z_t) k_t^{\\alpha}  - i_t -c_t \\right)  + q_t \\left( (1-\\delta) k_{t} + i_{t} - k_{t+1} \\right) \\right\\\\}\\]\n\n\n\n\n\n\n\n\nWe maximize the lagrangian to get:\n\n\\[\\begin{eqnarray}\n\\forall t\\geq0 & \\frac{\\partial \\mathcal{L}}{\\partial i_t} & = & 0 \\\\\\\\\n& \\frac{\\partial \\mathcal{L}}{\\partial c_t} & = & 0 \\\\\\\\\n& \\frac{\\partial \\mathcal{L}}{\\partial k_{t+1}} & = & 0\n\\end{eqnarray}\\]\n\nIt is important to note that we don’t differentiate with respect to a predetermined state\n\ncheck that you don’t differentiate w.r.t. \\(k_0\\)\n\nIt looks like the first order condition added two new variables \\(\\lambda_t\\), \\(q_t\\)\n\n\n\n\nLuckily these variables are associated to constraints. | | | —————————————- | | \\((1-\\delta) k_{t} + i_{t} - k_{t+1} = 0\\) | | \\(\\exp(z_t) k_t^{\\alpha} - i_t -c_t = 0\\) |\n\nwhich make the problem square again\n\n\n\n\n\n\n\n\n\nOptimality Condition: \\[\\beta  \\left[ \\frac{\\left(c_{t+1}\\right)^{-\\gamma}}{\\left(c_t\\right)^{-\\gamma}} \\left( (1-\\delta + \\alpha \\exp(z_{t+1}) k_{t+1}^{\\alpha -1}) \\right)\\right] = 1\\]\n\nTakes into account the fact that optimally \\(c_t>0\\) and \\(i_t>0\\).\n\nBudget Constraint: \\[c_t = exp(z_t) k_t^\\alpha - i_t\\]\nTransition: \\[k_t = (1-\\delta) k_{t-1} + i_{t-1}\\] \\[z_t = \\rho z_{t-1}\\]\n\n\n\n\n\n\n\n\nSteady-State: \\(\\overline{i}, \\overline{k}, \\overline{z}\\) such that:\n\n\\(z_{t+1}=k_t=\\overline{z}\\)\n\\(k_{t+1}=k_t=\\overline{k}\\)\n\\(i_{t+1}=i_t=\\overline{i}\\)\n\n…satisfy the first order conditions\n…i.e. \\[\\beta   \\left( (1-\\delta + \\alpha {\\overline{k}}^{\\alpha -1}) \\right) = 1\\] \\[\\overline{k}=  (1-\\delta) \\overline{k} + \\overline{i}\\] \\[\\overline{z} = \\rho \\overline{z}\\]\n\n\n\n\nSolution?\n\nclosed-form\nnumerical\n\nHere we can get a closed form:\n\n\\[\\begin{eqnarray}\n\\overline{k} & = & \\left( \\frac{\\frac{1}{\\beta}-(1-\\delta)}{\\alpha} \\right)^{\\frac{1}{\\alpha - 1}} \\\\\\\\\n\\overline{i} & = & \\delta \\overline{k} \\\\\\\\\\\n\\overline{z} & = & 0\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\n\n\n\n\nWe know the model at the steady-state\nLinearize it around the steady-state\nCharacterize its dynamics for small deviations around the steady-state\n\n\n\n\n\n\nTake function \\(f: \\\\; \\mathbb{R}\\rightarrow \\mathbb{R}\\)\n\ndefine model $ t \\; x_t = f(x_{t-1})$\n\n\nFind steady-state \\(\\overline{x}\\) s.t. \\(f(\\overline{x})=\\overline{x}\\)\n\nTaylor expansion: \\[ \\overline{x} + (x_{t} - \\overline{x}) \\approx f(\\overline{x}) + f^{\\prime}(\\overline{x})(x_{t-1}-\\overline{x})\\]\n\nFirst order model: \\[ \\lambda (x_{t-1} - \\overline{x}) = (x_{t}-\\overline{x}) \\]\n\nEasy to solve: \\[x_t-\\overline{x} = \\lambda^t (x_0 - \\overline{x})\\]\n\n\n\n\n\n\nTake function \\(f: \\\\; \\mathbb{R}\\rightarrow \\mathbb{R}\\)\n\ndefine model implicitly by \\[\\forall t \\\\; f(x_{t-1}, x_{t})=0\\]\n\nFind steady-state \\(\\overline{x}\\) such that: \\[f(\\overline{x}, \\overline{x})=0\\]\n\n\n\n\nImplicit Function Theorem: there is a unique \\(\\varphi\\) such that \\[\\forall x_t \\\\; f(x_t, \\varphi(x_{t})) = 0\\]\nIt satisfies \\(\\varphi(\\overline{x})=\\overline{x}\\) and \\(\\varphi^{\\prime}(\\overline{x}) = - \\frac{f^{\\prime}\\_{x_t}(\\overline{x}, \\overline{x})}{f^{\\prime}\\_{x_{t-1}}(\\overline{x}, \\overline{x})}\\)\n\n\n\n\nIn practice, we use the undetermined coefficient method\nApproximate model close to \\(\\overline{x}\\) by: \\[\\underbrace{f^{\\prime}\\_{x\\_{t-1}}}\\_{A} (x\\_{t-1}-\\overline{x}) + \\underbrace{f^{\\prime}\\_{x\\_t}}\\_{B} (x_{t}-\\overline{x}) = 0\\]\nLook for \\((x_t-\\overline{x})=\\lambda (x_{t-1}-\\overline{x})\\) with unknown \\(\\lambda\\).\n\\(\\lambda\\) satisfies \\(\\lambda = -\\frac{A}{B}\\)\n\n\n\n\n\n\n\n\nIn general economic models link future and past: \\[\\forall t \\\\; f(x_{t-1}, x_t, x_{t+1}) = 0\\]\nLinearize model: \\[A \\Delta x_{t-1} + B \\Delta x_t + C x_{t+1} \\\\equiv 0\\]\nLook for a recursive solution as: \\[x_t = \\lambda x_{t-1}\\]\n\\(\\lambda\\) is one of two roots \\(\\lambda_1, \\lambda_2\\) of \\(A + B X + C X^2\\)\nThere is a unique, stable solution iff \\(\\lambda_1 \\leq 1 < \\lambda_2\\)\n\n\n\n\n\n\n\n\n\nWrite all variables in deviation to the steady-state: \\[z_{t}=\\overline{z} + \\Delta z_t\\] \\[k_{t}=\\overline{k} + \\Delta k_t\\] \\[i_{t}=\\overline{i} + \\Delta i_t\\] \\[c_{t}=\\overline{c} + \\Delta c_t\\]\n\nRemark: some smart economists use log-deviations (i.e. \\(x_t = \\overline{x} \\hat{x}_t\\) to make computations easier)\n\n\n\n\n\nReplace in the system \\[\\beta  \\left[ \\frac{\\left(\\overline{c}+ \\Delta c_{t+1}\\right)^{-\\gamma}}{\\left(\\overline{c} + \\Delta c_t\\right)^{-\\gamma}} \\left( (1-\\delta + \\alpha (\\overline{k} + \\Delta k_{t+1})^{\\alpha -1}) \\right)\\right] = 1\\] \\[\\overline{c} + \\Delta c_t = (\\overline{k}+ \\Delta k_t)^\\alpha - \\overline{i} - \\Delta i_t\\] \\[\\overline{k} + \\Delta k_t = (1-\\delta) (\\overline{k}+ \\Delta k_{t-1}) + \\overline{i }+ \\Delta i_{t-1}\\] \\[\\overline{z }+ \\Delta z_t = \\overline{z}+ \\Delta \\rho z_{t-1}\\]\nDifferentiate…\n(if we want to limit the number of equations, we can replace \\(c_t\\) by its value)\n\n\n\n\n\n\n\nOptimality Condition \\[\\begin{bmatrix} . & . & . \\\\ \\end{bmatrix} \\begin{bmatrix} \\Delta c_t \\\\\\\\  \\Delta i_t \\\\\\\\ \\Delta k_t \\\\\\\\ \\Delta z_t \\end{bmatrix} = \\begin{bmatrix} . & . & . \\\\ \\end{bmatrix} \\begin{bmatrix} \\Delta c_{t+t} \\\\\\\\ \\Delta i_{t+1} \\\\\\\\ \\Delta k_{t+1} \\\\\\\\ \\Delta z_{t+1} \\end{bmatrix} \\]\nTransition \\[ \\begin{bmatrix} \\Delta k_t \\\\\\\\ \\Delta z_t \\end{bmatrix} = \\begin{bmatrix} . & .  \\\\\\\\ . & . \\end{bmatrix} \\begin{bmatrix} \\Delta k_{t-1} \\\\\\\\ \\Delta z_{t-1} \\end{bmatrix}  + \\begin{bmatrix} . \\end{bmatrix} \\begin{bmatrix}\\Delta  c_{t-1}\\\\\\\\ \\Delta i_{t-1}\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral formulation of a linearized model: \\[ \\begin{eqnarray} A s_t + B x_t + C s_{t+1} + D x_{t+1} & = & 0_{n_x} \\\\\\\\\ns_{t+1} & = & E s_t + F x_t \\end{eqnarray}\\] where:\n\n\\(s_t \\in \\mathbb{R}^{n_s}\\) is a vector of states\n\\(x_t \\in \\mathbb{R}^{n_x}\\) is a vector of controls\n\nRemark:\n\nfirst equation is forward looking\nsecond equation is backward looking\n\n\n\n\n\n\nIn the neoclassical model: \\[\\begin{eqnarray}\ns_t & = & (\\Delta z_t, \\Delta k_t) \\\\\\\\\nx_t & = & (\\Delta c_t, \\Delta i_t)\n\\end{eqnarray}\\]\nThe linearized system is: \\[\\begin{eqnarray}\nA & = & ...\\\\\\\\\nB & = & ...\\\\\\\\\nC & = & ...\\\\\\\\\nD & = & ...\\\\\\\\\nE & = & ...\\\\\\\\\nF & = &\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\n\n\n\nWhat is the solution of our problem?\nAt date \\(t\\) controls must be chosen as a function of (predetermined) states\nMathematically speaking, the solution is a function \\(\\varphi\\) such that: \\[\\forall t, x_t = \\varphi(s_t)\\]\nSince the model is linear we look for un unknown matrix \\(X \\in \\mathbb{R}^{n_x} \\times \\mathbb{R}^{n_s}\\) such that:\n\n\\[\\Delta x_t = X \\Delta s_t\\]\n\n\n\nIn the neoclassical model - The controls \\(c_t, i_t\\) must be a function of the states - there is a decision rule \\(c(), i()\\) such that \\[c_t=c(z_t, k_t) \\\\; i_t = i(z_t, k_t)\\] - In the linearized model: \\[\\Delta c_t =c_z \\Delta c_t + c_k \\Delta k_t\\] \\[\\Delta i_t =i_z \\Delta z_t + i_k \\Delta k_t\\]\n\n\\(k_t\\) and \\(z_t\\): the states\n\n\n\n\n\n\n\n\n\n\nReplacing in the system: \\[ \\begin{eqnarray}\n\\Delta x_t & = & X \\Delta s_t \\\\\\\\\n\\Delta s_{t+1} & = & E \\Delta s_t + F X \\Delta s_t \\\\\\\\\n\\Delta x_{t+1} & = & X \\Delta s_{t+1} \\\\\\\\\nA \\Delta s_t + B \\Delta x_t + C \\Delta s_{t+1} + D \\Delta x_{t+1} & = & 0\n\\end{eqnarray}\n\\]\nIf we make the full substitution:\n\n\\[( (A + B X) + ( D X + C) ( E  + F X ) ) s_t = 0\\]\n\n\n\nThis must be true for all \\(s_t\\). We get the special Ricatti equation:\n\n\\[(A + B \\color{red}{X}) + ( D \\color{red}{X} + C) ( E  + F \\color{red}{X} ) = 0 \\]\n\nthis is a quadratic, matrix ( \\(X\\) is 1 by 2 ) equation:\n\nrequires special solution method\nthere are multiple solutions: which should we choose?\n\ntoday: linear time iteration selects only one solution\nnext time: eigenvalues analysis\n\n\n\n\n\n\n\n\n\n\nLet’s be more subtle: define\n\n\\(X\\): decision rule today and\n\\(\\tilde{X}\\) is decision rule tomorrow. \\[\\begin{eqnarray}\n\\Delta x_t & =&  X \\Delta s_t \\\\\\\\\n\\Delta s_{t+1} & = & E \\Delta  s_t + F X \\Delta s_t \\\\\\\\\n\\Delta x_{t+1} & = & \\tilde{X} \\Delta s_{t+1} \\\\\\\\\nA \\Delta s_t + B \\Delta x_t + C \\Delta s_{t+1} + D \\Delta x_{t+1} & = & 0\n\\end{eqnarray}\\]\n\nWe get, \\(\\forall s_t\\): \\[(A + B X) + (C + D \\tilde{X}) ( E  + F X ) ) \\Delta s_t = 0 \\]\nAgain, this must be zero in all states \\(\\Delta s_t\\).\n\n\n\n\n\n\n\n\nWe get the equation: \\[F(X, \\tilde{X}) = (A + B X) + ( C+ D \\tilde{X}) ( E  + F X ) = 0 \\]\nConsider the linear time iteration algorithm\nWhen the model is well-specified it is guaranteed to converge to the right solution.\n\ncf linear time iteration by Pontus Rendahl (link)\n\nThere are simple criteria to check that the solution is right, and that the model is well specified\n\\(T\\) is the time iteration operator… for linear models\n\nit does forward iteration (\\(X_t\\) as a function of \\(X_{t+1}\\))\n\n\n\n\n\nalgorithm:\n\nchoose stopping criteria: \\(\\epsilon_0\\) and \\(\\eta_0\\)\nchoose random \\(X_0\\)\ngiven \\(X_n\\):\n\ncompute \\(X_{n+1}\\) such that \\(F(X_{n+1}, X_{n}) = 0\\) \\[(B + (C+D X_{n})F)X_{n+1} + A  + (C+D X_n )E=0\\]\\[X_{n+1} = (B + (C + D X_n) F)^{-1} (A + (C+DX_n)E)\\]\\[X_{n+1} = T(X_n)\\]\ncompute:\n\n\\(\\eta_n = |X_{n+1} - X_n|\\)\n\\(\\epsilon_n = F(X_{n+1}, X_{n+1})\\)\n\nif \\(\\eta_n<\\eta_0\\) and \\(\\epsilon_n<\\epsilon_0\\)\n\nstop and return \\(X_{n+1}\\)\notherwise iterate with \\(X_{n+1}\\)\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have found the solution \\(\\Delta x_t = X \\Delta s_t\\)\nRecall the transition equation: \\(\\Delta s_{t+1} = F \\Delta s_t + G \\Delta x_t\\)\nWe can now compute the model evolution following initial deviation in the state: \\[\\Delta s_t = \\underbrace{(F + G X)}\\_{P} \\Delta s\\_{t-1}\\]\n\n\\(P\\) is the simulation operator\nit does backward iteration (TODO: example of a reaction to a shock)\n\nThe system is stable if the biggest eigenvalue of \\(P\\) is smaller than one…\n… or if its spectral radius is smaller than 1: \\[\\rho(P)<1\\]\nThis condition is called backward stability\n\nit rules out explosive solutions\nif \\(\\rho(P)>1\\) one can always find \\(s_0\\) such that the model simulation diverges\n\n\n\n\n\n\n\n\n\nHow do you compute the spectral radius of matrix P?\n\nnaive approach: compute all eigenvalues, check the value of the biggest one…\nbetter approach: power iteration method\n\nPower iteration method:\n\ntake a linear operator \\(L\\) over a Banach Space \\(\\mathcal{B}\\) (vector space with a norm)\nuse the fact that for most \\(u_0\\in \\mathcal{B}\\), \\(\\frac{|L^{n+1} u_0|}{|L^n u_0|}\\rightarrow \\rho(L)\\)\n\n\n\n\n\nAlgorithm:\n\nchoose tolerance criterium: \\(\\eta>0\\)\nchoose random initial \\(x_0\\) and define \\(u_0 = \\frac{x_0}{|x_0|}\\)\n\nby construction: \\(|u_0|=1\\)\n\ngiven \\(u_n\\), compute\n\n\\(x_{n+1} = L.u_n\\)\n\\(u_{n+1} = \\frac{x_{n+1}}{|x_{n+1}|}\\)\ncompute \\(\\eta_{n+1} = |u_{n+1} - u_n|\\)\nif \\(\\eta_{n+1}<\\eta\\):\n\nstop and return \\(|x_{n+1}|\\)\nelse iterate with \\(u_{n+1}\\)\n\n\n\n\n\n\n\n\n\n\n\nTo solve the model we use the backard operator: \\[T: \\begin{eqnarray} \\mathbb{R}^{n_x} \\times \\mathbb{R}^{n_s}  & \\rightarrow &  \\mathbb{R}^{n_x} \\times \\mathbb{R}^{n_s}  \\\\\\\\X_{t+1} & \\mapsto & X_t \\text{s.t.} F(X_t,X_{t+1})=0\\end{eqnarray}\\]\nWhat about its stability?\n\nTODO: interpretation\n\nRecall: fixed point \\(\\overline{z}\\) of recursive sequence \\(z_n=f(z_{n_1})\\) is stable if \\(|f^{\\prime}(\\overline{z})|<1\\)\nWe need to study \\(T^{\\prime}\\) of (\\(X\\)).\n\nbut \\(T\\) maps a matrix to another matrix 🐉😓\nhow do we differentiate it?\n\n\n\n\n\n\n\n\nConsider a Banach Space \\(\\mathcal{B}\\).\nConsider an operator (i.e. a function): \\(\\mathcal{T}: \\mathcal{B} \\rightarrow \\mathcal{B}\\).\nConsider \\(\\overline{x} \\in \\mathcal{B}\\).\n\\(\\mathcal{T}\\) is differentiable at \\(\\overline{x}\\) if there exists a bounded linear operator \\(L \\in \\mathcal{L}(\\mathcal{B})\\) such that: \\[\\mathcal{T}(x) = \\overline{x} + L.(x-\\overline{x}) + o(|x-\\overline{x}|)\\]\nwhen it exists we denote this operator by \\(\\mathcal{T}^{\\prime}(\\overline{x})\\)\nRemarks:\n\nBounded operator means: \\(\\sup_{|x|=1} |L.x|<+\\infty\\)\nThis definition of a derivative is usually referred to as Fréchet-derivative\n\n\n\n\n\n\n\n\\(x\\) vector, A a matrix, \\(T(x) = Ax\\)\n\nthen \\(T(x+u) = Ax + A.u + 0\\)\n\\(T^{\\prime}(x) = A\\) for all x\n\n\\(A\\) a matrix, B a matrix, X a matrix: \\(T(X) = A X B\\)\n\nthen \\(T(X+u) = A X B + A u B + 0\\)\n\\(T^{\\prime}(X).u = A u B\\)\n\n\\(A\\) a matrix, X a matrix: \\(T(X) = A X B\\)\n\nthen \\(T(X+u) = A X B + A u B\\)\n\\(T^{\\prime}(X).u = A u B\\)\n\n\n\n\n\n\n\n\\(T(X)\\) is implicitly defined by \\(F(T(X), X)=0\\)\n\\(F(X,Y) = (A + B X) + ( C+ D Y) ( E + F X )\\)\n\nit is linear in \\(X\\) and in \\(Y\\)\n\n\\(F^{\\prime}_X (X, Y).u = (B + (C+DY)F) u\\)\n\na regular matrix multiplication\nits inverse is: \\(F^{\\prime}_X (X, Y)^{-1} = (B + (C+DY)F)^{-1}\\)\n\n\\(F^{\\prime}_Y (X, Y).u = D u (E+FX)\\)\n\na linear operation on matrices\n\n\n\n\n\n\n\nImplicit relation can be differentiated: \\[F^{\\prime}_X (T(X), X) T^{\\prime} (X) + F_Y^{\\prime}(T(X),X) = 0\\]\n\\(F^{\\prime}_X (T(X), X)\\) being a regular matrix, it is (conceptually) easy to invert: \\[T^{\\prime}(X) = -(F^{\\prime}_X (T(X), X))^{-1}F_Y^{\\prime}(T(X),X)\\]\nFinally, we get the explicit formula for the linear operator \\(T^{\\prime}\\) computed at the steady state: \\[T^{\\prime}(\\overline{X}).u = ((B + (C+D \\overline{X})F)^{-1})D u (E+F \\overline{X})\\]\nWe can compute the spectral radius of \\(T^{\\prime}(\\overline{X})\\) using the power iteration method\n\n\n\n\n\n\nWe compute the derivatives of the model\nTime iteration algorithm, starting from an initial guess \\(X_0\\) and we repeat until convergence: \\[X_{n+1} = (B + (C + D X_n) F)^{-1} (A + (C+DX_n)E)\\]\nWe compute the spectral radius of two operators to ensure the model is well defined and that the solution is the right one.\nbackward stability: derivative of simulation operator \\[\\rho(E + F \\overline{X} )<1\\]\nforward stability: derivative of time iteration operator \\[\\rho \\left( u\\mapsto ((B + (C+D \\overline{X})F)^{-1})D u (E+F \\overline{X}) \\right) <1\\]\n\nThis is equivalent to the so-called Blanchard-Kahn conditions."
  }
]