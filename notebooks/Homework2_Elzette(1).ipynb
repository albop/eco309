{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "Elzette Janse van Rensburg\n",
    "\n",
    "## Mc-Call Job Search Model with Separation\n",
    "\n",
    "We consider here a very simple job-search model, with separation. Our goal here consists in solving this model using a policy iteration algorithm.\n",
    "\n",
    "### Model\n",
    "\n",
    "There is a single worker who can be either employed (\"e\") or unemployed (\"u\") in any period.\n",
    "\n",
    "When unemployed, the jobless worker receives unemployment benefits $c_t=\\alpha>0$ in every period as long as he stays unemployed. He also receives a salary offer $w_t$ which is drawn from a discrete i.i.d. distribution, which takes values $w_1, ..., w_K$ with probabilities $p_1, ... p_K$ respectively.\n",
    "\n",
    "When an unemployed worker accepts an offer in period $t$, he gets the salary $w_t$ and becomes employed. He then keeps his salary $w_t$ as long as he stays employed (for $s\\geq t$, $c_s=w_t$ if $t$ is the date at which worker got the current job); in each period he has a probability $\\lambda$ of becoming unemployed in the next period and remains employed otherwise.\n",
    "\n",
    "When a worker receives a given amount $x$ his perceived utility is $U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}$ with $\\gamma>1.0$. A worker discounts the future at a rate $\\beta \\in [0,1[$. As a result, in any period $t_0$ workers seek to maximize $\\sum_{t\\geq t_0}^{\\infty} U(c_t)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define a parameter type `Parameter`, with fields $\\alpha$, $\\beta$, $\\gamma$, $K$, $\\sigma$, $\\lambda$. Create a parameter variable $\\omega$ with $\\alpha=0.5$, $\\beta=0.96$, $\\gamma=4$, $K=10$, $\\sigma=0.6$, $\\lambda=0.015$__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Parameter\n",
    "    α::Float64\n",
    "    β::Float64\n",
    "    γ::Int64    \n",
    "    K::Int\n",
    "    σ::Float64\n",
    "    λ::Float64 \n",
    "end\n",
    "\n",
    "ω = Parameter(0.5,0.96,4,10,0.6,0.015)\n",
    "\n",
    "ω.K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the uniform distribution, whose mean is 1 and standard deviation is $\\sigma$? Write a function `discrete_uniform(σ::Float64, K::Int64)::Tuple{Vector{Float64, Float64}}` to discretize it, using $K$ points. The function should return two vectors `w` and `p` of floats of the same size `K`. Check the results satisfy the conditions (uniformity, standard deviation).__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A uniform distribution on the interval (a, b) has a mean $μ = (a+b)/2 $ and a variance $ σ^2= (b-a)^2/12$. Thereby, a uniform distribution with standard deviation $\\sigma$ and  mean $μ = 1$ is a uniform distribution on the interval $(1-\\frac{\\sqrt{12} \\sigma}{2}, 1+\\frac{\\sqrt{12} \\sigma}{2}$). Below is a discete version of the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discrete_uniform (generic function with 1 method)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function discrete_uniform(σ::Float64, K::Int64)\n",
    "    \n",
    "    a = 1 - (12)^0.5*σ/2\n",
    "    b = 1 + (12)^0.5*σ/2\n",
    "    w = [LinRange(a, b, K)...]\n",
    "    p = [1/K for i=1:K]\n",
    "    \n",
    "    return (w,p) #w: certain wage  p:probablilty of getting wage \n",
    "end \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the discrete distribution is:0.9999999999999998\n",
      "The standard deviation of the discrete distribution is:0.6633249580710798\n"
     ]
    }
   ],
   "source": [
    "w, p = discrete_uniform(ω.σ, ω.K)\n",
    "\n",
    "μ = dot(w,p)  #mean\n",
    "σ = ( dot( (w-ones( ω.K )).^2 , p) )^0.5 #standard deviation \n",
    "\n",
    "\n",
    "println(\"The mean of the discrete distribution is:\",μ)\n",
    "println(\"The standard deviation of the discrete distribution is:\",σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal decision of a worker is characterized by two value functions: $V^E(w)$ the value of being employed at wage $w$ and $V^U(w)$ the value of being unemployed, while receiving job offer $w_t$. In Julia, both $V^U$ and $V^E$ will be represented by arrays `V_U` and `V_E` of size `K`.\n",
    "\n",
    "A policy `g` is a binary choice in the unemployed state: accept or reject an offer $w_t$. It will then naturally be represented by a boolean array (type `zeros(Bool, K)` to initialize one).\n",
    "\n",
    "__Given a policy $g$, write down the recursive equation which defines the corresponding value functions $V^{U,g}(w)$ and $V^{E,g}(w)$.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the next update will be given by: \n",
    "$$\n",
    "V(w) = \\begin{cases}\n",
    "V_E(w)  \\text{ if } g=1 \\\\\n",
    "V_U(w)  \\text{ if } g=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Then, \n",
    "\n",
    "\n",
    "$$\n",
    "V^{E,g}_{t}(w) = util(w) +\\beta \\left[ (1-\\lambda)*V^E_{t+1}(w)+\\lambda * V^U_{t+1}(w) \\right] \n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "V^{U,g}_{t}(w) = util( \\alpha ) +\\beta \\left( \\sum_{w_i \\in W} max\\left(V^U_{t+1}(w_i),V^E_{t+1}(w_i) \\right) p(w_i) \\right) \n",
    "$$\n",
    "\n",
    "Note that the sum is an expectation over the future wages. From here on, I'm not quite going to use the guidance given by notebook, but take an alternative approach which I think is equivalent. Particularly, I will always be updating and returning both $V^E$ and $V^U$ not $V$ itself. I found it more convenient to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write a function which takes a guess $V^{U,g}(w)$ and $V^{E,g}(w)$ and a policy function $g$ as arguments (and other model parameters) and updates the values, according to the updating equations. This function could have signature `value_update(V_U::Vector{Float64}, V_E::Vector{Float64}, g::Vector{Bool}, ω::Parameter, w::Vector{Float64}, p::Vector{Float64})::Vector{Float64}` where the returned vector has the same size as the supplied ones.__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "next_value (generic function with 1 method)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function utilt(w,ω)\n",
    "    return ( w.^(1-ω.γ) )./(1-ω.γ)\n",
    "end\n",
    "\n",
    "\n",
    "function next_value( g,p,w,ω,V_u,V_e )\n",
    "\n",
    "            \n",
    "    #calculating next step \n",
    "    U_next =  ( utilt(ω.α,ω) + ω.β*dot( max.(V_u,V_e) , p ) )*ones(ω.K) \n",
    "    E_next =   utilt(w,ω) + ω.β*( (1-ω.λ)*V_e + ω.λ*V_u )\n",
    "\n",
    "    return (U_next,E_next)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3333333333333333"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = utilt(1,ω)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write a function `eval_policy(g::Vector{Bool}, ω::Parameter, w::Vector{Float64}, p::Vector{Float64}, η::Float64)::Tuple{Vector{Float64}, Vector{Float64}}` which iterates on `value_update` find the values that satisfy the evaluation equations for policy `g`.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance (generic function with 1 method)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taken notebook 7\n",
    "distance(A::Vector{Float64}, B::Vector{Float64}) = maximum( (u)->abs(u[1]-u[2]), zip(A[1],B[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_policy (generic function with 2 methods)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_policy(g::Vector{Bool}, ω::Parameter, w::Vector{Float64}, p::Vector{Float64}, η::Float64,V_U,V_E)\n",
    "\n",
    "    V_fin  = [ g[i] ? V_U[i] : V_E[i] for i in 1:ω.K ] \n",
    "    V = ones(ω.K)\n",
    "    \n",
    "    \n",
    "    V_us = [V_U] #initialize \n",
    "    V_es = [ V_E] #initialize \n",
    "    \n",
    "    val_V = [V_fin ] #keep track of values unemployed \n",
    "    T_max =1000000\n",
    "    i = 0\n",
    "    while (distance(V,V_fin) > η) & (i<T_max)\n",
    "\n",
    "        V_U,V_E =  next_value(g,p,w,ω,V_us[end],V_es[end])\n",
    "        \n",
    "        push!(  V_us,V_U)\n",
    "        push!( V_es,V_E)\n",
    "        \n",
    "        V_fin = [ g[i] ? V_E[i] : V_U[i] for i in 1:ω.K ]\n",
    "        push!(val_V, V_fin)\n",
    "        i += 1\n",
    "  \n",
    "        end \n",
    "    \n",
    "    return V_us[end], V_es[end]\n",
    "end \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write a function `improve_policy(g::Vector{Bool}, V_U::Vector{Bool}, V_E::Vector{Bool}, ω::Parameter, w::Vector{Float64}, p::Vector{Float64}, η::Float64)::Vector{Float64}` which returns the improved policy given guesses for the value function(s) at for $t+1$.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "improve_policy (generic function with 3 methods)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is still no bueno NEED TO FIX \n",
    "\n",
    "\n",
    "function improve_policy(g::Vector{Bool}, V_U::Vector{Float64}, V_E::Vector{Float64}, ω::Parameter, w::Vector{Float64}, p::Vector{Float64}, η::Float64)        \n",
    "    \n",
    "    V_Enew, V_Unew = eval_policy(g, ω, w, p, η,V_U,V_E)  \n",
    "    return convert(Vector{Bool},V_Enew .> V_Unew)\n",
    "end \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Bool,1}:\n",
       " 0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "\n",
    "j = [6,1,2,3]\n",
    "\n",
    "k = [l .> j]\n",
    "\n",
    "k = [ k[i] == 1 for i in 1:length(k)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Implement the policy function algorithm. Print the successive approximation errors and comment on the convergence speed.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_algorithm (generic function with 2 methods)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function policy_algorithm(ω)\n",
    "    #initialize value functions \n",
    "    #initialize policy \n",
    "    val_u = ones(ω.K)*0.3\n",
    "    val_e = ones(ω.K)*0.5\n",
    "    g = ones(ω.K) \n",
    "    g = [1==g[i] for i in 1:ω.K]\n",
    "    gs = [g]\n",
    "    η = 0.000001\n",
    "    vals = [ ones(ω.K), [g[i] ? val_e[i] : val_u[i] for i in 1:ω.K ] ]\n",
    "    \n",
    "    Tmax = 10000000\n",
    "    i = 1\n",
    "\n",
    "    \n",
    "    while (distance( vals[end],vals[end-1] ) > η) & (i < Tmax)\n",
    "        \n",
    "        #get max val using end policy \n",
    "        val_u, val_e = eval_policy(gs[end], ω, w, p, η, val_u,val_e)\n",
    "\n",
    "        \n",
    "\n",
    "        #update end policy to match max val\n",
    "        g_new = improve_policy( gs[end], val_u, val_e, ω, w, p, η )\n",
    "        push!(gs,g_new)\n",
    "        \n",
    "        val_fin = [ g_new[i] ? val_e[i] : val_u[i] for i in 1:ω.K ]\n",
    "        push!(vals, val_fin)\n",
    "        i += 1\n",
    "        \n",
    "    end    \n",
    "    \n",
    "    dif = [distance(vals[i],vals[i-1]) for i in 2:length(vals)]   \n",
    "    return  vals, dif \n",
    "end \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [88074.91803380546, 22444.291674581007, 23232.78963561277, 23292.002456908256, 23305.09483613894, 23309.534141468812, 23311.438463685983, 23312.387558754664, 23312.91261555881, 23313.22631967954], [88074.91803380546, 22444.291674581007, 23232.78963561277, 23292.002456908256, 23305.09483613894, 23309.534141468812, 23311.438463685983, 23312.387558754664, 23312.91261555881, 23313.22631967954]], [0.5, 88074.41803380546, 0.0])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals, dif = policy_algorithm(ω)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is converging extremely fast, I am not sure why or if it is right. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- \n",
    "## Bonus: reinforcement learning version\n",
    "\n",
    "The previous solution relied on perfect knowledge of the model: the probabilities, the effect of the policies... In this (optional section) we consider another way to solve the problem, where the agent only uses past experience to update the value and to improve its job-search policy.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neoclassical growth model (2)\n",
    "\n",
    "We consider here, another deterministic version of the neoclassical growth model, but propose a slightly different solution method.\n",
    "\n",
    "A representative agent uses capital $k_t$ to produce $y_t$ using the following production function:\n",
    "\n",
    "$$y_t = k_t^{\\alpha}$$\n",
    "\n",
    "He chooses to consume an amount $c_t \\in ]0, y_t]$ and invests what remains:\n",
    "\n",
    "$$i_t = y_t - c_t$$.\n",
    "\n",
    "He accumulates capital $k_t$ according to:\n",
    "\n",
    "$$k_{t+1} = \\left( 1-\\delta \\right) k_{t} + i_{t}$$\n",
    "\n",
    "where $\\delta$ is the depreciation rate and $i_t$ is the amount invested.\n",
    "\n",
    "The goal of the representative agent is to maximize:\n",
    "\n",
    "$$\\sum_{t\\geq 0} \\beta^t U(c_t)$$\n",
    "\n",
    "where $U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}$ and $\\beta<1$ is the discount factor.\n",
    "\n",
    "Since the problem is time homogenous, the value function only depends only on available capital and satisfies the following Bellman equation:\n",
    "\n",
    "$$V\\left(\\underbrace{k}_{k_t}\\right) = \\max_{c\\in[0,1[} U(c) + \\beta V\\left(\\underbrace{(1-\\delta)k + \\underbrace{(k^{\\alpha}-c)}_{y_{t+1}}}_{k_{t+1}}\\right)$$\n",
    "\n",
    "Our goal is to obtain a smooth approximation of $k$ and $V$ by using interpolations techniques.\n",
    "\n",
    "For this model, using the dynamic first-order conditions, ne can show the deterministic steady-state of the model satisfies $1=\\beta \\left( (1-\\delta) + \\alpha k^{\\alpha -1} \\right)$. \n",
    "\n",
    "__Create a suitable Parameter type to hold the paramters. Write a function `steady_state(p::Parameter)` to compute the steady-state capital `kbar` and the corresponding steady-state consumption `cbar`__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Param\n",
    "    α::Float64\n",
    "    β::Float64\n",
    "    γ::Float64\n",
    "    δ::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fact that the deterministic steady-state of the model satisfies $1=\\beta \\left( (1-\\delta) + \\alpha k^{\\alpha -1} \\right)$, we obtain $kbar = \\left( (\\frac{1}{β} + δ - 1)\\frac{1}{α} \\right)^{\\frac{1}{(α-1)}} $ and by using the fact that in the equilibrium $k_{t+1}=k_{t}$ combined with the otehr equations that govern the investment and production rules we obtain $cbar = kbar^α - δ*kbar$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steady_state (generic function with 1 method)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function steady_state(p::Param)\n",
    "    kbar = ((1/p.β + p.δ - 1)/p.α)^(1/(p.α-1)) \n",
    "    cbar = kbar^p.α - p.δ*kbar \n",
    "    return kbar, cbar\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set $N=10$ and define a reasonable grid `kgrid=range(kmin, kmax; length=N)` to approximate capital $k$.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "p = Param(0.5, 0.95, 3.0, 0.04) \n",
    "kbar, cbar = steady_state(p)\n",
    "\n",
    "\n",
    "kmin = kbar/2;\n",
    "kmax = 1.5* kbar;\n",
    "\n",
    "kgrid=range(kmin, kmax; length = N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The unknown value function is represented as a `N` elements arrays. Define `Vi(k,p)=δ * k^α` and compute the initial guess `V0 = [Vi(k) for k in kgrid]`. Define a finer grid `ktest=range(kmin, kmax;length=1000)` and find the values of `Vi` on it by  using `Interpolations.jl` library to interpolate `V0` between the points of `kgrid`.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.juliapro/JuliaPro_v1.4.0-1/environments/v1.4/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.juliapro/JuliaPro_v1.4.0-1/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Interpolations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Interpolations [a98d9a8b-a2ab-59e6-89dd-64a1c18fca59]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vi (generic function with 1 method)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Vi(k,p) \n",
    "    return (p.δ * k^p.α)^(1-p.γ)/((1-p.β)*(1-p.γ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element scale(interpolate(::Array{Float64,1}, BSpline(Linear())), (14.567729855371908:3.2372733011937576:43.703189566115725,)) with element type Float64:\n",
       " -429.0304709141268\n",
       " -351.024930747922\n",
       " -297.0210952482417\n",
       " -257.41828254847604\n",
       " -227.13377871924362\n",
       " -203.22495990669168\n",
       " -183.87020182034004\n",
       " -167.88148861857138\n",
       " -154.45096952908568\n",
       " -143.0101569713756"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V0 = [Vi(k,p) for k in kgrid] #get correspong Vi for all value in grid\n",
    "\n",
    "ktest= range(kmin, kmax; length = 1000)\n",
    "V0test = [Vi(k,p) for k in ktest] \n",
    "\n",
    "#interpolation \n",
    "\n",
    "interp = interpolate( V0, BSpline(Linear()) ) #estimate using linear spline \n",
    "interp_scaled= scale(interp, kgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compute a Bellman improvement function `bellman(V0::Vector{Float64}, p::Parameter, kgrid)::Tuple{Vector{Float64}, Vector{Float64}}` which does the following steps:__\n",
    "\n",
    "- take an initial guess `V0` for the value function\n",
    "\n",
    "- at each grid point from kvec, optimize nonlinearly, the function $c \\rightarrow U(c) + \\beta V\\left((1-\\delta)k + (k^{\\alpha}-c)\\right)$ for each capital level in the grid `kvec`. In this expression the function `V()` interpolates `V0` defined on `kvec` on any point `k` so that the resulting function is continuous. \n",
    "\n",
    "- return the updated value and investment rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bellman (generic function with 1 method)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that all code in this exercise is a slight modification form code in previous notebooks\n",
    "\n",
    "\n",
    "function bellman(V0::Vector{Float64}, p::Param, kgrid)\n",
    "  \n",
    "    V = deepcopy(V0)\n",
    "    C = zeros(length(V0))\n",
    "    for (n,k) in enumerate(kgrid)\n",
    "        nn0 = -1\n",
    "        gv = -Inf\n",
    "        copt = - 1.0\n",
    "        for (nn,kk) in enumerate(kgrid)\n",
    "            y = k^p.α\n",
    "            i = kk - (1 - p.δ) * k \n",
    "            c = y - i\n",
    "            \n",
    "            if c < 0 # can't have negative consumption ! \n",
    "                continue\n",
    "            end\n",
    "            \n",
    "\n",
    "            \n",
    "            interp = interpolate(V0, BSpline(Linear()))\n",
    "            interpscaled = scale(interp, kgrid)\n",
    "            esitp = extrapolate(interpscaled,Line());\n",
    "            \n",
    "            var = (1-p.δ) * kk + kk^p.α - c\n",
    "            v = c^(1-p.γ)/(1-p.γ) + p.β * esitp(var)\n",
    "            \n",
    "\n",
    "            if v > gv\n",
    "                gv = v\n",
    "                copt = c\n",
    "                nn0 = nn\n",
    "            end\n",
    "        end\n",
    "        V[n] = gv\n",
    "        C[n] = copt\n",
    "    end\n",
    "    return V, C\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write a value function interation function `vfi(N, p)` which solves the model defined by parameter `p` using the value function algorithm. The function should return the value function and the policy rule.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vfi (generic function with 1 method)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vfi(V0, p, tol, kgrid)\n",
    "    V0 = deepcopy(V0)\n",
    "    V,C = bellman(V0, p, kgrid)\n",
    "    \n",
    "    while distance(V,V0) > tol\n",
    "        V0 = V\n",
    "        V, C = bellman(V, p, kgrid)\n",
    "    end\n",
    "    return V, C\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot the solution__\n",
    "\n",
    "__Bonus 1: plot a graph showing the convergence back to the steady-state__\n",
    "\n",
    "__Bonus 2: implement the policy iteration algorithm by adding an evaluation step in the `vfi` function.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1260\n",
      "ERROR: LoadError: LoadError: EOFError: read end of file\n",
      "Stacktrace:\n",
      " [1] read(::IOStream, ::Type{Int64}) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [2] parse_cache_header(::IOStream) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [3] stale_cachefile(::String, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [4] _require_search_from_serialized(::Base.PkgId, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [5] _require(::Base.PkgId) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [6] require(::Base.PkgId) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [7] require(::Module, ::Symbol) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [8] include(::Module, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [9] include(::String) at /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/packages/FFMPEG_jll/tCUYA/src/FFMPEG_jll.jl:1\n",
      " [10] top-level scope at /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/packages/FFMPEG_jll/tCUYA/src/FFMPEG_jll.jl:50\n",
      " [11] include(::Module, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [12] top-level scope at none:2\n",
      " [13] eval at ./boot.jl:331 [inlined]\n",
      "in expression starting at /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/packages/FFMPEG_jll/tCUYA/src/wrappers/x86_64-apple-darwin14.jl:16\n",
      "in expression starting at /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/packages/FFMPEG_jll/tCUYA/src/FFMPEG_jll.jl:43\n",
      "ERROR: LoadError: Failed to precompile FFMPEG_jll [b22a6f82-2f65-5046-a5b2-351ab43fb4e5] to /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/compiled/v1.4/FFMPEG_jll/uSD0T_F2mWv.ji.\n",
      "Stacktrace:\n",
      " [1] error(::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [2] compilecache(::Base.PkgId, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [3] _require(::Base.PkgId) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [4] require(::Base.PkgId) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [5] require(::Module, ::Symbol) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [6] include(::Module, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [7] top-level scope at none:2\n",
      " [8] eval at ./boot.jl:331 [inlined]\n",
      "in expression starting at /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/packages/FFMPEG/vocw2/src/FFMPEG.jl:3\n",
      "ERROR: LoadError: Failed to precompile FFMPEG [c87230d0-a227-11e9-1b43-d7ebe4e7570a] to /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/compiled/v1.4/FFMPEG/TGvga_F2mWv.ji.\n",
      "Stacktrace:\n",
      " [1] error(::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [2] compilecache(::Base.PkgId, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [3] _require(::Base.PkgId) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [4] require(::Base.PkgId) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [5] require(::Module, ::Symbol) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [6] include(::Module, ::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " [7] top-level scope at none:2\n",
      " [8] eval at ./boot.jl:331 [inlined]\n",
      "in expression starting at /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/packages/Plots/Xnzc7/src/Plots.jl:15\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80] to /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/compiled/v1.4/Plots/ld3vC_F2mWv.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80] to /Users/Elzette/.juliapro/JuliaPro_v1.4.0-1/compiled/v1.4/Plots/ld3vC_F2mWv.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at /Applications/JuliaPro-1.4.0-1.app/Contents/Resources/julia/Contents/Resources/julia/lib/julia/sys.dylib:?",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1272",
      " [3] _require(::Base.PkgId) at ./loading.jl:1029",
      " [4] require(::Base.PkgId) at ./loading.jl:927",
      " [5] require(::Module, ::Symbol) at ./loading.jl:922",
      " [6] top-level scope at In[357]:1"
     ]
    }
   ],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[358]:3"
     ]
    }
   ],
   "source": [
    "tol = 0.00001\n",
    "V, C = vfi(V0 ,p, tol, kgrid)\n",
    "\n",
    "\n",
    "plot(kgrid, V)\n",
    "\n",
    "\n",
    "plot(kgrid, C)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.001\n",
    "V, C = vfi(V0test, p, tol, ktest)\n",
    "\n",
    "plot(ktest, V)\n",
    "\n",
    "plot(ktest, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
