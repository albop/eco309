{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MIE 37 - Final Exam 2024\n",
        "\n",
        "**Name**:\n",
        "\n",
        "**Surname**:\n",
        "\n",
        "After completing the following questions, send the edited notebook to\n",
        "`pablo.winant@ensae.fr`.\n",
        "\n",
        "You are allowed to use any online available resource, even to install\n",
        "Julia packages, but not to copy/paste any code.\n",
        "\n",
        "Also, don’t forget to comment your code and take any initiative you find\n",
        "relevant.\n",
        "\n",
        "## Part I - Linear Regression and Stochastic Gradient Descent\n",
        "\n",
        "We consider the following data generation process:\n",
        "\n",
        "$$y=0.4+2.5 x + \\epsilon$$\n",
        "\n",
        "where $x_i$ is uniformly distributed between 0 and 1 and $\\epsilon$ is\n",
        "drawn from a normal distribution with standard deviation $\\sigma=0.5$.\n",
        "\n",
        "1.  **Write a function\n",
        "    `draw(a::Number, b::Number)::Tuple{Float64, Float64}` which\n",
        "    generates one random draw for a pair $(x,y)$.**"
      ],
      "id": "8d79b9b7-69d8-4c8b-9250-45ac3d48d74a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "bd614686"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Generate a sample $d=(x_i, y_i)_{i=[1,N]}$ of $N=100000$ different\n",
        "    observations. Justify your choice for how to represent this data.**"
      ],
      "id": "9ce74982-0ce1-4379-8e68-4a5dee90bb5c"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "418409d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Write the loss function\n",
        "    $L(d,a,b)=\\frac{1}{N}\\sum_{i=1}^N ( a x_i + b-y_i)^2$. Find the\n",
        "    values of $a$ and $b$ minimizing this function by implementing the\n",
        "    gradient descent algorithm (do not use any library). What is the\n",
        "    best learning rate?**"
      ],
      "id": "16fac762-4f7f-4d96-93a7-0202189d05bf"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "cell-7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Write another function\n",
        "    `ξ(a::Number, b::Number)::Tuple{Float64, Float64, Float64}` which\n",
        "    returns a random realization of $( a x + b - y)^2$ as well as its\n",
        "    derivatives w.r.t. `a` and `b` (make sure the derivatives are\n",
        "    computed for the same realization of $\\epsilon$). We call `ξ` the\n",
        "    empirical loss.**\n",
        "\n",
        "(hint: here you can either compute the derivatives by hand, or use an\n",
        "automatic differentiation library)"
      ],
      "id": "a6b3ce82-5734-48a2-90fb-0f6530c729f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "2fced963"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. Stochastic gradient algorithm.**\n",
        "\n",
        "The stochastic gradient algorithm minimizes $$E\\xi(a,b)$$ with the\n",
        "following steps:\n",
        "\n",
        "-   start with an initial guess $a_0,b_0$\n",
        "-   given a guess $a_k, b_k$\n",
        "    -   compute $\\xi, \\xi^{prime}_a, \\xi^{prime}_b$ using the function\n",
        "        from the last function\n",
        "    -   make a new guess\n",
        "        $(a_{k+1}, b_{k+1}) = (1-\\lambda) (a_{k}, b_{k}) - \\lambda (\\xi^{\\prime}_a, \\xi^{\\prime}_b)$\n",
        "\n",
        "**Implement the SGD algorithm. How many iterations does one needs to get\n",
        "a good approximation of $a,b$? What value of \\$ \\$ works better? Compare\n",
        "with question 3.**"
      ],
      "id": "91c77dea-e9a8-459e-b297-ae67abc91c5d"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "b28908e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6. (bonus) Illustrate the convergence by plotting the empirical loss\n",
        "for each step $k$ in the above alogorithm, as well as the validation\n",
        "loss in the same step. (Given $a,b$, the validation loss is the\n",
        "empirical mean of $\\xi(a,b)$ computed using $N=1000$ observations.)**"
      ],
      "id": "397a391f-03cf-4520-b359-ed9157b9f355"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "e13268b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part II - Endogenous Exit\n",
        "\n",
        "### Discretization of an AR1\n",
        "\n",
        "The following code, taken from Quantecon.jl approximates an AR1 process\n",
        "$$y_t = \\mu + \\rho (y_{t-1}-\\mu) + \\epsilon_t$$ (where $\\nu$ is the\n",
        "standard deviation of normal process $\\epsilon$), using a finite markov\n",
        "chain with $N$ different values.\n",
        "\n",
        "The output is a transition matrix and a vector containing discretized\n",
        "values $y_1, y_2, ... y_p$"
      ],
      "id": "3ae6420a-3cef-4293-8f6e-af8e44f31192"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uncomment the following line if \"SpecialFunctions\" is not on your system\n",
        "# import Pkg; Pkg.add(\"SpecialFunctions\")"
      ],
      "id": "43cedb56"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tauchen (generic function with 3 methods)"
            ]
          }
        }
      ],
      "source": [
        "using SpecialFunctions: erfc\n",
        "\n",
        "std_norm_cdf(x::T) where {T <: Real} = 0.5 * erfc(-x/sqrt(2))\n",
        "std_norm_cdf(x::Array{T}) where {T <: Real} = 0.5 .* erfc(-x./sqrt(2))\n",
        "\n",
        "function tauchen(N::Integer, ρ::T1, σ::T2, μ=zero(promote_type(T1, T2)), n_std::T3=3) where {T1 <: Real, T2 <: Real, T3 <: Real}\n",
        "    # Get discretized space\n",
        "    a_bar = n_std * sqrt(σ^2 / (1 - ρ^2))\n",
        "    y = range(-a_bar, stop=a_bar, length=N)\n",
        "    d = y[2] - y[1]\n",
        "\n",
        "    # Get transition probabilities\n",
        "    Π = zeros(promote_type(T1, T2), N, N)\n",
        "    for row = 1:N\n",
        "        # Do end points first\n",
        "        Π[row, 1] = std_norm_cdf((y[1] - ρ*y[row] + d/2) / σ)\n",
        "        Π[row, N] = 1 - std_norm_cdf((y[N] - ρ*y[row] - d/2) / σ)\n",
        "\n",
        "        # fill in the middle columns\n",
        "        for col = 2:N-1\n",
        "            Π[row, col] = (std_norm_cdf((y[col] - ρ*y[row] + d/2) / σ) -\n",
        "                           std_norm_cdf((y[col] - ρ*y[row] - d/2) / σ))\n",
        "        end\n",
        "    end\n",
        "\n",
        "    yy = y .+ μ / (1 - ρ) # center process around its mean (wbar / (1 - rho)) in new variable\n",
        "\n",
        "    (;transitions=Π, values=yy)\n",
        "\n",
        "end"
      ],
      "id": "516366bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Take $\\rho=0.95, \\mu=0.1, \\nu=0.1$. Approximate the AR1 with 200\n",
        "discrete states, using the tauchen function above. Check that all rows\n",
        "sum to 1. Compute and plot the steady-state distribution.**"
      ],
      "id": "eb9d6015-dafd-4eb0-b866-c7a595d0adcd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "7b9d009c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider a firm whose productivity $y_t$ is exogenous and evolves\n",
        "according to the markov chain above.\n",
        "\n",
        "Profits are given by $\\pi(y_t) = y_t$.\n",
        "\n",
        "At the start of each period, the firm decides whether to remain in\n",
        "operation and receive current profit $\\pi_t$ or to exit and receive\n",
        "scrap value $s>0$ for the sale of physical assets.\n",
        "\n",
        "Time is discounted using interest rate, that is\n",
        "$\\beta=\\frac{1}{1+r} \\in [0,1[$.\n",
        "\n",
        "The following code creates a parameterization of the firm’s problem:"
      ],
      "id": "06a2fbd2-2a70-47aa-bc36-d6a62c67fa6f"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "create_exit_model"
            ]
          }
        }
      ],
      "source": [
        "\"Creates an instance of the firm exit model.\"\n",
        "function create_exit_model(;\n",
        "    n=200, # productivity grid size\n",
        "    ρ=0.95, μ=0.1, ν=0.1, # persistence, mean and volatility\n",
        "    β=0.98, s=100.0 # discount factor and scrap value\n",
        "    )\n",
        "    mc = tauchen(n, ρ, ν, μ)\n",
        "    z_vals, Q = mc.state_values, mc.p\n",
        "    return (; n, z_vals, Q, β, s)\n",
        "end"
      ],
      "id": "30cd7d91"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. What are the states of the problem? The controls? The rewards? What\n",
        "equation defines the value of the firm? How would you represent\n",
        "numerically the value function and the decision rule?**"
      ],
      "id": "ce3269b7-caa7-437a-988b-33c7440be81f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "b48b1e41"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Solve for the optimal exit decision using value function iteration.\n",
        "Plot the results.**"
      ],
      "id": "5d25fb58-7edc-4a87-96a6-dfc21f1c47a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "82879ed6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. (bonus) Taking into account the specific nature of this problem,\n",
        "propose a more efficient algorithm.**"
      ],
      "id": "c4ca845d-81f1-4575-b980-d1ed7febbca9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you code here"
      ],
      "id": "c71a31dd"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "julia-1.10",
      "display_name": "Julia 1.10.3",
      "language": "julia"
    },
    "language_info": {
      "name": "julia",
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "version": "1.10.3"
    }
  }
}