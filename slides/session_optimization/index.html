<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Pablo Winant">
  <meta name="dcterms.date" content="2024-04-03">
  <title>Introduction to Computational Economics – Optimization</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-bbe7401fe57d4b791b917637bb662036.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Optimization</h1>
  <p class="subtitle">Computational Economics (ECO309)</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Pablo Winant 
</div>
</div>
</div>

  <p class="date">2024-04-03</p>
</section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="introduction-1" class="slide level2">
<h2>Introduction</h2>
<p>Optimization is everywhere in economics:</p>
<ul>
<li>to model agent’s behaviour: what would a rational agent do?
<ul>
<li>consumer maximizes utility from consumption</li>
<li>firm maximizes profit</li>
</ul></li>
<li>an economist tries to solve a model:
<ul>
<li>find prices that clear the market</li>
</ul></li>
</ul>
</section>
<section id="two-kinds-of-optimization-problem" class="slide level2">
<h2>Two kinds of optimization problem:</h2>
<ul>
<li><p>root finding: <span class="math inline">\(\text{find  $x$ in $X$ such that $f(x)=0$}\)</span></p></li>
<li><p>minimization/maximization <span class="math inline">\(\min_{x\in X} f(x)\)</span> or <span class="math inline">\(\max_{x\in X} f(x)\)</span></p></li>
<li><p>often a minimization problem can be reformulated as a root-finding problem</p>
<p><span class="math display">\[x_0 = {argmin}_{x\in X} f(x) \overbrace{\iff}^{??} f^{\prime} (x_0) = 0\]</span></p></li>
</ul>
</section>
<section id="plan" class="slide level2">
<h2>Plan</h2>
<ul>
<li>general consideration about optimization problems</li>
<li>one-dimensional root-finding</li>
<li>one-dimensional optimization</li>
<li>local root-finding</li>
<li>local optimization</li>
<li>constrained optimization</li>
<li>constrained root-finding</li>
</ul>
</section></section>
<section>
<section id="general-considerations" class="title-slide slide level1 center">
<h1>General considerations</h1>

</section>
<section id="optimization-tasks-come-in-many-flavours" class="slide level2">
<h2>Optimization tasks come in many flavours</h2>
<ul>
<li>continuous versus discrete optimization</li>
<li>constrained and unconstrained optimization</li>
<li>global and local</li>
<li>stochastic and deterministic optimization</li>
<li>convexity</li>
</ul>
</section>
<section id="continuous-versus-discrete-optimization" class="slide level2">
<h2>Continuous versus discrete optimization</h2>
<ul>
<li>Choice is picked from a given set (<span class="math inline">\(x\in X\)</span>) which can be:
<ul>
<li>continuous: choose amount of debt <span class="math inline">\(b_t \in [0,\overline{b}]\)</span>, of capital <span class="math inline">\(k_t \in R^{+}\)</span></li>
<li>discrete: choose whether to repay or default <span class="math inline">\(\delta\in{0,1}\)</span>, how many machines to buy (<span class="math inline">\(\in N\)</span>), at which age to retire…</li>
<li>a combination of both: mixed integer programming</li>
</ul></li>
</ul>
</section>
<section id="continuous-versus-discrete-optimization-2" class="slide level2">
<h2>Continuous versus discrete optimization (2)</h2>
<ul>
<li>Discrete optimization requires a lot of combinatorial thinking
<ul>
<li>We don’t cover it today.</li>
<li>…if needed, we just test all choices until we find the best one</li>
</ul></li>
<li>Sometimes a discrete choice can be approximated by a mixed strategy (i.e.&nbsp;a random strategy).
<ul>
<li>Instead of <span class="math inline">\(\delta\in{0,1}\)</span> we choose <span class="math inline">\(x\)</span> in <span class="math inline">\(prob(\delta=1)=\sigma(x)\)</span></li>
<li>with <span class="math inline">\(\sigma(x)=\frac{2}{1+\exp(-x)}\)</span></li>
</ul></li>
</ul>
</section>
<section id="constrained-and-unconstrained-optimization" class="slide level2">
<h2>Constrained and Unconstrained optimization</h2>
<ul>
<li>Unconstrained optimization: <span class="math inline">\(x\in R\)</span></li>
<li>Constrained optimization: <span class="math inline">\(x\in X\)</span>
<ul>
<li>budget set: <span class="math inline">\(p_1 c_1 + p_2 c_2 \leq I\)</span></li>
<li>positivity of consumption: <span class="math inline">\(c \geq 0\)</span>.</li>
</ul></li>
<li>In good cases, the optimization set is <em>convex</em>…
<ul>
<li>pretty much always in this course</li>
</ul></li>
</ul>
</section>
<section id="stochastic-vs-deterministic" class="slide level2">
<h2>Stochastic vs Deterministic</h2>
<ul>
<li>Common case, especially in machine learning <span class="math display">\[f(x) = E_{\epsilon}[ \xi (\epsilon, x)]\]</span></li>
<li>One wants to maximize (resp solve) w.r.t. <span class="math inline">\(x\)</span> but it is costly to compute expectation precisely using Monte-Carlo draws (there are other methods).</li>
<li>A <em>stochastic</em> optimization method allows to use noisy estimates of the expectation, and will still converge in expectation.</li>
<li>For now we focus on <em>deterministic</em> methods. Maybe later…</li>
</ul>
</section>
<section id="local-vs-global-algorithms" class="slide level2">
<h2>Local vs global Algorithms</h2>
<ul>
<li><p>In principle, there can be many roots (resp maxima) within the optimization set.</p></li>
<li><p>Algorithms that find them all are called “global”. For instance:</p>
<ul>
<li>grid search</li>
<li>simulated annealing</li>
</ul></li>
<li><p>We will deal only with local algorithms, and consider local convergence properties.</p>
<ul>
<li>-&gt;then it might work or not</li>
<li>to perform global optimization just restart from different points.</li>
</ul></li>
</ul>
</section>
<section id="math-vs-practice" class="slide level2">
<h2>Math vs practice</h2>
<ul>
<li><p>The full mathematical treatment will typically assume that <span class="math inline">\(f\)</span> is smooth (<span class="math inline">\(\mathcal{C}_1\)</span> or <span class="math inline">\(\mathcal{C}_2\)</span> depending on the algorithm).</p></li>
<li><p>In practice we often don’t know about these properties</p>
<ul>
<li>we still try and check thqt we have a local optimal</li>
</ul></li>
<li><p>So: fingers crossed</p></li>
</ul>
</section>
<section id="math-vs-practice-1" class="slide level2">
<h2>Math vs practice</h2>
<p>Here is the surface representing the objective that a deep neural network training algorithm tries to minimize.</p>

<img src="nonsmooth.png" width="50%" class="r-stretch"><p>And yet, neural networks do great things!</p>
</section>
<section id="what-do-you-need-to-know" class="slide level2">
<h2>What do you need to know?</h2>
<ul>
<li>be able to handcode simple algos (Newton, Gradient Descent)</li>
<li>understand the general principle of the various algorithms to compare them in terms of
<ul>
<li>robustness</li>
<li>efficiency</li>
<li>accuracy</li>
</ul></li>
<li>then you can just switch the various options, when you use a library…</li>
</ul>
</section></section>
<section>
<section id="one-dimensional-root-finding" class="title-slide slide level1 center">
<h1>One-dimensional root-finding</h1>

</section>
<section id="bisection" class="slide level2">
<h2>Bisection</h2>
<ul>
<li>Find <span class="math inline">\(x \in [a,b]\)</span> such that <span class="math inline">\(f(x) = 0\)</span>. Assume <span class="math inline">\(f(a)f(b) &lt;0\)</span>.</li>
<li>Algorithm
<ol type="1">
<li>Start with <span class="math inline">\(a_n, b_n\)</span>. Set <span class="math inline">\(c_n=(a_n+b_n)/2\)</span></li>
<li>Compute <span class="math inline">\(f(c_n)\)</span></li>
</ol>
<ul>
<li>if <span class="math inline">\(f(c_n)f(a_n)&lt;0\)</span> then set <span class="math inline">\((a_{n+1},b_{n+1})=(a_n,c_n)\)</span></li>
<li>else set <span class="math inline">\((a_{n+1},b_{n+1})=(c_n,b_n)\)</span></li>
</ul>
<ol start="3" type="1">
<li>If <span class="math inline">\(|f(c_n)|&lt;\epsilon\)</span> and/or <span class="math inline">\(\frac{b-a}{2^n}&lt;\delta\)</span> stop. Otherwise go back to 1.</li>
</ol></li>
</ul>
</section>
<section id="bisection-2" class="slide level2">
<h2>Bisection (2)</h2>
<ul>
<li>No need for initial guess: <em>globally convergent algorithm</em>
<ul>
<li>not a <em>global</em> algorithm…</li>
<li>… in the sense that it doesn’t find all solutions</li>
</ul></li>
<li><span class="math inline">\(\delta\)</span> is a guaranteed accuracy on <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(\epsilon\)</span> is a measure of how good the solution is</li>
<li>think about your tradeoff: (<span class="math inline">\(\delta\)</span> or <span class="math inline">\(\epsilon\)</span> ?)</li>
</ul>
</section>
<section id="newton-algorithm" class="slide level2">
<h2>Newton algorithm</h2>
<ul>
<li>Find <span class="math inline">\(x\)</span> such that <span class="math inline">\(f(x) = 0\)</span>. Use <span class="math inline">\(x_0\)</span> as initial guess.</li>
<li><span class="math inline">\(f\)</span> must be <span class="math inline">\(\mathcal{C_1}\)</span> and we assume we can compute its derivative <span class="math inline">\(f^{\prime}\)</span></li>
<li>General idea:
<ul>
<li>observe that the zero <span class="math inline">\(x^{\star}\)</span> must satisfy <span class="math display">\[f(x^{\star})=0=f(x_0)+f^{\prime}(x_0)(x^{\star}-x_0) + o(x-x_0)\]</span></li>
<li>Hence a good approximation should be <span class="math display">\[x^{\star}\approx = x_0- f(x_0)/f^{\prime}(x_0)\]</span></li>
<li>Check it is good. otherwise, replace <span class="math inline">\(x_0\)</span> by <span class="math inline">\(x^{\star}\)</span></li>
</ul></li>
</ul>
</section>
<section id="newton-algorithm-2" class="slide level2">
<h2>Newton algorithm (2)</h2>
<ul>
<li>Algorithm:
<ul>
<li>start with <span class="math inline">\(x_n\)</span></li>
<li>compute <span class="math inline">\(x_{n+1} = x_n- \frac{f(x_n)}{f^{\prime}(x_n)}=f^{\text{newton}}(x_n)\)</span></li>
<li>stop if <span class="math inline">\(|x_{n+1}-x_n|&lt;\eta\)</span> or <span class="math inline">\(|f(x_n)| &lt; \epsilon\)</span></li>
</ul></li>
<li>Convergence: <strong>quadratic</strong></li>
</ul>
</section>
<section id="quasi-newton" class="slide level2">
<h2>Quasi-Newton</h2>
<ul>
<li>What if we can’t compute <span class="math inline">\(f^{\prime}\)</span> or it is expensive to do so?
<ul>
<li>Idea: try to approximate <span class="math inline">\(f^{\prime}(x_n)\)</span> from the last iterates</li>
</ul></li>
<li><strong>Secant method</strong>: <span class="math display">\[f^{\prime}(x_n)\approx \frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}\]</span> <span class="math display">\[x_{n+1} = x_n- f(x_n)\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\]</span>
<ul>
<li>requires two initial guesses: <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_0\)</span></li>
<li>superlinear convergence: <span class="math inline">\(\lim \frac{x_t-x^{\star}}{x_{t-1}-x^{\star}}\rightarrow 0\)</span></li>
</ul></li>
</ul>
</section>
<section id="limits-of-newtons-method" class="slide level2">
<h2>Limits of Newton’s method</h2>
<ul>
<li>How could Newton method fail?
<ul>
<li>bad guess
<ul>
<li>-&gt; start with a better guess</li>
</ul></li>
<li>overshoot
<ul>
<li>-&gt; dampen the update (problem: much slower)</li>
<li>-&gt; backtrack</li>
</ul></li>
<li>stationary point
<ul>
<li>-&gt; if root of multiplicity <span class="math inline">\(m\)</span> try <span class="math inline">\(x_{n+1} = x_n- m \frac{f(x_n)}{f^{\prime}(x_n)}\)</span></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="backtracking" class="slide level2">
<h2>Backtracking</h2>
<ul>
<li>Simple idea:
<ul>
<li>at stage <span class="math inline">\(n\)</span> given <span class="math inline">\(f(x_n)\)</span> compute Newton step <span class="math inline">\(\Delta_n=-\frac{f(x_n)}{f^{\prime}(x_n)}\)</span></li>
<li>find the smallest <span class="math inline">\(k\)</span> such that <span class="math inline">\(|f(x_n-\Delta/2^k)|&lt;|f(x_n)|\)</span></li>
<li>set <span class="math inline">\(x_{n+1}=x_n-\Delta/2^k\)</span></li>
</ul></li>
</ul>
</section></section>
<section>
<section id="one-dimensional-minimization" class="title-slide slide level1 center">
<h1>One dimensional minimization</h1>

</section>
<section id="golden-section-search" class="slide level2">
<h2>Golden section search</h2>
<ul>
<li><p>Minimize <span class="math inline">\(f(x)\)</span> for <span class="math inline">\(x \in [a,b]\)</span></p></li>
<li><p>Choose <span class="math inline">\(\Phi \in [0,0.5]\)</span></p></li>
<li><p>Algorithm:</p>
<ul>
<li>start with <span class="math inline">\(a_n &lt; b_n\)</span> (initially equal to <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>)</li>
<li>define <span class="math inline">\(c_n = a_n+\Phi(b_n-a_n)\)</span> and <span class="math inline">\(d_n = a_n+(1-\Phi)(b_n-a_n)\)</span>
<ul>
<li>if <span class="math inline">\(f(c_n)&lt;f(d_n)\)</span> set <span class="math inline">\(a_{n+1},b_{n+1}=a_n, d_n\)</span></li>
<li>else set <span class="math inline">\(a_{n+1}, b_{n+1}= c_n, b_n\)</span></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="golden-section-search-2" class="slide level2">
<h2>Golden section search (2)</h2>
<ul>
<li>This is guaranteed to converge to a local minimum</li>
<li>In each step, the size of the interval is reduced by a factor <span class="math inline">\(\Phi\)</span></li>
<li>By choosing <span class="math inline">\(\Phi=\frac{\sqrt{5}-1}{2}\)</span> one can save one evaluation by iteration.
<ul>
<li>you can check that either <span class="math inline">\(c_{n+1} = d_n\)</span> or <span class="math inline">\(d_{n+1} = c_n\)</span></li>
</ul></li>
<li>Remark that bisection is not enough</li>
</ul>
</section>
<section id="gradient-descent" class="slide level2">
<h2>Gradient Descent</h2>
<ul>
<li>Minimize <span class="math inline">\(f(x)\)</span> for <span class="math inline">\(x \in R\)</span> given initial guess <span class="math inline">\(x_0\)</span></li>
<li>Algorithm:
<ul>
<li>start with <span class="math inline">\(x_n\)</span></li>
<li>compute <span class="math inline">\(x_{n+1} = x_n (1-\lambda)- \lambda f^{\prime}(x_n)\)</span></li>
<li>stop if <span class="math inline">\(|x_{n+1}-x_n|&lt;\eta\)</span> or <span class="math inline">\(|f^{\prime}(x_n)| &lt; \epsilon\)</span></li>
</ul></li>
</ul>
</section>
<section id="gradient-descent-2" class="slide level2">
<h2>Gradient Descent (2)</h2>
<ul>
<li>Uses local information
<ul>
<li>one needs to compute the gradient</li>
<li>note that gradient at <span class="math inline">\(x_n\)</span> does not provide a better guess for the minimum than <span class="math inline">\(x_n\)</span> itself</li>
<li>learning speed is crucial</li>
</ul></li>
<li>Convergence speed: <em>linear</em>
<ul>
<li>rate depend on the learning speed</li>
<li>optimal learning speed? the fastest for which there is convergence</li>
</ul></li>
</ul>
</section>
<section id="newton-raphson-method" class="slide level2">
<h2>Newton-Raphson method</h2>
<ul>
<li>Minimize <span class="math inline">\(f(x)\)</span> for <span class="math inline">\(x \in R\)</span> given initial guess <span class="math inline">\(x_0\)</span></li>
<li>Build a local model of <span class="math inline">\(f\)</span> around <span class="math inline">\(x_0\)</span> <span class="math display">\[f(x) = f(x_0) + f^{\prime}(x_0)(x-x_0) + f^{\prime\prime}(x_0)\frac{(x-x_0)^2}{2} + o(x-x_0)^2\]</span></li>
<li>According to this model, <span class="math display">\[ f(x{\star}) = min_x f(x)\iff \frac{d}{d x} \left[ f(x_0) + f^{\prime}(x_0)(x-x_0) + f^{\prime\prime}(x_0)\frac{(x-x_0)^2}{2} \right] = 0\]</span> which yields: <span class="math inline">\(x^{\star} = x_0 - \frac{f^{\prime}(x_0)}{f^{\prime\prime}(x_0)}\)</span></li>
<li>this is Newton applied to <span class="math inline">\(f^{\prime}(x)=0\)</span></li>
</ul>
</section>
<section id="newton-raphson-algorithm-2" class="slide level2">
<h2>Newton-Raphson Algorithm (2)</h2>
<ul>
<li>Algorithm:
<ul>
<li>start with <span class="math inline">\(x_n\)</span></li>
<li>compute <span class="math inline">\(x_{n+1} = x_n-\frac{f^{\prime}(x_0)}{f^{\prime\prime}(x_0)}\)</span></li>
<li>stop if <span class="math inline">\(|x_{n+1}-x_n|&lt;\eta\)</span> or <span class="math inline">\(|f^{\prime}(x_n)| &lt; \epsilon\)</span></li>
</ul></li>
<li>Convergence: <em>quadratic</em></li>
</ul>
</section></section>
<section>
<section id="unconstrained-multidimensional-optimization" class="title-slide slide level1 center">
<h1>Unconstrained Multidimensional Optimization</h1>

</section>
<section id="unconstrained-problems" class="slide level2">
<h2>Unconstrained problems</h2>
<ul>
<li><p>Minimize <span class="math inline">\(f(x)\)</span> for <span class="math inline">\(x \in R^n\)</span> given initial guess <span class="math inline">\(x_0 \in R^n\)</span></p></li>
<li><p>Many intuitions from the 1d case, still apply</p>
<ul>
<li>replace derivatives by gradient, jacobian and hessian</li>
<li>recall that matrix multiplication is not commutative</li>
</ul></li>
<li><p>Some specific problems:</p>
<ul>
<li>update speed can be specific to each dimension</li>
<li>saddle-point issues (for minimization)</li>
</ul></li>
</ul>
</section>
<section id="quick-terminology" class="slide level2">
<h2>Quick terminology</h2>
<p>Function <span class="math inline">\(f: R^p \rightarrow R^q\)</span></p>
<ul>
<li><p><em>Jacobian</em>: <span class="math inline">\(J(x)\)</span> or <span class="math inline">\(f^{\prime}_x(x)\)</span>, <span class="math inline">\(p\times q\)</span> matrix such that: <span class="math display">\[J(x)_{ij} = \frac{\partial f(x)_i}{\partial x_j}\]</span></p></li>
<li><p><em>Gradient</em>: <span class="math inline">\(\nabla f(x) = J(x)\)</span>, gradient when <span class="math inline">\(q=1\)</span></p></li>
<li><p><em>Hessian</em>: denoted by <span class="math inline">\(H(x)\)</span> or <span class="math inline">\(f^{\prime\prime}_{xx}(x)\)</span> when <span class="math inline">\(q=1\)</span>: <span class="math display">\[H(x)_{jk} = \frac{\partial f(x)}{\partial x_j\partial x_k}\]</span></p></li>
<li><p>In the following explanations, <span class="math inline">\(|x|\)</span> denotes the supremum norm, but most of the following explanations also work with other norms.</p></li>
</ul>
</section></section>
<section>
<section id="unconstrained-multidimensional-root-finding" class="title-slide slide level1 center">
<h1>Unconstrained Multidimensional Root-Finding</h1>

</section>
<section id="multidimensional-newton-raphson" class="slide level2">
<h2>Multidimensional Newton-Raphson</h2>
<ul>
<li>Algorithm:
<ul>
<li>start with <span class="math inline">\(x_n\)</span></li>
<li>compute <span class="math inline">\(x_{n+1} = x_n- J(x_{n})^{-1}f(x_n)=f^{\text{newton}}(x_n)\)</span></li>
<li>stop if <span class="math inline">\(|x_{n+1}-x_n|&lt;\eta\)</span> or <span class="math inline">\(|f(x_n)| &lt; \epsilon\)</span></li>
</ul></li>
<li>Convergence: <strong>quadratic</strong></li>
</ul>
</section>
<section id="multidimensional-newton-root-finding-2" class="slide level2">
<h2>Multidimensional Newton root-finding (2)</h2>
<ul>
<li>what matters is the computation of the step <span class="math inline">\(\Delta_n = {\color{\red}{J(x_{n})^{-1}}} f(x_n)\)</span></li>
<li>don’t compute <span class="math inline">\(J(x_n)^{-1}\)</span>
<ul>
<li>it takes less operations to compute <span class="math inline">\(X\)</span> in <span class="math inline">\(AX=Y\)</span> than <span class="math inline">\(A^{-1}\)</span> then <span class="math inline">\(A^{-1}Y\)</span></li>
<li>in Julia: <code>X = A \ Y</code></li>
</ul></li>
<li>strategies to improve convergence:
<ul>
<li><em>dampening</em>: <span class="math inline">\(x_n = (1-\lambda)x_{n-1} - \lambda \Delta_n\)</span></li>
<li><em>backtracking</em>: choose <span class="math inline">\(k\)</span> such that <span class="math inline">\(|f(x_n-2^{-k}\Delta_n)|\)</span>&lt;<span class="math inline">\(|f(x_{n-1})|\)</span></li>
<li><em>linesearch</em>: choose <span class="math inline">\(\lambda\in[0,1]\)</span> so that <span class="math inline">\(|f(x_n-\lambda\Delta_n)|\)</span> is minimal</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="unconstrained-multidimensional-minimization" class="title-slide slide level1 center">
<h1>Unconstrained Multidimensional Minimization</h1>

</section>
<section id="multidimensional-gradient-descent" class="slide level2">
<h2>Multidimensional Gradient Descent</h2>
<ul>
<li>Minimize <span class="math inline">\(f(x) \in R\)</span> for <span class="math inline">\(x \in R^n\)</span> given <span class="math inline">\(x_0 \in R^n\)</span></li>
<li>Algorithm
<ul>
<li>start with <span class="math inline">\(x_n\)</span> <span class="math display">\[x_{n+1} = (1-\lambda) x_n - \lambda \nabla f(x_n)\]</span></li>
<li>stop if <span class="math inline">\(|x_{n+1}-x_n|&lt;\eta\)</span> or <span class="math inline">\(|f(x_n)| &lt; \epsilon\)</span></li>
</ul></li>
<li>Comments:
<ul>
<li>lots of variants</li>
<li><strong>automatic differentiation</strong> software makes gradient easy to compute</li>
<li>convergence is typically <strong>linear</strong></li>
</ul></li>
</ul>
</section>
<section id="gradient-descent-variants" class="slide level2">
<h2>Gradient descent variants</h2>

<img src="contours_evaluation_optimizers.gif" width="60%" class="r-stretch"></section>
<section id="multidimensional-newton-minimization" class="slide level2">
<h2>Multidimensional Newton Minimization</h2>
<ul>
<li>Algorithm:
<ul>
<li>start with <span class="math inline">\(x_n\)</span></li>
<li>compute <span class="math inline">\(x_{n+1} = x_n-{\color{\red}{H(x_{n})^{-1}}}\color{\green}{ J(x_n)'}\)</span></li>
<li>stop if <span class="math inline">\(|x_{n+1}-x_n|&lt;\eta\)</span> or <span class="math inline">\(|f(x_n)| &lt; \epsilon\)</span></li>
</ul></li>
<li>Convergence: <strong>quadratic</strong></li>
<li>Problem:
<ul>
<li><span class="math inline">\(H(x_{n})\)</span> hard to compute efficiently</li>
<li>rather unstable</li>
</ul></li>
</ul>
</section>
<section id="quasi-newton-method-for-multidimensional-minimization" class="slide level2">
<h2>Quasi-Newton method for multidimensional minimization</h2>
<ul>
<li>Recall the secant method:
<ul>
<li><span class="math inline">\(f(x_{n-1})\)</span> and <span class="math inline">\(f(x_{n-2})\)</span> are used to approximate <span class="math inline">\(f^{\prime}(x_{n-2})\)</span>.</li>
<li>Intuitively, <span class="math inline">\(n\)</span> iterates would be needed to approximate a hessian of size <span class="math inline">\(n\)</span>….</li>
</ul></li>
<li>Broyden method: takes <span class="math inline">\(2 n\)</span> steps to solve a linear problem of size <span class="math inline">\(n\)</span>
<ul>
<li>uses past information incrementally</li>
</ul></li>
</ul>
</section>
<section id="quasi-newton-method-for-multidimensional-minimization-1" class="slide level2">
<h2>Quasi-Newton method for multidimensional minimization</h2>
<ul>
<li>Consider the approximation: <span class="math display">\[f(x_n)-f(x_{n-1}) \approx J(x_n) (x_n - x_{n-1})\]</span>
<ul>
<li><span class="math inline">\(J(x_n)\)</span> is unknown and cannot be determined directly as in the secant method.</li>
<li>idea: <span class="math inline">\(J(x_n)\)</span> as close as possible to <span class="math inline">\(J(x_{n-1})\)</span> while solving the secant equation</li>
<li>formula: <span class="math display">\[J_n = J_{n-1} + \frac{(f(x_n)-f(x_{n-1})) - J_{n-1}(x_n-x_{n-1})}{||x_n-x_{n-1}||^2}(x_n-x_{n-1})^{\prime}\]</span></li>
</ul></li>
</ul>
</section>
<section id="gauss-newton-minimization" class="slide level2">
<h2>Gauss-Newton Minimization</h2>
<ul>
<li>Restrict to least-square minimization: $min_x _i f(x)_i^2 R $</li>
<li>Then up to first order, <span class="math inline">\(H(x_n)\approx J(x_n)^{\prime}J(x_n)\)</span></li>
<li>Use the step: <span class="math inline">\(({J(x_n)^{\prime}J(x_n)})^{-1}\color{\green}{ J(x_n)}\)</span></li>
<li>Convergence:
<ul>
<li>can be <strong>quadratic</strong> at best</li>
<li>linear in general</li>
</ul></li>
</ul>
</section>
<section id="levenberg-marquardt" class="slide level2">
<h2>Levenberg-Marquardt</h2>
<ul>
<li><p>Least-square minimization: $min_x _i f(x)_i^2 R $</p></li>
<li><p>replace <span class="math inline">\({J(x_n)^{\prime}J(x_n)}^{-1}\)</span> by <span class="math inline">\({J(x_n)^{\prime}J(x_n)}^{-1} +\mu I\)</span></p>
<ul>
<li>adjust <span class="math inline">\(\lambda\)</span> depending on progress</li>
</ul></li>
<li><p>uses only gradient information like Gauss-Newton</p></li>
<li><p>equivalent to Gauss-Newton close to the solution (<span class="math inline">\(\mu\)</span> small)</p></li>
<li><p>equivalent to Gradient far from solution (<span class="math inline">\(\mu\)</span> high)</p></li>
</ul>
</section></section>
<section>
<section id="constrained-optimization-and-complementarity-conditions" class="title-slide slide level1 center">
<h1>Constrained optimization and complementarity conditions</h1>

</section>
<section id="consumption-optimization" class="slide level2">
<h2>Consumption optimization</h2>
<p>Consider the optimization problem: <span class="math display">\[\max U(x_1, x_2)\]</span></p>
<p>under the constraint <span class="math inline">\(p_1 x_1 + p_2 x_2 \leq B\)</span></p>
<p>where <span class="math inline">\(U(.)\)</span>, <span class="math inline">\(p_1\)</span>, <span class="math inline">\(p_2\)</span> and <span class="math inline">\(B\)</span> are given.</p>
<p>How do you find a solution by hand?</p>
</section>
<section id="consumption-optimization-1" class="slide level2">
<h2>Consumption optimization (1)</h2>
<ul>
<li>Compute by hand</li>
<li>Easy:
<ul>
<li>since the budget constraint must be binding, get rid of it by stating <span class="math inline">\(x_2 = B - p_1 x_1\)</span></li>
<li>then maximize in <span class="math inline">\(x_1\)</span>, <span class="math inline">\(U(x_1, B - p_1 x_1)\)</span> using the first order conditions.</li>
</ul></li>
<li>It works but:
<ul>
<li>breaks symmetry between the two goods</li>
<li>what if there are other constraints: <span class="math inline">\(x_1\geq \underline{x}\)</span>?</li>
<li>what if constraints are not binding?</li>
<li>is there a better way to solve this problem?</li>
</ul></li>
</ul>
</section>
<section id="consumption-optimization-2" class="slide level2">
<h2>Consumption optimization (2)</h2>
<ul>
<li>Another method, which keeps the symmetry. Constraint is binding, trying to minimize along the budget line yields an implicit relation between <span class="math inline">\(d x_1\)</span> and <span class="math inline">\(d x_2\)</span> <span class="math display">\[p_1 d {x_1} + p_2 d {x_2} = 0\]</span></li>
<li>At the optimal: <span class="math inline">\(U^{\prime}_{x_1}(x_1, x_2)d {x_1} + U^{\prime}_{x_2}(x_1, x_2)d {x_2} = 0\)</span></li>
<li>Eliminate <span class="math inline">\(d {x_1}\)</span> and <span class="math inline">\(d {x_2}\)</span> to get <em>one</em> condition which characterizes optimal choices for all possible budgets. Combine with the budget constraint to get a <em>second</em> condition.</li>
</ul>
</section>
<section id="penalty-function" class="slide level2">
<h2>Penalty function</h2>
<ul>
<li>Take a penalty function <span class="math inline">\(p(x)\)</span> such that <span class="math inline">\(p(x)=K&gt;0\)</span> if <span class="math inline">\(x&gt;0\)</span> and <span class="math inline">\(p(x)=0\)</span> if <span class="math inline">\(x \leq 0\)</span>. Maximize: <span class="math inline">\(V(x_1, x_2) = U(x_1, x_2) - p( p_1 x_1 + p_2 x_2 - B)\)</span></li>
<li>Clearly, <span class="math inline">\(\min U \iff \min V\)</span></li>
<li>Problem: <span class="math inline">\(\nabla V\)</span> is always equal to <span class="math inline">\(\nabla U\)</span>.</li>
<li>Solution: use a smooth solution function like <span class="math inline">\(p(x) = x^2\)</span></li>
<li>Problem: distorts optimization
<ul>
<li>Solution: adjust weight of barrier and minimize <span class="math inline">\(U(x_1, x_2) - \kappa p(x)\)</span></li>
</ul></li>
<li>Possible but hard to choose the weights/constraints.</li>
</ul>
</section>
<section id="penalty-function-1" class="slide level2">
<h2>Penalty function</h2>
<ul>
<li>Another idea: is there a canonical way to choose <span class="math inline">\(\lambda\)</span> such that at the minimum it is equivalent to minimize the original problem under constraint or to minimize <span class="math display">\[V(x_1, x_2) = U(x_1, x_2) - \lambda (p_1 x_1 + p_2 x_2 - B)\]</span></li>
<li>Clearly, when the constraint is not binding we must have <span class="math inline">\(\lambda=0\)</span>. What should be the value of <span class="math inline">\(\lambda\)</span> when the constraint is binding ?</li>
</ul>
</section>
<section id="karush-kuhn-tucker-conditions" class="slide level2">
<h2>Karush-Kuhn-Tucker conditions</h2>
<ul>
<li>If <span class="math inline">\((x^{\star},y^{\star})\)</span> is optimal there exists <span class="math inline">\(\lambda\)</span> such that:
<ul>
<li><span class="math inline">\((x^{\star},y^{\star})\)</span> maximizes lagrangian <span class="math inline">\(\mathcal{L} = U(x_1, x_2) + \lambda (B- p_1 x_1 - p_2 x_2)\)</span></li>
<li><span class="math inline">\(\lambda \geq 0\)</span></li>
<li><span class="math inline">\(B- p_1 x_1 - p_2 x_2 \geq 0\)</span></li>
<li><span class="math inline">\(\lambda  (B - p_1 x_1 - p_2 x_2 ) = 0\)</span></li>
</ul></li>
<li>The three latest conditions are called “complementarity” or “slackness” conditions
<ul>
<li>they are equivalent to <span class="math inline">\(\min(\lambda, B - p_1 x_1 - p_2 x_2)=0\)</span></li>
<li>we denote <span class="math inline">\(\lambda \geq 0 \perp B- p_1 x_1 + p_2 x_2  \geq 0\)</span></li>
</ul></li>
<li><span class="math inline">\(\lambda\)</span> can be interpreted as the welfare gain of relaxing the constraint.</li>
</ul>
</section>
<section id="karush-kuhn-tucker-conditions-1" class="slide level2">
<h2>Karush-Kuhn-Tucker conditions</h2>
<ul>
<li>We can get first order conditions that factor in the constraints:
<ul>
<li><span class="math inline">\(U^{\prime}_x - \lambda p_1 = 0\)</span></li>
<li><span class="math inline">\(U^{\prime}_y - \lambda p_2 = 0\)</span></li>
<li><span class="math inline">\(\lambda \geq 0 \perp B-p_1 x_1 -p_2 x_2 \geq 0\)</span></li>
</ul></li>
<li>It is now a nonlinear system of equations with complementarities (NCP)
<ul>
<li>there are specific solution methods to deal with it</li>
</ul></li>
</ul>
</section>
<section id="solution-strategies-for-ncp-problems" class="slide level2">
<h2>Solution strategies for NCP problems</h2>
<ul>
<li><p>General formulation for vector-valued functions <span class="math display">\[f(x)\geq 0 \perp g(x)\geq 0\]</span> means <span class="math display">\[\forall i, f_i(x)\geq 0 \perp g_i(x)\geq 0\]</span></p>
<ul>
<li>NCP do not necessarily arise from a single optimization problem</li>
</ul></li>
<li><p>There are robust (commercial) solvers for NCP problems (PATH, Knitro) for that</p></li>
<li><p>How do we solve it numerically?</p>
<ul>
<li>assume constraint is binding then non-binding then check which one is good
<ul>
<li>OK if not too many constraints</li>
</ul></li>
<li>reformulate it as a smooth problem</li>
<li>approximate the system by a series of linear complementarities problems (LCP)</li>
</ul></li>
</ul>
</section>
<section id="smooth-method" class="slide level2">
<h2>Smooth method</h2>
<ul>
<li>Consider the <em>Fisher-Burmeister</em> function <span class="math display">\[\phi(a,b) = a+b-\sqrt{a^2+b^2}\]</span></li>
<li>It is infinitely differentiable, except at <span class="math inline">\((0,0)\)</span></li>
<li>Show that <span class="math inline">\(\phi(a,b) = 0 \iff \min(a,b)=0 \iff a\geq 0 \perp b \geq 0\)</span></li>
<li>After substitution in the original system one can use regular non-linear solver
<ul>
<li>fun fact: the formulation with a <span class="math inline">\(\min\)</span> is nonsmooth but also works quite often</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="practicalities" class="title-slide slide level1 center">
<h1>Practicalities</h1>

</section>
<section id="optimization-libraries" class="slide level2">
<h2>Optimization libraries</h2>
<ul>
<li>Robust optimization code is contained in the following libraries:
<ul>
<li>Roots.jl: one-dimensional root finding</li>
<li>NLSolve.jl: multidimensional root finding (+complementarities)</li>
<li>Optim.jl: minimization</li>
</ul></li>
<li>The two latter libraries have a somewhat peculiar API, but it’s worth absorbing it.
<ul>
<li>in particular they provide non-allocating algorithms for functions that modify arguments in place</li>
<li>they are compatible with automatic differentiation</li>
</ul></li>
</ul>
<pre><code>julia&gt; f(x) = [x[1] - x[2] - 1, x[1] + x[2]]
f (generic function with 1 method)

julia&gt; NLsolve.nlsolve(f, [0., 0.0])
Results of Nonlinear Solver Algorithm
 * Algorithm: Trust-region with dogleg and autoscaling
 * Starting Point: [0.0, 0.0]
 * Zero: [0.5000000000009869, -0.5000000000009869]
 * Inf-norm of residuals: 0.000000       
 * Iterations: 1                       
 * Convergence: true
   * |x - x'| &lt; 0.0e+00: false
   * |f(x)| &lt; 1.0e-08: true                           
 * Function Calls (f): 2
 * Jacobian Calls (df/dx): 2</code></pre>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="logo.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/albop\.github\.io\/eco309\/");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>